{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:06.107576700Z",
     "start_time": "2025-12-18T12:18:06.056854800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Language\n",
    "import dev.biserman.planet.language.Segment\n",
    "import dev.biserman.planet.language.SyllableConstructor\n",
    "import dev.biserman.planet.language.InventoryTransformation\n",
    "import dev.biserman.planet.language.Manner\n",
    "import dev.biserman.planet.language.SegmentType\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:09.317391200Z",
     "start_time": "2025-12-18T12:18:06.125446800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Glide\n",
    "import dev.biserman.planet.language.Place\n",
    "import dev.biserman.planet.language.SegmentData\n",
    "import dev.biserman.planet.utils.toWeightedBag\n",
    "import kotlin.random.Random\n",
    "\n",
    "SyllableConstructor.languageFile = \"\"\"E:\\Users\\Winggar\\source\\repos\\Planet\\planet\\english.json\"\"\"\n",
    "SyllableConstructor.phonemeFile = \"\"\"E:\\Users\\Winggar\\source\\repos\\Planet\\planet\\phonemes.json\"\"\"\n",
    "\n",
    "val basicPhonemes = \"ptksmnljw\"\n",
    "val basicTransformation: InventoryTransformation = { inventory ->\n",
    "    inventory.plus(basicPhonemes.mapNotNull { SyllableConstructor.segments[it.toString()] })\n",
    "}\n",
    "\n",
    "fun (Set<Segment>).addSet(\n",
    "    from: (SegmentData) -> Boolean,\n",
    "    to: (SegmentData) -> SegmentData,\n",
    "    condition: Boolean = true\n",
    "): Set<Segment> {\n",
    "    if (!condition) return this\n",
    "\n",
    "    val new = this\n",
    "        .filter { from(it.data) }\n",
    "        .map { to(it.data) }\n",
    "    val matching = SyllableConstructor.segments.values.filter { it.data in new }\n",
    "    return this.plus(matching)\n",
    "}\n",
    "\n",
    "val random = Random(System.currentTimeMillis())\n",
    "\n",
    "val placeWeights = mapOf(\n",
    "    Place.LABIAL to 40,\n",
    "    Place.DENTAL to 5,\n",
    "    Place.ALVEOLAR to 50,\n",
    "    Place.POSTALVEOLAR to 35,\n",
    "    Place.PALATAL to 25,\n",
    "    Place.VELAR to 45,\n",
    "    Place.UVULAR to 5,\n",
    "    Place.GLOTTAL to 50,\n",
    ")\n",
    "\n",
    "val inversePlaceWeights = (placeWeights.values.max()).let { maxWeight ->\n",
    "    placeWeights.mapValues { (_, weight) -> maxWeight - weight + 1 }\n",
    "}\n",
    "\n",
    "//val affricates = mapOf(\n",
    "//    'ɸ' to Pair('p', 10),\n",
    "//    'β' to Pair('b', 10),\n",
    "//    'f' to Pair('p', 50),\n",
    "//    'v' to Pair('b', 50),\n",
    "//    'θ' to Pair('t', 10),\n",
    "//    'ð' to Pair('d', 10),\n",
    "//    's' to Pair('t', 100),\n",
    "//    'z' to Pair('d', 100),\n",
    "//    'ʃ' to Pair('t', 250),\n",
    "//    'ʒ' to Pair('d', 250),\n",
    "//    'x' to Pair('k', 100)\n",
    "//)\n",
    "\n",
    "fun center(x: Double) = 4 * (x - 0.5).pow(3) + 0.5\n",
    "\n",
    "val inventoryTransformations = listOf<Pair<InventoryTransformation, Int>>(\n",
    "    { inventory: Set<Segment> -> // add voicing\n",
    "        val chance = random.nextDouble()\n",
    "        val newInventory = inventory.let {\n",
    "            if (chance <= 0.9) {\n",
    "                inventory.addSet(\n",
    "                    from = { it.manner == Manner.PLOSIVE },\n",
    "                    to = { it.copy(voiced = true) },\n",
    "                    condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "            } else it\n",
    "        }.let {\n",
    "            if (chance <= 0.4 || chance > 0.9) {\n",
    "                inventory.addSet(\n",
    "                    from = { it.manner == Manner.FRICATIVE },\n",
    "                    to = { it.copy(voiced = true) },\n",
    "                    condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "            } else it\n",
    "        }\n",
    "        newInventory\n",
    "    } to 600,\n",
    "    { inventory: Set<Segment> -> // add aspiration\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(isAspirated = true, voiced = null) },\n",
    "            condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "    } to 400,\n",
    "    { inventory: Set<Segment> -> // add ejectives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(isEjective = true, voiced = null) })\n",
    "    } to 100,\n",
    "\n",
    "    { inventory: Set<Segment> -> // add plosives from fricatives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.PLOSIVE) })\n",
    "    } to 300,\n",
    "    { inventory: Set<Segment> -> // add fricatives from plosives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE },\n",
    "            to = { it.copy(manner = Manner.FRICATIVE) })\n",
    "    } to 300,\n",
    "\n",
    "    { inventory: Set<Segment> -> // add rhotic\n",
    "        inventory.plus(SyllableConstructor.segments[\"ɹ\"]!!)\n",
    "    } to 500,\n",
    "    { inventory: Set<Segment> -> // add implosives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.IMPLOSIVE) })\n",
    "    } to 100,\n",
    "    { inventory: Set<Segment> -> // add clicks\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.CLICK, voiced = null) })\n",
    "    } to 100,\n",
    "    { inventory: Set<Segment> -> // add nasals\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.NASAL, voiced = null) })\n",
    "    } to 250,\n",
    "    { inventory: Set<Segment> -> // remove randomly\n",
    "        inventory.filter { random.nextDouble() <= center(it.prevalence).pow(0.33) }.toSet()\n",
    "    } to 500,\n",
    "\n",
    "    affricate@{ inventory: Set<Segment> -> // add affricates\n",
    "        val fricative =\n",
    "            inventory.filter { it.data.manner == Manner.FRICATIVE && it.data.place != Place.GLOTTAL }\n",
    "                .randomOrNull(random) ?: return@affricate inventory\n",
    "        val glide = Glide.from(fricative.data, false)\n",
    "        val affricate = if (random.nextDouble() <= 0.75) {\n",
    "            val place = when (fricative.data.place) {\n",
    "                Place.LABIODENTAL -> Place.BILABIAL\n",
    "                Place.POSTALVEOLAR -> Place.ALVEOLAR\n",
    "                Place.PALATAL -> Place.ALVEOLAR\n",
    "                Place.DENTAL -> Place.ALVEOLAR\n",
    "                else -> fricative.data.place\n",
    "            }\n",
    "            fricative.copyData { it.copy(place = place, manner = Manner.PLOSIVE, consonantGlide = glide) }\n",
    "        } else {\n",
    "            val plosive =\n",
    "                inventory\n",
    "                    .filter {\n",
    "                        it.data.manner == Manner.PLOSIVE &&\n",
    "                                it.data.place != Place.GLOTTAL &&\n",
    "                                it.data.isAspirated == false &&\n",
    "                                it.data.isEjective == false &&\n",
    "                                it.data.voiced == fricative.data.voiced\n",
    "                    }\n",
    "                    .randomOrNull(random) ?: return@affricate inventory\n",
    "            plosive.copyData { it.copy(consonantGlide = glide) }\n",
    "        }\n",
    "        inventory.plus(affricate)\n",
    "    } to 300,\n",
    "\n",
    "    glideColoredSet@{ inventory: Set<Segment> -> // add a glide-colored set\n",
    "        val chance = random.nextDouble()\n",
    "        val glide = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.SEMIVOWEL || it.data.manner == Manner.LIQUID }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSet inventory\n",
    "\n",
    "        val newInventory = inventory.let {\n",
    "            if (chance <= 0.67) {\n",
    "                it.plus(it.filter { it.data.manner == Manner.FRICATIVE }\n",
    "                    .map { it.copyData { it.copy(offGlide = Glide.from(glide.data, false)) } })\n",
    "            } else it\n",
    "        }.let {\n",
    "            if (chance <= 0.33 || chance > 0.67) {\n",
    "                it.plus(it.filter { it.data.manner == Manner.PLOSIVE }\n",
    "                    .filter { it.data.place != Place.GLOTTAL }\n",
    "                    .map { it.copyData { it.copy(offGlide = Glide.from(glide.data, false)) } })\n",
    "            } else it\n",
    "        }\n",
    "\n",
    "        newInventory\n",
    "    } to 200,\n",
    "\n",
    "    glideColoredSingle@{ inventory: Set<Segment> ->\n",
    "        val glide = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.SEMIVOWEL || it.data.manner == Manner.LIQUID }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSingle inventory\n",
    "\n",
    "        val plosive = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.PLOSIVE }\n",
    "            .filter { it.data.place != Place.GLOTTAL }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSingle inventory\n",
    "\n",
    "        inventory.plus(plosive.copyData { it.copy(offGlide = Glide.from(glide.data, false)) })\n",
    "    } to 300,\n",
    "\n",
    "    { inventory: Set<Segment> -> // tʃ, dʒ\n",
    "        if (inventory.any { it.data.place == Place.ALVEOLAR && it.data.manner == Manner.PLOSIVE }) {\n",
    "            val tʃ = SyllableConstructor.segments[\"t\"]!!.copyData {\n",
    "                it.copy(\n",
    "                    consonantGlide = Glide(\n",
    "                        Place.POSTALVEOLAR,\n",
    "                        Manner.FRICATIVE,\n",
    "                        false\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "            val dʒ = SyllableConstructor.segments[\"d\"]!!.copyData {\n",
    "                it.copy(\n",
    "                    consonantGlide = Glide(\n",
    "                        Place.POSTALVEOLAR,\n",
    "                        Manner.FRICATIVE,\n",
    "                        false\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "\n",
    "            if (inventory.any { it.data.place == Place.ALVEOLAR && it.data.manner == Manner.PLOSIVE && it.data.voiced == true }) {\n",
    "                inventory.plus(listOf(tʃ, dʒ))\n",
    "            } else {\n",
    "                inventory.plus(tʃ)\n",
    "            }\n",
    "        } else {\n",
    "            inventory\n",
    "        }\n",
    "    } to 200,\n",
    ").plus(placeWeights.map { (place, weight) ->\n",
    "    { inventory: Set<Segment> ->\n",
    "        inventory.addSet(\n",
    "            from = { it.type == SegmentType.CONSONANT },\n",
    "            to = { it.copy(place = place) })\n",
    "\n",
    "    } to weight * 3\n",
    "}).plus(inversePlaceWeights.map { (place, weight) ->\n",
    "    { inventory: Set<Segment> ->\n",
    "        inventory.filter { it.data.place != place }.toSet()\n",
    "    } to weight\n",
    "})\n",
    "\n",
    "val bag = inventoryTransformations.toWeightedBag(random) { it.second }\n",
    "\n",
    "fun generateConsonants() = basicTransformation(setOf()).let {\n",
    "    (1..15).fold(it) { acc, _ -> bag.grab()!!.first.invoke(acc) }\n",
    "}.sortedBy { SyllableConstructor.segments.keys.indexOf(it.symbol) }\n",
    "\n",
    "for (_1 in 0..10) {\n",
    "    val testLanguage = generateConsonants()\n",
    "    println(\"${testLanguage.size} phonemes: ${testLanguage.map { it.display }}\")\n",
    "}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 phonemes: [m, n, ŋ, p, t, tʷ, k, k͡s, ɡ, ɡˡ, f, s, w, ɹ, l]\r\n",
      "24 phonemes: [m, n, ŋ, p, p͡s, p?, t͡ʃ, t͡s, t?, k, k?, b, b?, ɡ, ɡ?, f, f?, s, s?, v, z, z?, j, l]\r\n",
      "25 phonemes: [m, n, ŋ, p, p?, t, t͡ʃ, t?, k, k?, b, b?, d, dʷ, d͡ʒ, d?, ɡ, ɡ?, s, s?, z, z?, j, w, l]\r\n",
      "21 phonemes: [m, n, ŋ, p, pʷ, t, tʷ, t͡ʃ, k, kʷ, d, d͡ʒ, ɡ, s, sʷ, z, zʷ, j, w, ɹ, l]\r\n",
      "13 phonemes: [m, n, p, t, t͡ʃ, k, kʷ, f, s, j, w, ɹ, l]\r\n",
      "15 phonemes: [m, n, ŋ, p, t, tˡ, t͡s, k, k?, f, s, v, j, ɹ, l]\r\n",
      "26 phonemes: [m, n, ŋ, p, p?, t, tʷ, t?, k, kʷ, k?, b, b?, d?, ɡ, ɡ?, f, fʷ, s, v, vʷ, z, zʷ, j, w, l]\r\n",
      "16 phonemes: [m, n, ŋ, p, pˡ, t, t͡ʃ, k, s, ʃ, z, ʒ, j, w, ɹ, l]\r\n",
      "19 phonemes: [m, n, ŋ, p, pʷ, pʳ, t, tˡ, t͡s, tʷ, tʳ, k, kʳ, f, s, j, w, ɹ, l]\r\n",
      "19 phonemes: [m, n, ŋ, p, t, t͡ʃ, k, b, d, d͡ʒ, ɡ, f, s, v, z, ʔ, w, ɹ, l]\r\n",
      "17 phonemes: [m, n, p, t, t͡s, t?, k, k?, b, d, f, s, v, z, j, w, ɹ]\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:09.440949100Z",
     "start_time": "2025-12-18T12:18:09.327801100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SyllableConstructor.segments.entries.map {\n",
    "    println(\"${it.key} - ${it.value}\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m - Segment(symbol=m, data=SegmentData(type=CONSONANT, place=LABIAL, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.97)\r\n",
      "n - Segment(symbol=n, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.97)\r\n",
      "ŋ - Segment(symbol=ŋ, data=SegmentData(type=CONSONANT, place=VELAR, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.69)\r\n",
      "p - Segment(symbol=p, data=SegmentData(type=CONSONANT, place=LABIAL, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.95)\r\n",
      "t - Segment(symbol=t, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.99)\r\n",
      "k - Segment(symbol=k, data=SegmentData(type=CONSONANT, place=VELAR, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.99)\r\n",
      "b - Segment(symbol=b, data=SegmentData(type=CONSONANT, place=LABIAL, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.7)\r\n",
      "d - Segment(symbol=d, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.7)\r\n",
      "ɡ - Segment(symbol=ɡ, data=SegmentData(type=CONSONANT, place=VELAR, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.64)\r\n",
      "f - Segment(symbol=f, data=SegmentData(type=CONSONANT, place=LABIAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.46)\r\n",
      "θ - Segment(symbol=θ, data=SegmentData(type=CONSONANT, place=DENTAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.04)\r\n",
      "s - Segment(symbol=s, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.8)\r\n",
      "ʃ - Segment(symbol=ʃ, data=SegmentData(type=CONSONANT, place=POSTALVEOLAR, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.54)\r\n",
      "v - Segment(symbol=v, data=SegmentData(type=CONSONANT, place=LABIAL, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.3)\r\n",
      "z - Segment(symbol=z, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.4)\r\n",
      "ʒ - Segment(symbol=ʒ, data=SegmentData(type=CONSONANT, place=POSTALVEOLAR, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.37)\r\n",
      "ʔ - Segment(symbol=ʔ, data=SegmentData(type=CONSONANT, place=GLOTTAL, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.4)\r\n",
      "h - Segment(symbol=h, data=SegmentData(type=CONSONANT, place=GLOTTAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.6)\r\n",
      "j - Segment(symbol=j, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=SEMIVOWEL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.92)\r\n",
      "w - Segment(symbol=w, data=SegmentData(type=CONSONANT, place=LABIAL, manner=SEMIVOWEL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.86)\r\n",
      "ɹ - Segment(symbol=ɹ, data=SegmentData(type=CONSONANT, place=RETROFLEX, manner=LIQUID, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.06)\r\n",
      "l - Segment(symbol=l, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=LIQUID, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.83)\r\n",
      "i - Segment(symbol=i, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.98)\r\n",
      "u - Segment(symbol=u, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE, depth=BACK, rounded=true, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.94)\r\n",
      "ɪ - Segment(symbol=ɪ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=NEAR_CLOSE, depth=NEAR_FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.18)\r\n",
      "e - Segment(symbol=e, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE_MID, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.78)\r\n",
      "o - Segment(symbol=o, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE_MID, depth=BACK, rounded=true, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.77)\r\n",
      "ɛ - Segment(symbol=ɛ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN_MID, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.43)\r\n",
      "ʌ - Segment(symbol=ʌ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN_MID, depth=BACK, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.06)\r\n",
      "æ - Segment(symbol=æ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=NEAR_OPEN, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.1)\r\n",
      "a - Segment(symbol=a, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.95)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:41.009554500Z",
     "start_time": "2025-12-18T12:25:40.505977400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.geometry.scaleAndCoerceIn\n",
    "import dev.biserman.planet.language.Depth\n",
    "import dev.biserman.planet.language.Height\n",
    "\n",
    "val vowelDistanceFeatures = listOf(\n",
    "    SegmentData::depth,\n",
    "    SegmentData::height,\n",
    "    SegmentData::rounded,\n",
    "    SegmentData::lengthened,\n",
    "    SegmentData::nasalized,\n",
    "    SegmentData::onGlide,\n",
    "    SegmentData::offGlide,\n",
    ")\n",
    "\n",
    "inline fun <reified T : Enum<T>> center() = (enumValues<T>().size / 2.0).roundToInt()\n",
    "\n",
    "@JvmName(\"vowelNonNull\")\n",
    "fun (Glide).vowel(isOnGlide: Boolean): Segment = (this as Glide?).vowel(isOnGlide)!!\n",
    "fun (Glide?).vowel(isOnGlide: Boolean): Segment? {\n",
    "    return when {\n",
    "        this == null -> null\n",
    "        this.manner != Manner.SEMIVOWEL -> null\n",
    "        this.place == Place.PALATAL ->\n",
    "            SyllableConstructor.segments[\"i\"]!!\n",
    "        this.place == Place.LABIAL ->\n",
    "            if (isOnGlide) SyllableConstructor.segments[\"u\"]\n",
    "            else SyllableConstructor.segments[\"o\"]\n",
    "        else -> null\n",
    "    }\n",
    "}\n",
    "\n",
    "fun (Segment?).vowelDistanceTo(other: Segment?): Int = if (this == null || other == null) 0 else\n",
    "    (vowelDistanceFeatures.count { feature -> feature.get(this.data) != feature.get(other.data) }\n",
    "            + (this.data.height!!.ordinal - other.data.height!!.ordinal).absoluteValue\n",
    "            + (this.data.depth!!.ordinal - other.data.depth!!.ordinal).absoluteValue\n",
    "            + (this.data.onGlide.vowel(true).vowelDistanceTo(other.data.onGlide.vowel(true)))\n",
    "            + (this.data.offGlide.vowel(false).vowelDistanceTo(other.data.offGlide.vowel(false))))\n",
    "\n",
    "val (SegmentData).isFrontward get() = this.depth!!.ordinal < Depth.CENTRAL.ordinal\n",
    "val (SegmentData).isBackward get() = this.depth!!.ordinal > Depth.CENTRAL.ordinal\n",
    "val (SegmentData).isHigh get() = this.height!!.ordinal < Height.MID.ordinal\n",
    "val (SegmentData).isLow get() = this.height!!.ordinal > Height.MID.ordinal\n",
    "\n",
    "fun generateVowels(): List<Segment> {\n",
    "    val allVowels = SyllableConstructor.segments.values\n",
    "        .filter { it.data.type == SegmentType.VOWEL }\n",
    "\n",
    "    val baseVowels = allVowels\n",
    "        .filter { random.nextDouble() <= it.prevalence }\n",
    "\n",
    "    // adjusts for typo.uni-konstanz.de → Universal 1284\n",
    "    fun heightNasalityAdjustment(height: Height) = (-height.ordinal.toDouble()).scaleAndCoerceIn(-6.0..0.0, 0.7..1.3)\n",
    "\n",
    "    val nasalVowels = if (random.nextDouble() <= 0.2) {\n",
    "        baseVowels.filter {\n",
    "            val chance = random.nextDouble() * heightNasalityAdjustment(it.data.height!!)\n",
    "            chance <= it.prevalence * 1.5\n",
    "        }.map { it.copy(data = it.data.copy(nasalized = true)) }\n",
    "    } else allVowels.filter {\n",
    "        random.nextDouble() <= it.prevalence * 0.05 * heightNasalityAdjustment(it.data.height!!)\n",
    "    }.map { it.copy(data = it.data.copy(nasalized = true)) }\n",
    "\n",
    "    val longVowels = if (random.nextDouble() <= 0.35) {\n",
    "        baseVowels.plus(nasalVowels).filter {\n",
    "            val chance = random.nextDouble()\n",
    "            chance <= it.prevalence * 2.0\n",
    "        }.map { it.copy(data = it.data.copy(lengthened = true)) }\n",
    "    } else listOf()\n",
    "\n",
    "    val wOnGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"u\" }\n",
    "            .map { it.copy(data = it.data.copy(onGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, true))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"u\" }\n",
    "        .map { it.copy(data = it.data.copy(onGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, true))) }\n",
    "\n",
    "    val jOnGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"i\" }\n",
    "            .map { it.copy(data = it.data.copy(onGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, true))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"i\" }\n",
    "        .map { it.copy(data = it.data.copy(onGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, true))) }\n",
    "\n",
    "    val wOffGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .plus(jOnGlides)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"o\" }\n",
    "            .map { it.copy(data = it.data.copy(offGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, false))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"o\" }\n",
    "        .map { it.copy(data = it.data.copy(offGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, false))) }\n",
    "\n",
    "    val jOffGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .plus(wOnGlides)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"i\" }\n",
    "            .map { it.copy(data = it.data.copy(offGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, false))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"i\" }\n",
    "        .map { it.copy(data = it.data.copy(offGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, false))) }\n",
    "\n",
    "    return baseVowels + nasalVowels + longVowels + wOnGlides + jOnGlides + wOffGlides + jOffGlides\n",
    "}\n",
    "\n",
    "for (_1 in 0..10) {\n",
    "    println(generateVowels().map { it.display })\n",
    "}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i, u, e, o, a, ao̯]\r\n",
      "[i, u, e, o, a]\r\n",
      "[i, u, ɪ, o, ɛ, a]\r\n",
      "[i, u, e, ɛ, a, ĩ, ũ, ẽ, ɛ̃, ã]\r\n",
      "[i, u, ɪ, ɛ, æ, a, ĩ, ũ, ã, iː, uː, ɪː, ɛː, aː, ĩː, ũː, ãː]\r\n",
      "[i, u, e, o, ɛ, a]\r\n",
      "[i, u, e, o, a, iː, uː, eː, oː, aː]\r\n",
      "[i, u, e, a, io̯, uo̯, eo̯, ao̯]\r\n",
      "[i, o, ɛ, a]\r\n",
      "[i, u, e, o, a, ĩ, ũ, ẽ, õ, ã]\r\n",
      "[i, u, e, a, ĩ, ũ, ẽ, ã, u̯e]\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T22:51:43.769113200Z",
     "start_time": "2025-12-18T22:51:43.432518400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val allGlides = SyllableConstructor.segments.values\n",
    "    .filter { it.data.place != Place.GLOTTAL }\n",
    "    .filter {\n",
    "        it.data.manner in listOf(\n",
    "            Manner.FRICATIVE,\n",
    "            Manner.SEMIVOWEL,\n",
    "            Manner.LIQUID\n",
    "        )\n",
    "    }.flatMap { listOf(Glide.from(it.data, false), Glide.from(it.data, true)) }\n",
    "    .toSet()\n",
    "    .plus(null)\n",
    "\n",
    "data class ConsonantSlot(\n",
    "    val manner: Set<Manner> = Manner.values().toSet(),\n",
    "    val place: Set<Place> = Place.values().toSet(),\n",
    "    val voiced: Set<Boolean?> = setOf(true, false, null),\n",
    "    val consonantGlide: Set<Glide?> = allGlides.filter { it?.manner == Manner.FRICATIVE || it?.manner == null }.toSet(),\n",
    "    val offGlide: Set<Glide?> = allGlides.filter { it?.manner != Manner.FRICATIVE }.toSet()\n",
    ") {\n",
    "    fun getMatching(segments: List<Segment>) = segments.filter {\n",
    "        it.data.type == SegmentType.CONSONANT &&\n",
    "                it.data.manner in manner &&\n",
    "                it.data.place in place &&\n",
    "                it.data.voiced in voiced &&\n",
    "                it.data.consonantGlide in consonantGlide &&\n",
    "                it.data.offGlide in offGlide\n",
    "    }\n",
    "\n",
    "    companion object\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T22:51:44.844008700Z",
     "start_time": "2025-12-18T22:51:44.699292100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlin.random.nextInt\n",
    "\n",
    "fun (ConsonantSlot.Companion).gen(consonants: List<Segment>): ConsonantSlot {\n",
    "    val mainCandidates = (1..random.nextInt(1..2)).map { consonants.random() }\n",
    "    val secondaryCandidates = (1..random.nextInt(1..3)).map { consonants.random() }\n",
    "\n",
    "    return ConsonantSlot(\n",
    "        manner = mainCandidates.map { it.data.manner!! }.toSet(),\n",
    "        place = (mainCandidates + secondaryCandidates).map { it.data.place!! }.toSet(),\n",
    "        voiced = (mainCandidates + secondaryCandidates).map { it.data.voiced }.toSet(),\n",
    "        consonantGlide = mainCandidates.map { it.data.consonantGlide }.plus(null).toSet(),\n",
    "        offGlide = mainCandidates.map { it.data.offGlide }.plus(null).toSet()\n",
    "    )\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:41.811438800Z",
     "start_time": "2025-12-18T12:25:41.691592700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// adapted from: https://gist.github.com/erikhuizinga/d2ca2b501864df219fd7f25e4dd000a4\n",
    "\n",
    "import kotlin.reflect.KFunction\n",
    "\n",
    "/**\n",
    " * Create the cartesian product of any number of sets of any size. Useful for parameterized tests\n",
    " * to generate a large parameter space with little code. Note that any type information is lost, as\n",
    " * the returned set contains list of any combination of types in the input set.\n",
    " *\n",
    " * @param sets The sets.\n",
    " */\n",
    "fun <T> cartesianProduct(vararg sets: Set<T>) =\n",
    "    sets\n",
    "        .fold(listOf(listOf<T>())) { acc, set ->\n",
    "            acc.flatMap { list -> set.map { element -> list + element } }\n",
    "        }\n",
    "        .toSet()\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:28.311562400Z",
     "start_time": "2025-12-19T05:15:27.725177700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun isSonoritySequenced(cluster: List<ConsonantSlot>, isOnset: Boolean): Boolean = when {\n",
    "    isOnset -> cluster\n",
    "        .windowed(size = 2) { (a, b) ->\n",
    "            a.manner.minOf { it.ordinal } >= b.manner.maxOf { it.ordinal } &&\n",
    "                    (a.manner.maxOf { it.ordinal } < Manner.PLOSIVE.ordinal || b.manner.maxOf { it.ordinal } < Manner.PLOSIVE.ordinal)\n",
    "        }\n",
    "        .all { it }\n",
    "    else -> isSonoritySequenced(cluster.reversed(), !isOnset)\n",
    "}\n",
    "\n",
    "typealias Cluster = List<ConsonantSlot>\n",
    "\n",
    "fun generateClusters(\n",
    "    onsetMaxConsonants: Int,\n",
    "    codaMaxConsonants: Int,\n",
    "    fallOff: Double,\n",
    "    sonoritySequencingStrictness: Double,\n",
    "    consonants: List<Segment>\n",
    "): Pair<List<Cluster>, List<Cluster>> {\n",
    "    val onsetClusters = mutableListOf<List<ConsonantSlot>>(\n",
    "        listOf(\n",
    "            ConsonantSlot(\n",
    "                manner = consonants.mapNotNull { it.data.manner }.toSet(),\n",
    "                place = consonants.mapNotNull { it.data.place }.toSet(),\n",
    "                voiced = consonants.map { it.data.voiced }.toSet(),\n",
    "                consonantGlide = consonants.map { it.data.consonantGlide }.toSet(),\n",
    "                offGlide = consonants.map { it.data.offGlide }.toSet()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    val codaClusters = mutableListOf<List<ConsonantSlot>>(listOf())\n",
    "\n",
    "    if (random.nextDouble() < 0.98) onsetClusters.add(listOf())\n",
    "\n",
    "    for (i in 2..onsetMaxConsonants) {\n",
    "        val attempts = max(1.0, onsetMaxConsonants - i * fallOff + random.nextDouble(-2.0, 1.0)).roundToInt()\n",
    "        for (_j in 1..attempts) {\n",
    "            while (true) {\n",
    "                val newCluster =\n",
    "                    if (i >= 3 && random.nextDouble() < 0.5)\n",
    "                        listOf(ConsonantSlot.gen(consonants)) + onsetClusters.filter { it.size == i - 1 }.random()\n",
    "                    else (1..i).map { ConsonantSlot.gen(consonants) }\n",
    "                if (random.nextDouble() < sonoritySequencingStrictness.pow(1.0 / i) &&\n",
    "                    !isSonoritySequenced(newCluster, true)\n",
    "                ) continue\n",
    "                if (newCluster.any { it.getMatching(consonants).isEmpty() }) continue\n",
    "\n",
    "                onsetClusters.add(newCluster)\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for (i in 1..codaMaxConsonants) {\n",
    "        val attempts = max(1.0, codaMaxConsonants - i * fallOff + random.nextDouble(-2.0, 1.0)).roundToInt()\n",
    "        for (_j in 1..attempts) {\n",
    "            val mustBeSonoritySequenced = random.nextDouble() < sonoritySequencingStrictness\n",
    "            while (true) {\n",
    "                val newCluster = if (i >= 3 && random.nextDouble() < 0.5)\n",
    "                    codaClusters.filter { it.size == i - 1 }.random().plus(ConsonantSlot.gen(consonants))\n",
    "                else (1..i).map { ConsonantSlot.gen(consonants) }\n",
    "                if (mustBeSonoritySequenced && !isSonoritySequenced(newCluster, false)) {\n",
    "                    continue\n",
    "                }\n",
    "                if (newCluster.any { it.getMatching(consonants).isEmpty() }) continue\n",
    "\n",
    "                codaClusters.add(newCluster)\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return onsetClusters to codaClusters\n",
    "}\n",
    "\n",
    "data class Syllable(val onset: List<Segment>, val nucleus: List<Segment>, val coda: List<Segment>, val tone: Segment? = null) {\n",
    "    val allConsonants by lazy { onset + coda }\n",
    "    val length get() = onset.size + nucleus.size + coda.size\n",
    "    override fun toString() =\n",
    "        \"${onset.joinToString(\"\") { it.display }}${nucleus.joinToString(\"\") { it.display }}${coda.joinToString(\"\") { it.display }}\"\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:29.166188600Z",
     "start_time": "2025-12-19T05:15:28.333236100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.SyllableConstructor\n",
    "import kotlin.reflect.KProperty1\n",
    "\n",
    "class SyllableRule(val name: String, val tag: String = \"\", val check: (Syllable) -> Boolean)\n",
    "\n",
    "class Prop<T, U>(val name: String, val get: (T) -> U) {\n",
    "    constructor(prop: KProperty1<T, U>) : this(prop.name, prop)\n",
    "}\n",
    "\n",
    "fun generateSyllableRules(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    maxOnset: Int,\n",
    "    maxCoda: Int\n",
    "): List<SyllableRule> {\n",
    "    val rules = mutableListOf<SyllableRule>()\n",
    "\n",
    "    class SidedRule(val segment: Segment, val allowedInOnset: Boolean, val allowedInCoda: Boolean)\n",
    "\n",
    "    val possibleOnsetClusters = onsetClusters.map { cluster -> cluster.flatMap { it.getMatching(consonants) } }\n",
    "    val possibleCodaClusters = codaClusters.map { cluster -> cluster.flatMap { it.getMatching(consonants) } }\n",
    "//    val allPossibleOnsets = possibleOnsetClusters.flatten().toSet()\n",
    "    val allPossibleCodas = possibleCodaClusters.flatten().toSet()\n",
    "\n",
    "    if (maxOnset > 0 && maxCoda > 0) {\n",
    "//        val isRareRestrictive = random.nextDouble() < 0.33\n",
    "        val sidedPhonemeRules = consonants\n",
    "            .filter { consonant -> (possibleOnsetClusters + possibleOnsetClusters).none { it.size == 1 && it.first() == consonant } }\n",
    "            .map { consonant ->\n",
    "                when (consonant.display[0]) {\n",
    "                    in \"ŋɳ\" -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.7 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.65 && consonant in allPossibleOnsets -> SidedRule(consonant, true, false)\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                    in \"ptkmnlr\" -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.97 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.85 && consonant in allPossibleOnsets -> SidedRule(consonant, true, false)\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                    else -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.95 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.85 || isRareRestrictive && consonant in allPossibleOnsets -> SidedRule(\n",
    "//                                consonant,\n",
    "//                                true,\n",
    "//                                false\n",
    "//                            )\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }.filter { !it.allowedInOnset || !it.allowedInCoda }.map { rule ->\n",
    "                SyllableRule(\"${rule.segment.display} Sidedness (${rule.allowedInOnset}-${rule.allowedInCoda})\") {\n",
    "                    (rule.segment !in it.onset || rule.allowedInOnset) &&\n",
    "                            (rule.segment !in it.coda || rule.allowedInCoda)\n",
    "                }\n",
    "            }\n",
    "        rules.addAll(sidedPhonemeRules)\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.99 && maxOnset > 1 || maxCoda > 1) {\n",
    "        rules.add(SyllableRule(\"Offglide-Glide Adjacency\") { syllable ->\n",
    "            listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                cluster.windowed(size = 2) { (a, b) ->\n",
    "                    a.data.offGlide == null\n",
    "                            || a.data.offGlide!!.manner != Manner.SEMIVOWEL\n",
    "                            || a.data.offGlide!!.place != b.data.place\n",
    "                }.all { it }\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.8 && consonants.any { it.data.manner == Manner.SEMIVOWEL }) {\n",
    "        rules.add(SyllableRule(\"Semivowel-Vowel Adjacency\") { syllable ->\n",
    "            val onset = syllable.onset.size == 0 ||\n",
    "                    (syllable.onset.last().symbol != \"w\" || syllable.nucleus.first().symbol != \"u\") &&\n",
    "                    (syllable.onset.last().symbol != \"j\" || syllable.nucleus.first().symbol != \"i\")\n",
    "\n",
    "            val coda = syllable.coda.size == 0 ||\n",
    "                    (syllable.coda.first().symbol != \"w\" || syllable.nucleus.last().symbol != \"u\") &&\n",
    "                    (syllable.coda.first().symbol != \"j\" || syllable.nucleus.last().symbol != \"i\")\n",
    "            onset && coda\n",
    "        })\n",
    "    }\n",
    "\n",
    "    while (random.nextDouble() <= 0.33) {\n",
    "        val place = listOf(Syllable::onset, Syllable::coda, Syllable::allConsonants).random()\n",
    "        val consonantFeature = listOf(SegmentData::place, SegmentData::manner, SegmentData::voiced).random()\n",
    "        val vowelFeatures = listOf(\n",
    "            Prop(SegmentData::onGlide),\n",
    "            Prop(SegmentData::offGlide),\n",
    "            Prop(SegmentData::nasalized),\n",
    "            Prop(SegmentData::lengthened),\n",
    "            Prop(SegmentData::rounded),\n",
    "            Prop<SegmentData, Boolean>(\"isHigh\") { it.isHigh },\n",
    "            Prop<SegmentData, Boolean>(\"isLow\") { it.isLow },\n",
    "            Prop<SegmentData, Boolean>(\"isBackward\") { it.isBackward },\n",
    "            Prop<SegmentData, Boolean>(\"isFrontward\") { it.isFrontward },\n",
    "        ).filter { feature -> vowels.groupBy { feature.get(it.data) }.size > 1 }\n",
    "        if (vowelFeatures.isEmpty()) break\n",
    "        val vowelFeature = vowelFeatures.random()\n",
    "        val modelConsonant = consonants.random()\n",
    "        val modelVowel = vowels.random()\n",
    "        val vowelSet = vowels.filter { vowelFeature.get(it.data) == vowelFeature.get(modelVowel.data) }\n",
    "\n",
    "        rules.add(\n",
    "            SyllableRule(\n",
    "                \"${consonantFeature.name} ${consonantFeature.get(modelConsonant.data)} consonants cannot co-occur with {${vowelSet.joinToString { it.display }}} in ${place.name}\"\n",
    "            ) { syllable ->\n",
    "                place.get(syllable)\n",
    "                    .none { consonant -> consonantFeature.get(consonant.data) == consonantFeature.get(modelConsonant.data) } ||\n",
    "                        syllable.nucleus.none { vowel -> vowel in vowelSet }\n",
    "            })\n",
    "    }\n",
    "\n",
    "    if (vowels.any { it.data.nasalized == true }\n",
    "        && consonants.any { it.data.manner == Manner.NASAL }\n",
    "        && random.nextDouble() <= 0.5\n",
    "    ) random.nextDouble().let {\n",
    "        val onsetNasal =\n",
    "            onsetClusters.any { it.size > 0 && (Manner.NASAL in it.last().manner || it.last().offGlide.any { it?.manner == Manner.NASAL }) }\n",
    "        val codaNasal =\n",
    "            codaClusters.any { it.size > 0 && Manner.NASAL in it.first().manner }\n",
    "        when {\n",
    "            it <= 0.33 && onsetNasal && codaNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } ==\n",
    "                            (syllable.onset.lastOrNull()?.data?.manner == Manner.NASAL\n",
    "                                    || syllable.onset.lastOrNull()?.data?.offGlide?.manner == Manner.NASAL\n",
    "                                    || syllable.coda.lastOrNull()?.data?.manner == Manner.NASAL)\n",
    "                })\n",
    "            it <= 0.66 && codaNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals (Coda)\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } == (syllable.coda.firstOrNull()?.data?.manner == Manner.NASAL)\n",
    "                })\n",
    "            onsetNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals (Onset)\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } ==\n",
    "                            (syllable.onset.lastOrNull()?.data?.manner == Manner.NASAL\n",
    "                                    || syllable.onset.lastOrNull()?.data?.offGlide?.manner == Manner.NASAL)\n",
    "                })\n",
    "            else -> {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (maxOnset > 1 || maxCoda > 1) {\n",
    "        // needs probability analysis\n",
    "        if (random.nextDouble() <= 0.95) {\n",
    "            rules.add(SyllableRule(\"Homorganic Consonant Voicing\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                    cluster.windowed(size = 2) { (a, b) -> a.data.voiced == b.data.voiced || a.data.voiced == null || b.data.voiced == null }\n",
    "                        .all { it }\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "\n",
    "        // geminate consonants should be represented phonemically or via cross-syllable rules\n",
    "        rules.add(SyllableRule(\"No Geminate Consonants\") { syllable ->\n",
    "            listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                cluster.windowed(size = 2) { (a, b) -> a.display.last() != b.display.first() && a.symbol != b.symbol && a.data != b.data }\n",
    "                    .all { it }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        // needs probability analysis\n",
    "        if (random.nextDouble() <= 0.95) {\n",
    "            rules.add(SyllableRule(\"All Offglides must be Cluster-final\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda)\n",
    "                    .all { cluster ->\n",
    "                        cluster.size <= 1 || cluster.take(cluster.size - 1)\n",
    "                            .all { it.data.consonantGlide == null || it.data.consonantGlide?.manner == Manner.FRICATIVE }\n",
    "                    }\n",
    "            })\n",
    "        }\n",
    "\n",
    "        // needs probability analysis\n",
    "        while (random.nextDouble() <= 0.66) {\n",
    "            val manners = (onsetClusters + codaClusters)\n",
    "                .filter { it.size >= 2 }.random()\n",
    "                .windowed(size = 2).random()\n",
    "                .map { it.manner.random() }\n",
    "                .sortedByDescending { it.ordinal }\n",
    "\n",
    "            if (manners[0] == manners[1]) {\n",
    "                continue\n",
    "            }\n",
    "\n",
    "            rules.add(SyllableRule(\"Homorganic ${manners[0]}-${manners[1]} Consonant Placing\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                    cluster.windowed(size = 2) { (a, b) -> a.data.place == b.data.place || a.data.manner !in manners || b.data.manner !in manners }\n",
    "                        .all { it }\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return rules.distinctBy { it.name }\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:29.391624500Z",
     "start_time": "2025-12-19T05:15:29.218946400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun generateSyllable(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    syllableRules: List<SyllableRule> = listOf()\n",
    "): Syllable {\n",
    "    while (true) {\n",
    "        val onset = onsetClusters.random()\n",
    "        val nucleus = vowels.random()\n",
    "        val coda = codaClusters.random()\n",
    "\n",
    "        val syllable = Syllable(\n",
    "            onset.map { it.getMatching(consonants).random() },\n",
    "            listOf(nucleus),\n",
    "            coda.map { it.getMatching(consonants).random() }\n",
    "        )\n",
    "\n",
    "        if (syllableRules.all { it.check(syllable) }) return syllable\n",
    "    }\n",
    "}\n",
    "\n",
    "fun generateAllSyllables(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    syllableRules: List<SyllableRule>\n",
    "): List<Syllable> {\n",
    "    val allOnsetClusters = onsetClusters.flatMap { cluster ->\n",
    "        cartesianProduct(*cluster.map { slot ->\n",
    "            slot.getMatching(consonants)\n",
    "                .toSet()\n",
    "        }.toTypedArray())\n",
    "    }.toSet()\n",
    "\n",
    "    val allCodaClusters = codaClusters.flatMap { cluster ->\n",
    "        cartesianProduct(*cluster.map { slot ->\n",
    "            slot.getMatching(consonants)\n",
    "                .toSet()\n",
    "        }.toTypedArray())\n",
    "    }.toSet()\n",
    "\n",
    "    return cartesianProduct(\n",
    "        allOnsetClusters,\n",
    "        vowels.map { listOf(it) }.toSet(),\n",
    "        allCodaClusters\n",
    "    ).map { (onset, nucleus, coda) ->\n",
    "        Syllable(onset, nucleus, coda)\n",
    "    }.filter { syllable -> syllableRules.all { it.check(syllable) } }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:29.728122100Z",
     "start_time": "2025-12-19T05:15:29.420875500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.UtilityExtensions.formatDigits\n",
    "\n",
    "fun weighSyllables(consonants: List<Segment>, vowels: List<Segment>, syllables: List<Syllable>): Map<Syllable, Double> {\n",
    "    fun (Segment).glideCount() = listOf(\n",
    "        this.data.onGlide,\n",
    "        this.data.offGlide,\n",
    "        this.data.consonantGlide\n",
    "    ).count { it != null }\n",
    "\n",
    "    fun weighSegments(segments: List<Segment>): Map<Segment, Double> {\n",
    "        val segmentOrdering =\n",
    "            segments.sortedByDescending { it.prevalence + (random.nextDouble().pow(2) - 0.5) }\n",
    "        val offset = random.nextDouble(1.5, 3.5)\n",
    "        val power = random.nextDouble(0.7, 1.3)\n",
    "        val segmentWeights = segmentOrdering.withIndex().associate { (index, segment) ->\n",
    "            segment to 1.0 / (index + offset).pow(power)\n",
    "        }\n",
    "\n",
    "        return segmentWeights\n",
    "    }\n",
    "\n",
    "    val consonantWeights = weighSegments(consonants)\n",
    "    val vowelWeights = weighSegments(vowels)\n",
    "\n",
    "    println(\"top consonants: ${consonantWeights.entries.sortedByDescending { it.value }.take(10).joinToString(\", \") { \"${it.key.display} (${it.value.formatDigits(2)})\" }}\")\n",
    "    println(\"top vowels: ${vowelWeights.entries.sortedByDescending { it.value }.take(10).joinToString(\", \") { \"${it.key.display} (${it.value.formatDigits()})\" }}\")\n",
    "\n",
    "    fun (Segment).complexity() = 1 + this.glideCount() +\n",
    "            (if (this.data.lengthened == true) 1 else 0) +\n",
    "            (if (this.data.nasalized == true) 1 else 0)\n",
    "\n",
    "    fun (Syllable).complexity() = (\n",
    "            (if (this.onset.size == 0) 1 else this.onset.sumOf { it.complexity() }) +\n",
    "                    this.nucleus.sumOf { it.complexity() } +\n",
    "                    this.coda.sumOf { it.complexity() }) *\n",
    "            max(1, this.length - 1)\n",
    "\n",
    "    return syllables.associateWith { syllable ->\n",
    "        val baseWeight = (syllable.onset.fold(1.0) { acc, it -> acc * consonantWeights.getValue(it) } +\n",
    "                syllable.nucleus.fold(1.0) { acc, it -> acc * vowelWeights.getValue(it) } +\n",
    "                syllable.coda.fold(1.0) { acc, it -> acc * consonantWeights.getValue(it) })\n",
    "        val nullOnsetAdjustment = if (syllable.onset.isEmpty()) consonantWeights.values.random() else 1.0\n",
    "        baseWeight * nullOnsetAdjustment * random.nextDouble(0.5, 1.5) / syllable.complexity().toDouble()\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:30.372029400Z",
     "start_time": "2025-12-19T05:15:29.787061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Depth\n",
    "\n",
    "class WordTransformation(val name: String, val tag: String = \"\", val transform: (List<Syllable>) -> List<Syllable>)\n",
    "\n",
    "fun generateWordTransformations(\n",
    "    syllables: List<Syllable>,\n",
    "): List<WordTransformation> {\n",
    "    val consonants = syllables.flatMap { it.allConsonants }.toSet()\n",
    "    val vowels = syllables.flatMap { it.nucleus }.toSet()\n",
    "    val onsetClusters = syllables.map { it.onset }.toSet()\n",
    "//    val codaClusters = syllables.map { it.coda }.toSet()\n",
    "\n",
    "    val transformations = mutableListOf<WordTransformation>()\n",
    "\n",
    "    val glottalStop = SyllableConstructor.segments[\"ʔ\"]!!\n",
    "    if (random.nextDouble() <= 0.25\n",
    "        && onsetClusters.any { it.size == 0 }\n",
    "    ) {\n",
    "        transformations.add(WordTransformation(\"Add glottal stops to word-initial vowels\") { syllables ->\n",
    "            val first = syllables.first()\n",
    "            if (first.onset.isNotEmpty()) syllables else listOf(\n",
    "                first.copy(onset = listOf(glottalStop).plus(first.onset.drop(1)))\n",
    "            ).plus(syllables.drop(1))\n",
    "        })\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.25 && vowels.size >= 6) {\n",
    "        val vowelFeatures =\n",
    "            listOf(\n",
    "                Prop(SegmentData::depth),\n",
    "                Prop(SegmentData::height),\n",
    "                Prop(SegmentData::nasalized),\n",
    "                Prop(SegmentData::rounded),\n",
    "                Prop<SegmentData, Boolean>(\"isHigh\") { it.isHigh },\n",
    "                Prop<SegmentData, Boolean>(\"isLow\") { it.isLow },\n",
    "                Prop<SegmentData, Boolean>(\"isBackward\") { it.isBackward },\n",
    "                Prop<SegmentData, Boolean>(\"isFrontward\") { it.isFrontward },\n",
    "            ).associateWith { feature -> vowels.groupBy { feature.get(it.data) }.values.filter { it.size > 3 } }\n",
    "                .filterValues { featureGroups -> featureGroups.size == 2 }\n",
    "\n",
    "        if (vowelFeatures.isNotEmpty()) {\n",
    "            val (chosenFeature, groups) = vowelFeatures.entries.random()\n",
    "            val (firstGroup, secondGroup) = groups\n",
    "\n",
    "            val foreMap = firstGroup.associateWith { first -> secondGroup.minBy { first.vowelDistanceTo(it) } }\n",
    "            val aftMap = secondGroup.associateWith { second -> firstGroup.minBy { second.vowelDistanceTo(it) } }\n",
    "\n",
    "            transformations.add(WordTransformation(\"Vowel harmony via ${chosenFeature.name}\") { syllables ->\n",
    "                val primaryVowel = (syllables\n",
    "                    .firstOrNull { syllable -> syllable.nucleus.any { it.data.lengthened == true || it.data.onGlide != null || it.data.offGlide != null } }\n",
    "                    ?: syllables.first()).nucleus.first()\n",
    "\n",
    "                when (primaryVowel) {\n",
    "                    in firstGroup -> syllables.map { syllable ->\n",
    "                        syllable.copy(nucleus = syllable.nucleus.map {\n",
    "                            aftMap[it] ?: it\n",
    "                        })\n",
    "                    }\n",
    "                    in secondGroup -> syllables.map { syllable ->\n",
    "                        syllable.copy(nucleus = syllable.nucleus.map {\n",
    "                            foreMap[it] ?: it\n",
    "                        })\n",
    "                    }\n",
    "                    else -> syllables\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.25) {\n",
    "        transformations.add(WordTransformation(\"Interject glottal stop between adjacent vowels\", \"intervocalic_glottal_stop\") { syllables ->\n",
    "            syllables.drop(1).fold(syllables.take(1)) { acc, syllable ->\n",
    "                if (acc.last().coda.isEmpty() && syllable.onset.isEmpty()) {\n",
    "                    acc.plus(syllable.copy(onset = listOf(glottalStop)))\n",
    "                } else acc.plus(syllable)\n",
    "            }\n",
    "        })\n",
    "    } else {\n",
    "        transformations.add(WordTransformation(\"Elide adjacent identical vowels\") { syllables ->\n",
    "            syllables.drop(1).fold(syllables.take(1)) { acc, syllable ->\n",
    "                val lastVowel = acc.last().nucleus.last()\n",
    "                val trueLastVowel =\n",
    "                    if (lastVowel.data.offGlide != null) lastVowel.data.offGlide.vowel(false)!! else lastVowel\n",
    "                val nextVowel = syllable.nucleus.first()\n",
    "                val trueNextVowel =\n",
    "                    if (nextVowel.data.onGlide != null) nextVowel.data.onGlide.vowel(true)!! else nextVowel\n",
    "                if (acc.last().coda.isEmpty()\n",
    "                    && syllable.onset.isEmpty()\n",
    "                    && (trueLastVowel.data.depth == trueNextVowel.data.depth\n",
    "                            && trueLastVowel.data.height == trueNextVowel.data.height\n",
    "                            && trueLastVowel.data.rounded == trueNextVowel.data.rounded)\n",
    "                ) {\n",
    "                    val canLengthen = vowels.any { it.data.lengthened == true }\n",
    "                    acc.dropLast(1).plus(\n",
    "                        acc.last()\n",
    "                            .copy(\n",
    "                                nucleus = if (canLengthen) syllable.nucleus.map { it.copy(data = it.data.copy(lengthened = true)) }\n",
    "                                else syllable.nucleus,\n",
    "                                coda = syllable.coda\n",
    "                            )\n",
    "                    )\n",
    "                } else acc.plus(syllable)\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    return transformations.toList()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:15:30.421882300Z",
     "start_time": "2025-12-19T05:15:30.382069600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.WeightedBag\n",
    "\n",
    "fun generateWord(\n",
    "    length: Int,\n",
    "    syllableBag: WeightedBag<Syllable>,\n",
    "    wordTransformations: List<WordTransformation>\n",
    "): List<Syllable> {\n",
    "    return wordTransformations\n",
    "        .fold((1..length).map { syllableBag.grab()!! }) { syllables, transformation ->\n",
    "            transformation.transform(\n",
    "                syllables\n",
    "            )\n",
    "        }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T08:58:32.223310700Z",
     "start_time": "2025-12-19T08:58:29.059513100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Letter(val lowerCase: String, val titleCase: String, val upperCase: String, val search: String) {\n",
    "    constructor (lowerCase: String, search: String = lowerCase) : this(\n",
    "        lowerCase,\n",
    "        lowerCase.uppercase(),\n",
    "        lowerCase.uppercase(),\n",
    "        search\n",
    "    )\n",
    "\n",
    "    constructor (lowerCase: String, upperCase: String, search: String = upperCase) : this(\n",
    "        lowerCase,\n",
    "        upperCase,\n",
    "        upperCase,\n",
    "        search\n",
    "    )\n",
    "}\n",
    "\n",
    "class EnglishOrthographyConfig(\n",
    "    val enableDiacritics: Boolean = true,\n",
    "    val enableDiaresis: Boolean = true,\n",
    "    val enableLigatures: Boolean = true,\n",
    "    val enableToneMarkers: Boolean = false,\n",
    "    val enableComplexSyllables: Boolean = false,\n",
    "    val enableSpecialCharacters: Boolean = false,\n",
    ")\n",
    "\n",
    "fun flip() = random.nextDouble() < 0.5\n",
    "\n",
    "// this is an absolute awful rat's nest. welcome to English vowels!\n",
    "fun generateEnglishOrthography(\n",
    "    syllables: List<Syllable>,\n",
    "    syllableRules: List<SyllableRule>,\n",
    "    wordTransformations: List<WordTransformation>,\n",
    "    config: EnglishOrthographyConfig = EnglishOrthographyConfig()\n",
    "): (List<Syllable>) -> (String) {\n",
    "    val consonants = syllables.flatMap { it.allConsonants }.toSet()\n",
    "    val vowels = syllables.flatMap { it.nucleus }.toSet()\n",
    "    val tones = syllables.mapNotNull { it.tone }.toSet()\n",
    "    val segments = consonants + vowels\n",
    "\n",
    "    val vowelGroups = vowels\n",
    "        .map { it.copy(data = it.data.copy(onGlide = null, offGlide = null)) }\n",
    "        .groupBy { it.copy(data = it.data.copy(nasalized = false, lengthened = false)) }\n",
    "\n",
    "    val baseVowels = vowelGroups.values\n",
    "        .map { it.minBy { (if (it.data.nasalized == true) 2 else 0) + (if (it.data.lengthened == true) 1 else 0) } }\n",
    "\n",
    "    val baseLetters = mutableMapOf<String, Letter>()\n",
    "\n",
    "    fun moreVowelsRequired() = baseVowels.any { it.symbol !in baseLetters }\n",
    "\n",
    "    val yOffGliders =\n",
    "        segments.filter { it.data.offGlide?.manner == Manner.SEMIVOWEL && it.data.offGlide?.place == Place.PALATAL }\n",
    "    val yOnGliders =\n",
    "        segments.filter { it.data.onGlide?.manner == Manner.SEMIVOWEL && it.data.onGlide?.place == Place.PALATAL }\n",
    "    val vocalicYAvailable =\n",
    "        yOnGliders.isEmpty() && yOffGliders.isEmpty() && consonants.none { it.symbol == \"j\" } // $$$ OR j is mapped to j\n",
    "\n",
    "    val requiresNasalMarking = (syllableRules.none { it.tag == \"restricted_nasal_vowels\" }\n",
    "            && vowelGroups.any { it.value.map { it.data.nasalized }.distinct().count() > 1 })\n",
    "    val nasalDiacriticDesired =\n",
    "        requiresNasalMarking && syllables.any { it.coda.firstOrNull()?.data?.manner == Manner.NASAL }\n",
    "    val requiresLengthMarking = vowelGroups.any { it.value.map { it.data.lengthened }.distinct().count() > 1 }\n",
    "\n",
    "    // if this was the ONLY vowel, what letter would it have? ordered by priority\n",
    "    val preferredVowels = mapOf(\n",
    "        \"ɪ\" to \"i\",\n",
    "        \"i\" to \"i\",\n",
    "\n",
    "        \"ɛ\" to if (config.enableSpecialCharacters && flip()) \"ɛ,e\" else \"e\",\n",
    "        \"e̞\" to \"e\",\n",
    "        \"ɘ\" to \"e\",\n",
    "        \"ɜ\" to \"e\",\n",
    "        \"e\" to \"e\",\n",
    "\n",
    "        \"u\" to \"u\",\n",
    "        \"ʉ\" to if (vocalicYAvailable) \"u,y\" else \"u\",\n",
    "        \"y\" to if (vocalicYAvailable) \"y,u,i\" else \"u,i\",\n",
    "        \"ɯ\" to if (vocalicYAvailable) \"u,y\" else \"u\",\n",
    "        \"ɤ\" to \"u,e\",\n",
    "        \"ɤ̞\" to \"u,e\",\n",
    "        \"œ\" to \"u,e\" + if (config.enableLigatures && flip()) \",œ\" else \"\",\n",
    "        \"ø\" to \"u\" + if (config.enableDiacritics && flip()) \",ø\" else \"\",\n",
    "        \"ø̞\" to \"u\" + if (config.enableDiacritics && flip()) \",ø\" else \"\",\n",
    "\n",
    "        \"o\" to \"o\",\n",
    "        \"o̞\" to \"o\",\n",
    "\n",
    "        \"ɵ\" to \"o\",\n",
    "\n",
    "        \"a\" to \"a\",\n",
    "        \"ɐ\" to \"a\",\n",
    "        \"ä\" to \"a\",\n",
    "        \"ɑ\" to \"a\",\n",
    "        \"ɒ\" to \"a\",\n",
    "        \"ʌ\" to \"a\",\n",
    "        \"æ\" to \"a\" + if (config.enableLigatures) \",æ\" else \"\",\n",
    "        \"ɞ\" to \"a\",\n",
    "\n",
    "        \"ʏ\" to if (vocalicYAvailable) \"y,u,i\" else \"u,i\",\n",
    "        \"ɔ\" to \"o,a\",\n",
    "        \"ʊ\" to \"u,o\",\n",
    "        \"ɨ\" to \"u,i\",\n",
    "        \"ɶ\" to \"u,a\",\n",
    "        \"ə\" to \"e,u,o,a,i\",\n",
    "    )\n",
    "\n",
    "    preferredVowels.keys\n",
    "        .filter { vowel -> baseVowels.any { it.symbol == vowel } }\n",
    "        .forEach { vowel ->\n",
    "            val options = preferredVowels[vowel]!!.split(\",\")\n",
    "            val chosen = options.firstOrNull { option -> baseLetters.values.none { option in it.lowerCase } }\n",
    "            if (chosen != null) {\n",
    "                baseLetters[vowel] = Letter(chosen)\n",
    "            }\n",
    "        }\n",
    "\n",
    "//    val hasPolyphthongs = vowels.any { it.data.offGlide != null || it.data.onGlide != null }\n",
    "    val adjacentVowelsPossible =\n",
    "        wordTransformations.none { it.tag == \"intervocalic_glottal_stop\" } && syllables.any { it.onset.size == 0 }\n",
    "    val useDiaresis = config.enableDiaresis && adjacentVowelsPossible && flip()\n",
    "    val canDigraphVowels = !adjacentVowelsPossible || useDiaresis\n",
    "    val noCodaH = syllables.none { it.coda.firstOrNull()?.symbol == \"h\" }\n",
    "\n",
    "    val shouldDigraphVowels = canDigraphVowels && (listOf(\n",
    "        useDiaresis,\n",
    "        nasalDiacriticDesired && config.enableDiacritics,\n",
    "        requiresLengthMarking,\n",
    "        tones.isNotEmpty()\n",
    "    ).count { it } <= 2) && flip()\n",
    "    val lengthDiacriticDesired = config.enableDiacritics && requiresLengthMarking && (shouldDigraphVowels || flip())\n",
    "\n",
    "    // worst case: diaresis + long + nasal + tone + diff\n",
    "    // no digraphs: nasal + tone + diff\n",
    "\n",
    "    val weakI = baseVowels.firstOrNull { it.symbol == \"ɪ\" } ?: baseVowels.firstOrNull { it.symbol == \"ʏ\" }\n",
    "    val strongI = baseVowels.firstOrNull { it.symbol == \"i\" } ?: baseVowels.firstOrNull { it.symbol == \"ɨ\" }\n",
    "    if (weakI != null && strongI != null) {\n",
    "        if ((shouldDigraphVowels || noCodaH) && (flip() || !config.enableDiacritics)) {\n",
    "            if ((!noCodaH || flip()) && !requiresLengthMarking) {\n",
    "                baseLetters[weakI.symbol] = Letter(\"i\")\n",
    "                baseLetters[strongI.symbol] = Letter(\"ee\", \"Ee\", \"EE\")\n",
    "            } else if (noCodaH) {\n",
    "                baseLetters[weakI.symbol] = Letter(\"ih\", \"Ih\", \"IH\")\n",
    "                baseLetters[strongI.symbol] = Letter(\"i\")\n",
    "            }\n",
    "        } else if (config.enableDiacritics) {\n",
    "            baseLetters[weakI.symbol] =\n",
    "                if (config.enableSpecialCharacters && random.nextDouble() <= 0.1) Letter(\"ɪ\", \"I\")\n",
    "                else Letter(\"ı\", \"I\")\n",
    "            baseLetters[strongI.symbol] = Letter(\"i\", \"İ\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val schwaLike = \"ə,ɘ,ɜ,ɐ,ɞ,ɤ,œ\".split(\",\")\n",
    "    val unallocatedSchwa =\n",
    "        schwaLike.firstOrNull { schwa -> schwa !in baseLetters && baseVowels.any { it.symbol == schwa } }\n",
    "    if (unallocatedSchwa != null && noCodaH) {\n",
    "        baseLetters[unallocatedSchwa] = Letter(\"uh\", \"Uh\", \"UH\")\n",
    "    }\n",
    "\n",
    "    val aLike = \"æ,a,ɐ,ä,ɑ,ɶ\".split(\",\")\n",
    "    val includedALike = aLike\n",
    "        .filter { a -> baseVowels.any { it.symbol == a } }\n",
    "        .filter { baseLetters[it]?.lowerCase != \"æ\" }\n",
    "    val combineAllAh = !config.enableLigatures && !config.enableDiacritics\n",
    "    if (includedALike.size > 1\n",
    "        && noCodaH\n",
    "        && (combineAllAh || (flip() && includedALike.size == 2))\n",
    "    ) {\n",
    "        baseLetters[includedALike.first()] = Letter(\"a\")\n",
    "        includedALike.drop(if (combineAllAh && canDigraphVowels) 2 else 1)\n",
    "            .forEach { baseLetters[it] = Letter(\"ah\", \"Ah\", \"AH\") }\n",
    "    }\n",
    "\n",
    "    val eLike = \"e,e̞,ɛ,ɜ,ä,ɑ,ɶ\".split(\",\")\n",
    "    val includedELike = eLike\n",
    "        .filter { e -> baseVowels.any { it.symbol == e } }\n",
    "    val combineAllEh = !config.enableLigatures && !config.enableDiacritics\n",
    "    if (includedELike.size > 1\n",
    "        && noCodaH\n",
    "        && (combineAllEh || (flip() && includedELike.size == 2))\n",
    "    ) {\n",
    "        baseLetters[includedELike.first()] = Letter(\"e\")\n",
    "        includedELike.drop(if (combineAllEh && canDigraphVowels) 2 else 1)\n",
    "            .forEach { baseLetters[it] = Letter(\"eh\", \"Eh\", \"EH\") }\n",
    "    }\n",
    "\n",
    "    if (moreVowelsRequired() && shouldDigraphVowels && (flip() || !config.enableDiacritics)) {\n",
    "        val preferredVowelDigraphs = mapOf(\n",
    "            \"œ\" to \"eu\",\n",
    "            \"ø\" to \"eu\",\n",
    "            \"ʏ\" to \"eu\",\n",
    "            \"ɘ\" to \"eu\",\n",
    "            \"y\" to \"eu\",\n",
    "\n",
    "            \"ɒ\" to \"au\",\n",
    "            \"ɔ\" to \"au\",\n",
    "            \"ɶ\" to \"au\",\n",
    "            \"ʌ\" to \"au\",\n",
    "\n",
    "            \"æ\" to \"ae\",\n",
    "            \"e\" to if (yOffGliders.none { it.symbol == \"e\" }) \"ey\" else \"ae\",\n",
    "\n",
    "            \"u\" to \"ue\",\n",
    "            \"ʉ\" to \"ue\",\n",
    "            \"ɯ\" to \"ue\",\n",
    "            \"ɨ\" to \"ue\",\n",
    "        ).plus(\n",
    "            if (!lengthDiacriticDesired) mapOf(\n",
    "                \"ʊ\" to \"oo\",\n",
    "                \"ɤ\" to \"oo\",\n",
    "                \"ɤ̞\" to \"oo\",\n",
    "                \"ø\" to \"oo\",\n",
    "\n",
    "                \"ɑ\" to \"aa\",\n",
    "                \"a\" to \"aa\",\n",
    "                \"ɐ\" to \"aa\",\n",
    "                \"ä\" to \"aa\",\n",
    "            ) else mapOf()\n",
    "        )\n",
    "\n",
    "        preferredVowelDigraphs.keys\n",
    "            .filter { vowel -> baseVowels.any { it.symbol == vowel } }\n",
    "            .filter { vowel -> vowel !in baseLetters }\n",
    "            .forEach { vowel ->\n",
    "                val options = preferredVowelDigraphs[vowel]!!.split(\",\")\n",
    "                val chosen = options.firstOrNull { option -> baseLetters.values.none { option in it.lowerCase } }\n",
    "                if (chosen != null) {\n",
    "                    baseLetters[vowel] = Letter(chosen, chosen.first().uppercase() + chosen.drop(1), chosen.uppercase())\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "\n",
    "    val nasalDiacritic = if (nasalDiacriticDesired && config.enableDiacritics) listOf(\n",
    "        \"◌̃\",\n",
    "        \"◌̃\",\n",
    "        \"◌̃\",\n",
    "        \"◌̃\",\n",
    "        \"◌̐\"\n",
    "    ).plus(if (!moreVowelsRequired()) listOf(\"◌̇\", \"◌̣\") else listOf())\n",
    "        .random()[1] else null\n",
    "\n",
    "    val diaresis = if (useDiaresis) \"◌̈\"[1] else null\n",
    "    val lengthDiacritic = if (lengthDiacriticDesired) listOf(\n",
    "        \"◌̄\",\n",
    "        \"◌̄\",\n",
    "        \"◌̄\",\n",
    "        \"◌̅\",\n",
    "    ).plus(if (diaresis == null) listOf(\"◌̈\") else listOf())\n",
    "        .plus(\n",
    "            if (!moreVowelsRequired()) listOf(\n",
    "                \"◌̀\", \"◌́\", \"◌̂\", \"◌̆\", \"◌̨\", \"◌̊\"\n",
    "            ) else listOf()\n",
    "        )\n",
    "        .random()[1] else null\n",
    "\n",
    "    if (moreVowelsRequired() && config.enableDiacritics) {\n",
    "        val remainingVowels = baseVowels\n",
    "            .filter { it.symbol !in baseLetters }\n",
    "            .groupBy { preferredVowels[it.symbol]!!.split(\",\").random() }\n",
    "        val diacriticsNeeded = remainingVowels.values.maxOf { it.size }\n",
    "        val maxDiacritics =\n",
    "            listOf(useDiaresis, nasalDiacriticDesired, lengthDiacriticDesired, tones.isNotEmpty()).count { it }\n",
    "        val possibleDiacritics = (if (maxDiacritics >= 3 || random.nextDouble() < 0.33) {\n",
    "            listOf(\"◌̜\", \"◌̝\", \"◌̞\", \"◌̣\", \"◌̥̣\", \"◌̧\", \"◌̪\", \"◌̫\", \"◌̭\", \"◌̱\", \"◌̻\")\n",
    "        } else listOf()).plus(\n",
    "            if (maxDiacritics <= 2) {\n",
    "                listOf(\"◌̀\", \"◌́\", \"◌̂\", \"◌̆\", \"◌̇\", \"◌̈\", \"◌̊\", \"◌̉\")\n",
    "            } else listOf()\n",
    "        ).map { it[1] }\n",
    "\n",
    "        val selectedDiacritics = possibleDiacritics.shuffled(random).take(diacriticsNeeded)\n",
    "        remainingVowels.forEach { (baseLetter, vowels) ->\n",
    "            vowels.zip(selectedDiacritics)\n",
    "                .forEach { (vowel, diacritic) -> baseLetters[vowel.symbol] = Letter(baseLetter + diacritic) }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (moreVowelsRequired()) {\n",
    "        println(\"Ran out of options, adding ambiguous vowels.\")\n",
    "        baseVowels.filter { it.symbol !in baseLetters }\n",
    "            .forEach {\n",
    "                baseLetters[it.symbol] = Letter(preferredVowels[it.symbol]!!)\n",
    "            }\n",
    "    }\n",
    "\n",
    "    val diacriticPlaceFn = random.nextDouble().let {\n",
    "        when {\n",
    "            it < 0.25 -> ({ _: Int -> 1 })\n",
    "            it < 0.65 -> ({ size: Int -> max(1, size / 2 - 1) })\n",
    "            it < 0.85 -> ({ size: Int -> max(1, size / 2) })\n",
    "            else -> ({ size: Int -> size })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val defaultNasalSuffix = if (requiresNasalMarking && !nasalDiacriticDesired) {\n",
    "        consonants.filter { it.data.manner == Manner.NASAL }.randomOrNull()?.symbol ?: \"n\"\n",
    "    } else null\n",
    "\n",
    "    val hasDoubledVowels = baseLetters.values.any { it.lowerCase.count() == 2 && it.lowerCase.toSet().count() == 1 }\n",
    "\n",
    "    println(\"baseLetters: ${baseLetters.mapValues { (_, letter) -> letter.lowerCase }}\")\n",
    "\n",
    "    return ({ word ->\n",
    "        word.joinToString(\"\") { syllable ->\n",
    "            syllable.onset.joinToString(\"\") { it.display } +\n",
    "                    syllable.nucleus.joinToString(\"\") { segment ->\n",
    "                        val letter = baseLetters[segment.symbol]!!.lowerCase\n",
    "                        val shouldDouble = segment.data.lengthened == true && requiresLengthMarking && lengthDiacritic == null && !hasDoubledVowels\n",
    "                        val baseList = listOf(\n",
    "                            segment.data.onGlide?.display(segment)?.filter { it != \"◌̯\"[1] },\n",
    "                            if (shouldDouble) letter.trimEnd('h') else letter,\n",
    "                            if (shouldDouble) letter else null,\n",
    "                            if (segment.data.nasalized == true && requiresNasalMarking && !nasalDiacriticDesired) {\n",
    "                                consonants.firstOrNull {\n",
    "                                    it.data.manner == Manner.NASAL\n",
    "                                            && it.data.place == syllable.coda.firstOrNull()?.data?.place\n",
    "                                }?.symbol ?: defaultNasalSuffix\n",
    "                            } else null,\n",
    "                            segment.data.offGlide?.display(segment)?.filter { it != \"◌̯\"[1] }\n",
    "                        ).filterNotNull().toMutableList()\n",
    "\n",
    "                        val applicableDiacritics = listOf(\n",
    "                            if (segment.data.lengthened == true) lengthDiacritic else null,\n",
    "                            if (segment.data.nasalized == true) nasalDiacritic else null,\n",
    "                            if (syllable.tone != null) syllable.tone!!.display else null\n",
    "                        ).filterNotNull().joinToString(\"\")\n",
    "\n",
    "                        baseList.add(diacriticPlaceFn(baseList.size), applicableDiacritics)\n",
    "                        baseList.joinToString(\"\")\n",
    "                    } + syllable.coda.joinToString(\"\") { it.display }\n",
    "        }\n",
    "    })\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T08:58:49.836725100Z",
     "start_time": "2025-12-19T08:58:48.422575800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.UtilityExtensions.formatDigits\n",
    "import kotlin.random.nextInt\n",
    "\n",
    "val consonants = generateConsonants()\n",
    "println(\"consonants: ${consonants.map { it.display }}\")\n",
    "\n",
    "val vowels = generateVowels()\n",
    "println(\"vowels: ${vowels.map { it.display }}\")\n",
    "\n",
    "val onsetMaxConsonants = random.nextDouble().let {\n",
    "    when {\n",
    "        it <= 0.2 -> 3\n",
    "        it <= 0.8 -> 2\n",
    "        else -> 1\n",
    "    }\n",
    "}\n",
    "val codaMaxConsonants = min(3, onsetMaxConsonants + random.nextInt(-1..1))\n",
    "println(\"max onset consonants: $onsetMaxConsonants, coda consonants: $codaMaxConsonants\")\n",
    "\n",
    "val fallOff = random.nextDouble()\n",
    "println(\"fall off: $fallOff\")\n",
    "\n",
    "val sonoritySequencingStrictness = random.nextDouble(0.5, 1.0).pow(0.33)\n",
    "println(\"sonority sequencing strictness: ${sonoritySequencingStrictness.formatDigits()}\")\n",
    "\n",
    "val (onsetClusters, codaClusters) = generateClusters(\n",
    "    onsetMaxConsonants,\n",
    "    codaMaxConsonants,\n",
    "    fallOff,\n",
    "    sonoritySequencingStrictness,\n",
    "    consonants\n",
    ")\n",
    "println(\"onset patterns (${onsetClusters.size}):\\n${onsetClusters.joinToString(\"\") { \" - $it\\n\" }}\")\n",
    "println(\"coda patterns (${codaClusters.size}):\\n${codaClusters.joinToString(\"\") { \" - $it\\n\" }}\")\n",
    "\n",
    "val syllableRules =\n",
    "    generateSyllableRules(consonants, vowels, onsetClusters, codaClusters, onsetMaxConsonants, codaMaxConsonants)\n",
    "println(\"syllable rules:\\n${syllableRules.joinToString(\"\") { \" - ${it.name}\\n\" }}\")\n",
    "\n",
    "\n",
    "val allSyllables = generateAllSyllables(consonants, vowels, onsetClusters, codaClusters, syllableRules)\n",
    "\n",
    "val trueOnsets = allSyllables.map { it.onset }.distinct()\n",
    "val trueCodas = allSyllables.map { it.coda }.distinct()\n",
    "\n",
    "println(\"onsets (${trueOnsets.size}): ${trueOnsets.map { it.joinToString(\"\") { it.display } }}\")\n",
    "println(\"codas (${trueCodas.size}): ${trueCodas.map { it.joinToString(\"\") { it.display } }}\")\n",
    "\n",
    "println(\n",
    "    \"sample syllables: ${\n",
    "        (1..20).map { allSyllables.random().toString() }.joinToString()\n",
    "    }\"\n",
    ")\n",
    "\n",
    "val syllableWeights = weighSyllables(consonants, vowels, allSyllables)\n",
    "println(\n",
    "    \"top 20 syllables:\\n${\n",
    "        syllableWeights.toList()\n",
    "            .sortedByDescending { it.second }\n",
    "            .take(20)\n",
    "            .joinToString(\"\") { \" - ${it.first}: ${it.second.formatDigits()}\\n\" }\n",
    "    }\"\n",
    ")\n",
    "\n",
    "val wordTransformations = generateWordTransformations(allSyllables)\n",
    "val syllableBag = syllableWeights.keys.toWeightedBag(random) { syllableWeights[it]!! }\n",
    "val averageWordLength = 20.0 / log(allSyllables.size.toDouble(), 2.0)\n",
    "\n",
    "if (wordTransformations.isEmpty()) println(\"No word transformations.\\n\")\n",
    "else {\n",
    "    println(\"word transformations:\\n${wordTransformations.joinToString(\"\") { \" - ${it.name}\\n\" }}\")\n",
    "    println(\n",
    "        \"example transformations:\\n${\n",
    "            (1..10).map {\n",
    "                val word = (1..ceil(averageWordLength).toInt()).map { syllableBag.grab()!! }\n",
    "                word.joinToString(\"\") to wordTransformations\n",
    "                    .fold(word) { word, transformation -> transformation.transform(word) }\n",
    "                    .joinToString(\"\")\n",
    "            }.joinToString(\"\") {\n",
    "                \" - ${it.first} → ${it.second}\\n\"\n",
    "            }\n",
    "        }\"\n",
    "    )\n",
    "}\n",
    "\n",
    "val orthography = generateEnglishOrthography(\n",
    "    allSyllables, syllableRules, wordTransformations, EnglishOrthographyConfig(\n",
    "        enableDiacritics = true,\n",
    "        enableDiaresis = true,\n",
    "        enableLigatures = true,\n",
    "        enableToneMarkers = true,\n",
    "        enableComplexSyllables = true,\n",
    "        enableSpecialCharacters = true\n",
    "    )\n",
    ")\n",
    "\n",
    "val sentences = (1..5).map {\n",
    "    (1..random.nextInt(\n",
    "        4,\n",
    "        12\n",
    "    )).map {\n",
    "        generateWord(\n",
    "            (averageWordLength * (random.nextDouble() * random.nextDouble()).scaleAndCoerceIn(\n",
    "                0.0..1.0,\n",
    "                0.5..1.5\n",
    "            )).roundToInt(), syllableBag, wordTransformations\n",
    "        )\n",
    "    }\n",
    "}.associateWith { it.map { orthography.invoke(it) } }\n",
    "\n",
    "println(\n",
    "    \"example sentences:\\n${\n",
    "        sentences.entries.joinToString(\"\") { (ipa, ortho) ->\n",
    "            ipa.joinToString(\" \") { it.joinToString(\"\") } + \" → \" + ortho.joinToString(\" \") + \"\\n\"\n",
    "        }\n",
    "    }\"\n",
    ")\n",
    "\n",
    "println(\n",
    "    \"total possible syllables (${allSyllables.size}): ${\n",
    "        allSyllables.map { it.toString() }\n",
    "            .sorted()\n",
    "            .joinToString()\n",
    "    }\"\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consonants: [m, n, ŋ, p, p?, t, t?, k, kʷ, k?, d, d?, ɡ, ɡ?, f?, s, s?, j, w, l]\r\n",
      "vowels: [i, u, e, o, ɛ, a, iː, uː, eː, oː, aː]\r\n",
      "max onset consonants: 3, coda consonants: 2\r\n",
      "fall off: 0.8054296103724915\r\n",
      "sonority sequencing strictness: 0.91\r\n",
      "onset patterns (5):\n",
      " - [ConsonantSlot(manner=[NASAL, PLOSIVE, FRICATIVE, SEMIVOWEL, LIQUID], place=[LABIAL, ALVEOLAR, VELAR], voiced=[null, false, true], consonantGlide=[null, Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), Glide(place=LABIAL, manner=SEMIVOWEL, isOnGlide=false)], offGlide=[null])]\n",
      " - []\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[LABIAL, VELAR], voiced=[false], consonantGlide=[null], offGlide=[null]), ConsonantSlot(manner=[NASAL], place=[LABIAL, ALVEOLAR], voiced=[null, false], consonantGlide=[null], offGlide=[null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[LABIAL, ALVEOLAR, VELAR], voiced=[false, null, true], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), null], offGlide=[null]), ConsonantSlot(manner=[SEMIVOWEL], place=[LABIAL, VELAR], voiced=[null, false], consonantGlide=[null], offGlide=[null])]\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[VELAR, ALVEOLAR], voiced=[false], consonantGlide=[null, Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false)], offGlide=[null]), ConsonantSlot(manner=[FRICATIVE], place=[LABIAL, ALVEOLAR, VELAR], voiced=[false, null, true], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), null], offGlide=[null]), ConsonantSlot(manner=[SEMIVOWEL], place=[LABIAL, VELAR], voiced=[null, false], consonantGlide=[null], offGlide=[null])]\n",
      "\r\n",
      "coda patterns (3):\n",
      " - []\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[VELAR, ALVEOLAR, LABIAL], voiced=[false, null], consonantGlide=[Glide(place=LABIAL, manner=SEMIVOWEL, isOnGlide=false), null], offGlide=[null])]\n",
      " - [ConsonantSlot(manner=[SEMIVOWEL], place=[LABIAL, ALVEOLAR], voiced=[null, true], consonantGlide=[null], offGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[VELAR, ALVEOLAR, LABIAL], voiced=[true, false, null], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), null], offGlide=[null])]\n",
      "\r\n",
      "syllable rules:\n",
      " - w Sidedness (false-true)\n",
      " - Offglide-Glide Adjacency\n",
      " - Semivowel-Vowel Adjacency\n",
      " - Homorganic Consonant Voicing\n",
      " - No Geminate Consonants\n",
      " - All Offglides must be Cluster-final\n",
      " - Homorganic PLOSIVE-NASAL Consonant Placing\n",
      " - Homorganic PLOSIVE-FRICATIVE Consonant Placing\n",
      " - Homorganic FRICATIVE-SEMIVOWEL Consonant Placing\n",
      "\r\n",
      "onsets (21): [m, n, ŋ, p, p?, t, t?, k, kʷ, k?, d, d?, ɡ, ɡ?, f?, s, s?, j, l, , pm]\r\n",
      "codas (25): [, p, t, k, kʷ, wp, wp?, wt, wt?, wk, wk?, wd, wd?, wɡ, wɡ?, jp, jp?, jt, jt?, jk, jk?, jd, jd?, jɡ, jɡ?]\r\n",
      "sample syllables: t?ejd?, pewk?, pmɛkʷ, tɛwɡ, dujk, pmawɡ, kʷat, d?up, k?iwk, kʷɛwt, d?awɡ?, kʷajɡ, jokʷ, pmaːjp, t?ikʷ, pmɛwɡ, p?ɛjt?, jewt?, d?ejɡ?, sot\r\n",
      "top consonants: p (0.50), p? (0.35), k (0.27), j (0.22), kʷ (0.18), n (0.16), k? (0.14), t (0.13), t? (0.11), w (0.10)\r\n",
      "top vowels: iː (0.38), i (0.31), oː (0.26), aː (0.23), o (0.21), uː (0.19), u (0.17), e (0.16), a (0.15), eː (0.14)\r\n",
      "top 20 syllables:\n",
      " - ki: 1.10\n",
      " - pi: 1.09\n",
      " - to: 0.95\n",
      " - tɛ: 0.93\n",
      " - ke: 0.92\n",
      " - kɛ: 0.90\n",
      " - no: 0.90\n",
      " - de: 0.90\n",
      " - ta: 0.88\n",
      " - pɛ: 0.88\n",
      " - jɛ: 0.88\n",
      " - li: 0.86\n",
      " - ni: 0.85\n",
      " - lɛ: 0.85\n",
      " - jo: 0.83\n",
      " - ɡo: 0.81\n",
      " - pu: 0.80\n",
      " - pe: 0.80\n",
      " - po: 0.79\n",
      " - nɛ: 0.78\n",
      "\r\n",
      "word transformations:\n",
      " - Interject glottal stop between adjacent vowels\n",
      "\r\n",
      "example transformations:\n",
      " - k?iːpsiːwk → k?iːpsiːwk\n",
      " - d?ɛpf?aː → d?ɛpf?aː\n",
      " - kʷoːf?ujɡ → kʷoːf?ujɡ\n",
      " - ŋɛwk?ŋiːk → ŋɛwk?ŋiːk\n",
      " - tuːkʷɛwp → tuːkʷɛwp\n",
      " - nef?iː → nef?iː\n",
      " - t?aːpi → t?aːpi\n",
      " - s?ɛjpnu → s?ɛjpnu\n",
      " - tɛwtjuːjɡ → tɛwtjuːjɡ\n",
      " - f?osɛjk? → f?osɛjk?\n",
      "\r\n",
      "baseLetters: {i=i, ɛ=eh, u=u, o=o, a=a, e=e}\r\n",
      "example sentences:\n",
      "t?ewt? ŋe peːjp niːɡ?ujd? tuːk nɛkt?u → t?ewt? ŋe peejp niiɡ?ujd? tuuk nehkt?u\n",
      "s?oː pmi ɡ?oːk si p?owkdak ejɡ? → s?oo pmi ɡ?ook si p?owkdak ejɡ?\n",
      "ŋewkɡap tiwdt?iːk koːwd kʷoːjt nup nuːjk paː → ŋewkɡap tiwdt?iik koowd kʷoojt nup nuujk paa\n",
      "d?e luːpf?iː kʷɛwt p?owɡ? s?iwd? p?oːwp? → d?e luupf?ii kʷehwt p?owɡ? s?iwd? p?oowp?\n",
      "paːjt? dɛk t?uf?u pi dup kʷejp tikʷ doːwd? miwk? → paajt? dehk t?uf?u pi dup kʷejp tikʷ doowd? miwk?\n",
      "\r\n",
      "total possible syllables (4905): a, ajd, ajd?, ajk, ajk?, ajp, ajp?, ajt, ajt?, ajɡ, ajɡ?, ak, akʷ, ap, at, awd, awd?, awk, awk?, awp, awp?, awt, awt?, awɡ, awɡ?, aː, aːjd, aːjd?, aːjk, aːjk?, aːjp, aːjp?, aːjt, aːjt?, aːjɡ, aːjɡ?, aːk, aːkʷ, aːp, aːt, aːwd, aːwd?, aːwk, aːwk?, aːwp, aːwp?, aːwt, aːwt?, aːwɡ, aːwɡ?, d?a, d?ajd, d?ajd?, d?ajk, d?ajk?, d?ajp, d?ajp?, d?ajt, d?ajt?, d?ajɡ, d?ajɡ?, d?ak, d?akʷ, d?ap, d?at, d?awd, d?awd?, d?awk, d?awk?, d?awp, d?awp?, d?awt, d?awt?, d?awɡ, d?awɡ?, d?aː, d?aːjd, d?aːjd?, d?aːjk, d?aːjk?, d?aːjp, d?aːjp?, d?aːjt, d?aːjt?, d?aːjɡ, d?aːjɡ?, d?aːk, d?aːkʷ, d?aːp, d?aːt, d?aːwd, d?aːwd?, d?aːwk, d?aːwk?, d?aːwp, d?aːwp?, d?aːwt, d?aːwt?, d?aːwɡ, d?aːwɡ?, d?e, d?ejd, d?ejd?, d?ejk, d?ejk?, d?ejp, d?ejp?, d?ejt, d?ejt?, d?ejɡ, d?ejɡ?, d?ek, d?ekʷ, d?ep, d?et, d?ewd, d?ewd?, d?ewk, d?ewk?, d?ewp, d?ewp?, d?ewt, d?ewt?, d?ewɡ, d?ewɡ?, d?eː, d?eːjd, d?eːjd?, d?eːjk, d?eːjk?, d?eːjp, d?eːjp?, d?eːjt, d?eːjt?, d?eːjɡ, d?eːjɡ?, d?eːk, d?eːkʷ, d?eːp, d?eːt, d?eːwd, d?eːwd?, d?eːwk, d?eːwk?, d?eːwp, d?eːwp?, d?eːwt, d?eːwt?, d?eːwɡ, d?eːwɡ?, d?i, d?ik, d?ikʷ, d?ip, d?it, d?iwd, d?iwd?, d?iwk, d?iwk?, d?iwp, d?iwp?, d?iwt, d?iwt?, d?iwɡ, d?iwɡ?, d?iː, d?iːk, d?iːkʷ, d?iːp, d?iːt, d?iːwd, d?iːwd?, d?iːwk, d?iːwk?, d?iːwp, d?iːwp?, d?iːwt, d?iːwt?, d?iːwɡ, d?iːwɡ?, d?o, d?ojd, d?ojd?, d?ojk, d?ojk?, d?ojp, d?ojp?, d?ojt, d?ojt?, d?ojɡ, d?ojɡ?, d?ok, d?okʷ, d?op, d?ot, d?owd, d?owd?, d?owk, d?owk?, d?owp, d?owp?, d?owt, d?owt?, d?owɡ, d?owɡ?, d?oː, d?oːjd, d?oːjd?, d?oːjk, d?oːjk?, d?oːjp, d?oːjp?, d?oːjt, d?oːjt?, d?oːjɡ, d?oːjɡ?, d?oːk, d?oːkʷ, d?oːp, d?oːt, d?oːwd, d?oːwd?, d?oːwk, d?oːwk?, d?oːwp, d?oːwp?, d?oːwt, d?oːwt?, d?oːwɡ, d?oːwɡ?, d?u, d?ujd, d?ujd?, d?ujk, d?ujk?, d?ujp, d?ujp?, d?ujt, d?ujt?, d?ujɡ, d?ujɡ?, d?uk, d?ukʷ, d?up, d?ut, d?uː, d?uːjd, d?uːjd?, d?uːjk, d?uːjk?, d?uːjp, d?uːjp?, d?uːjt, d?uːjt?, d?uːjɡ, d?uːjɡ?, d?uːk, d?uːkʷ, d?uːp, d?uːt, d?ɛ, d?ɛjd, d?ɛjd?, d?ɛjk, d?ɛjk?, d?ɛjp, d?ɛjp?, d?ɛjt, d?ɛjt?, d?ɛjɡ, d?ɛjɡ?, d?ɛk, d?ɛkʷ, d?ɛp, d?ɛt, d?ɛwd, d?ɛwd?, d?ɛwk, d?ɛwk?, d?ɛwp, d?ɛwp?, d?ɛwt, d?ɛwt?, d?ɛwɡ, d?ɛwɡ?, da, dajd, dajd?, dajk, dajk?, dajp, dajp?, dajt, dajt?, dajɡ, dajɡ?, dak, dakʷ, dap, dat, dawd, dawd?, dawk, dawk?, dawp, dawp?, dawt, dawt?, dawɡ, dawɡ?, daː, daːjd, daːjd?, daːjk, daːjk?, daːjp, daːjp?, daːjt, daːjt?, daːjɡ, daːjɡ?, daːk, daːkʷ, daːp, daːt, daːwd, daːwd?, daːwk, daːwk?, daːwp, daːwp?, daːwt, daːwt?, daːwɡ, daːwɡ?, de, dejd, dejd?, dejk, dejk?, dejp, dejp?, dejt, dejt?, dejɡ, dejɡ?, dek, dekʷ, dep, det, dewd, dewd?, dewk, dewk?, dewp, dewp?, dewt, dewt?, dewɡ, dewɡ?, deː, deːjd, deːjd?, deːjk, deːjk?, deːjp, deːjp?, deːjt, deːjt?, deːjɡ, deːjɡ?, deːk, deːkʷ, deːp, deːt, deːwd, deːwd?, deːwk, deːwk?, deːwp, deːwp?, deːwt, deːwt?, deːwɡ, deːwɡ?, di, dik, dikʷ, dip, dit, diwd, diwd?, diwk, diwk?, diwp, diwp?, diwt, diwt?, diwɡ, diwɡ?, diː, diːk, diːkʷ, diːp, diːt, diːwd, diːwd?, diːwk, diːwk?, diːwp, diːwp?, diːwt, diːwt?, diːwɡ, diːwɡ?, do, dojd, dojd?, dojk, dojk?, dojp, dojp?, dojt, dojt?, dojɡ, dojɡ?, dok, dokʷ, dop, dot, dowd, dowd?, dowk, dowk?, dowp, dowp?, dowt, dowt?, dowɡ, dowɡ?, doː, doːjd, doːjd?, doːjk, doːjk?, doːjp, doːjp?, doːjt, doːjt?, doːjɡ, doːjɡ?, doːk, doːkʷ, doːp, doːt, doːwd, doːwd?, doːwk, doːwk?, doːwp, doːwp?, doːwt, doːwt?, doːwɡ, doːwɡ?, du, dujd, dujd?, dujk, dujk?, dujp, dujp?, dujt, dujt?, dujɡ, dujɡ?, duk, dukʷ, dup, dut, duː, duːjd, duːjd?, duːjk, duːjk?, duːjp, duːjp?, duːjt, duːjt?, duːjɡ, duːjɡ?, duːk, duːkʷ, duːp, duːt, dɛ, dɛjd, dɛjd?, dɛjk, dɛjk?, dɛjp, dɛjp?, dɛjt, dɛjt?, dɛjɡ, dɛjɡ?, dɛk, dɛkʷ, dɛp, dɛt, dɛwd, dɛwd?, dɛwk, dɛwk?, dɛwp, dɛwp?, dɛwt, dɛwt?, dɛwɡ, dɛwɡ?, e, ejd, ejd?, ejk, ejk?, ejp, ejp?, ejt, ejt?, ejɡ, ejɡ?, ek, ekʷ, ep, et, ewd, ewd?, ewk, ewk?, ewp, ewp?, ewt, ewt?, ewɡ, ewɡ?, eː, eːjd, eːjd?, eːjk, eːjk?, eːjp, eːjp?, eːjt, eːjt?, eːjɡ, eːjɡ?, eːk, eːkʷ, eːp, eːt, eːwd, eːwd?, eːwk, eːwk?, eːwp, eːwp?, eːwt, eːwt?, eːwɡ, eːwɡ?, f?a, f?ajd, f?ajd?, f?ajk, f?ajk?, f?ajp, f?ajp?, f?ajt, f?ajt?, f?ajɡ, f?ajɡ?, f?ak, f?akʷ, f?ap, f?at, f?awd, f?awd?, f?awk, f?awk?, f?awp, f?awp?, f?awt, f?awt?, f?awɡ, f?awɡ?, f?aː, f?aːjd, f?aːjd?, f?aːjk, f?aːjk?, f?aːjp, f?aːjp?, f?aːjt, f?aːjt?, f?aːjɡ, f?aːjɡ?, f?aːk, f?aːkʷ, f?aːp, f?aːt, f?aːwd, f?aːwd?, f?aːwk, f?aːwk?, f?aːwp, f?aːwp?, f?aːwt, f?aːwt?, f?aːwɡ, f?aːwɡ?, f?e, f?ejd, f?ejd?, f?ejk, f?ejk?, f?ejp, f?ejp?, f?ejt, f?ejt?, f?ejɡ, f?ejɡ?, f?ek, f?ekʷ, f?ep, f?et, f?ewd, f?ewd?, f?ewk, f?ewk?, f?ewp, f?ewp?, f?ewt, f?ewt?, f?ewɡ, f?ewɡ?, f?eː, f?eːjd, f?eːjd?, f?eːjk, f?eːjk?, f?eːjp, f?eːjp?, f?eːjt, f?eːjt?, f?eːjɡ, f?eːjɡ?, f?eːk, f?eːkʷ, f?eːp, f?eːt, f?eːwd, f?eːwd?, f?eːwk, f?eːwk?, f?eːwp, f?eːwp?, f?eːwt, f?eːwt?, f?eːwɡ, f?eːwɡ?, f?i, f?ik, f?ikʷ, f?ip, f?it, f?iwd, f?iwd?, f?iwk, f?iwk?, f?iwp, f?iwp?, f?iwt, f?iwt?, f?iwɡ, f?iwɡ?, f?iː, f?iːk, f?iːkʷ, f?iːp, f?iːt, f?iːwd, f?iːwd?, f?iːwk, f?iːwk?, f?iːwp, f?iːwp?, f?iːwt, f?iːwt?, f?iːwɡ, f?iːwɡ?, f?o, f?ojd, f?ojd?, f?ojk, f?ojk?, f?ojp, f?ojp?, f?ojt, f?ojt?, f?ojɡ, f?ojɡ?, f?ok, f?okʷ, f?op, f?ot, f?owd, f?owd?, f?owk, f?owk?, f?owp, f?owp?, f?owt, f?owt?, f?owɡ, f?owɡ?, f?oː, f?oːjd, f?oːjd?, f?oːjk, f?oːjk?, f?oːjp, f?oːjp?, f?oːjt, f?oːjt?, f?oːjɡ, f?oːjɡ?, f?oːk, f?oːkʷ, f?oːp, f?oːt, f?oːwd, f?oːwd?, f?oːwk, f?oːwk?, f?oːwp, f?oːwp?, f?oːwt, f?oːwt?, f?oːwɡ, f?oːwɡ?, f?u, f?ujd, f?ujd?, f?ujk, f?ujk?, f?ujp, f?ujp?, f?ujt, f?ujt?, f?ujɡ, f?ujɡ?, f?uk, f?ukʷ, f?up, f?ut, f?uː, f?uːjd, f?uːjd?, f?uːjk, f?uːjk?, f?uːjp, f?uːjp?, f?uːjt, f?uːjt?, f?uːjɡ, f?uːjɡ?, f?uːk, f?uːkʷ, f?uːp, f?uːt, f?ɛ, f?ɛjd, f?ɛjd?, f?ɛjk, f?ɛjk?, f?ɛjp, f?ɛjp?, f?ɛjt, f?ɛjt?, f?ɛjɡ, f?ɛjɡ?, f?ɛk, f?ɛkʷ, f?ɛp, f?ɛt, f?ɛwd, f?ɛwd?, f?ɛwk, f?ɛwk?, f?ɛwp, f?ɛwp?, f?ɛwt, f?ɛwt?, f?ɛwɡ, f?ɛwɡ?, i, ik, ikʷ, ip, it, iwd, iwd?, iwk, iwk?, iwp, iwp?, iwt, iwt?, iwɡ, iwɡ?, iː, iːk, iːkʷ, iːp, iːt, iːwd, iːwd?, iːwk, iːwk?, iːwp, iːwp?, iːwt, iːwt?, iːwɡ, iːwɡ?, ja, jajd, jajd?, jajk, jajk?, jajp, jajp?, jajt, jajt?, jajɡ, jajɡ?, jak, jakʷ, jap, jat, jawd, jawd?, jawk, jawk?, jawp, jawp?, jawt, jawt?, jawɡ, jawɡ?, jaː, jaːjd, jaːjd?, jaːjk, jaːjk?, jaːjp, jaːjp?, jaːjt, jaːjt?, jaːjɡ, jaːjɡ?, jaːk, jaːkʷ, jaːp, jaːt, jaːwd, jaːwd?, jaːwk, jaːwk?, jaːwp, jaːwp?, jaːwt, jaːwt?, jaːwɡ, jaːwɡ?, je, jejd, jejd?, jejk, jejk?, jejp, jejp?, jejt, jejt?, jejɡ, jejɡ?, jek, jekʷ, jep, jet, jewd, jewd?, jewk, jewk?, jewp, jewp?, jewt, jewt?, jewɡ, jewɡ?, jeː, jeːjd, jeːjd?, jeːjk, jeːjk?, jeːjp, jeːjp?, jeːjt, jeːjt?, jeːjɡ, jeːjɡ?, jeːk, jeːkʷ, jeːp, jeːt, jeːwd, jeːwd?, jeːwk, jeːwk?, jeːwp, jeːwp?, jeːwt, jeːwt?, jeːwɡ, jeːwɡ?, jo, jojd, jojd?, jojk, jojk?, jojp, jojp?, jojt, jojt?, jojɡ, jojɡ?, jok, jokʷ, jop, jot, jowd, jowd?, jowk, jowk?, jowp, jowp?, jowt, jowt?, jowɡ, jowɡ?, joː, joːjd, joːjd?, joːjk, joːjk?, joːjp, joːjp?, joːjt, joːjt?, joːjɡ, joːjɡ?, joːk, joːkʷ, joːp, joːt, joːwd, joːwd?, joːwk, joːwk?, joːwp, joːwp?, joːwt, joːwt?, joːwɡ, joːwɡ?, ju, jujd, jujd?, jujk, jujk?, jujp, jujp?, jujt, jujt?, jujɡ, jujɡ?, juk, jukʷ, jup, jut, juː, juːjd, juːjd?, juːjk, juːjk?, juːjp, juːjp?, juːjt, juːjt?, juːjɡ, juːjɡ?, juːk, juːkʷ, juːp, juːt, jɛ, jɛjd, jɛjd?, jɛjk, jɛjk?, jɛjp, jɛjp?, jɛjt, jɛjt?, jɛjɡ, jɛjɡ?, jɛk, jɛkʷ, jɛp, jɛt, jɛwd, jɛwd?, jɛwk, jɛwk?, jɛwp, jɛwp?, jɛwt, jɛwt?, jɛwɡ, jɛwɡ?, k?a, k?ajd, k?ajd?, k?ajk, k?ajk?, k?ajp, k?ajp?, k?ajt, k?ajt?, k?ajɡ, k?ajɡ?, k?ak, k?akʷ, k?ap, k?at, k?awd, k?awd?, k?awk, k?awk?, k?awp, k?awp?, k?awt, k?awt?, k?awɡ, k?awɡ?, k?aː, k?aːjd, k?aːjd?, k?aːjk, k?aːjk?, k?aːjp, k?aːjp?, k?aːjt, k?aːjt?, k?aːjɡ, k?aːjɡ?, k?aːk, k?aːkʷ, k?aːp, k?aːt, k?aːwd, k?aːwd?, k?aːwk, k?aːwk?, k?aːwp, k?aːwp?, k?aːwt, k?aːwt?, k?aːwɡ, k?aːwɡ?, k?e, k?ejd, k?ejd?, k?ejk, k?ejk?, k?ejp, k?ejp?, k?ejt, k?ejt?, k?ejɡ, k?ejɡ?, k?ek, k?ekʷ, k?ep, k?et, k?ewd, k?ewd?, k?ewk, k?ewk?, k?ewp, k?ewp?, k?ewt, k?ewt?, k?ewɡ, k?ewɡ?, k?eː, k?eːjd, k?eːjd?, k?eːjk, k?eːjk?, k?eːjp, k?eːjp?, k?eːjt, k?eːjt?, k?eːjɡ, k?eːjɡ?, k?eːk, k?eːkʷ, k?eːp, k?eːt, k?eːwd, k?eːwd?, k?eːwk, k?eːwk?, k?eːwp, k?eːwp?, k?eːwt, k?eːwt?, k?eːwɡ, k?eːwɡ?, k?i, k?ik, k?ikʷ, k?ip, k?it, k?iwd, k?iwd?, k?iwk, k?iwk?, k?iwp, k?iwp?, k?iwt, k?iwt?, k?iwɡ, k?iwɡ?, k?iː, k?iːk, k?iːkʷ, k?iːp, k?iːt, k?iːwd, k?iːwd?, k?iːwk, k?iːwk?, k?iːwp, k?iːwp?, k?iːwt, k?iːwt?, k?iːwɡ, k?iːwɡ?, k?o, k?ojd, k?ojd?, k?ojk, k?ojk?, k?ojp, k?ojp?, k?ojt, k?ojt?, k?ojɡ, k?ojɡ?, k?ok, k?okʷ, k?op, k?ot, k?owd, k?owd?, k?owk, k?owk?, k?owp, k?owp?, k?owt, k?owt?, k?owɡ, k?owɡ?, k?oː, k?oːjd, k?oːjd?, k?oːjk, k?oːjk?, k?oːjp, k?oːjp?, k?oːjt, k?oːjt?, k?oːjɡ, k?oːjɡ?, k?oːk, k?oːkʷ, k?oːp, k?oːt, k?oːwd, k?oːwd?, k?oːwk, k?oːwk?, k?oːwp, k?oːwp?, k?oːwt, k?oːwt?, k?oːwɡ, k?oːwɡ?, k?u, k?ujd, k?ujd?, k?ujk, k?ujk?, k?ujp, k?ujp?, k?ujt, k?ujt?, k?ujɡ, k?ujɡ?, k?uk, k?ukʷ, k?up, k?ut, k?uː, k?uːjd, k?uːjd?, k?uːjk, k?uːjk?, k?uːjp, k?uːjp?, k?uːjt, k?uːjt?, k?uːjɡ, k?uːjɡ?, k?uːk, k?uːkʷ, k?uːp, k?uːt, k?ɛ, k?ɛjd, k?ɛjd?, k?ɛjk, k?ɛjk?, k?ɛjp, k?ɛjp?, k?ɛjt, k?ɛjt?, k?ɛjɡ, k?ɛjɡ?, k?ɛk, k?ɛkʷ, k?ɛp, k?ɛt, k?ɛwd, k?ɛwd?, k?ɛwk, k?ɛwk?, k?ɛwp, k?ɛwp?, k?ɛwt, k?ɛwt?, k?ɛwɡ, k?ɛwɡ?, ka, kajd, kajd?, kajk, kajk?, kajp, kajp?, kajt, kajt?, kajɡ, kajɡ?, kak, kakʷ, kap, kat, kawd, kawd?, kawk, kawk?, kawp, kawp?, kawt, kawt?, kawɡ, kawɡ?, kaː, kaːjd, kaːjd?, kaːjk, kaːjk?, kaːjp, kaːjp?, kaːjt, kaːjt?, kaːjɡ, kaːjɡ?, kaːk, kaːkʷ, kaːp, kaːt, kaːwd, kaːwd?, kaːwk, kaːwk?, kaːwp, kaːwp?, kaːwt, kaːwt?, kaːwɡ, kaːwɡ?, ke, kejd, kejd?, kejk, kejk?, kejp, kejp?, kejt, kejt?, kejɡ, kejɡ?, kek, kekʷ, kep, ket, kewd, kewd?, kewk, kewk?, kewp, kewp?, kewt, kewt?, kewɡ, kewɡ?, keː, keːjd, keːjd?, keːjk, keːjk?, keːjp, keːjp?, keːjt, keːjt?, keːjɡ, keːjɡ?, keːk, keːkʷ, keːp, keːt, keːwd, keːwd?, keːwk, keːwk?, keːwp, keːwp?, keːwt, keːwt?, keːwɡ, keːwɡ?, ki, kik, kikʷ, kip, kit, kiwd, kiwd?, kiwk, kiwk?, kiwp, kiwp?, kiwt, kiwt?, kiwɡ, kiwɡ?, kiː, kiːk, kiːkʷ, kiːp, kiːt, kiːwd, kiːwd?, kiːwk, kiːwk?, kiːwp, kiːwp?, kiːwt, kiːwt?, kiːwɡ, kiːwɡ?, ko, kojd, kojd?, kojk, kojk?, kojp, kojp?, kojt, kojt?, kojɡ, kojɡ?, kok, kokʷ, kop, kot, kowd, kowd?, kowk, kowk?, kowp, kowp?, kowt, kowt?, kowɡ, kowɡ?, koː, koːjd, koːjd?, koːjk, koːjk?, koːjp, koːjp?, koːjt, koːjt?, koːjɡ, koːjɡ?, koːk, koːkʷ, koːp, koːt, koːwd, koːwd?, koːwk, koːwk?, koːwp, koːwp?, koːwt, koːwt?, koːwɡ, koːwɡ?, ku, kujd, kujd?, kujk, kujk?, kujp, kujp?, kujt, kujt?, kujɡ, kujɡ?, kuk, kukʷ, kup, kut, kuː, kuːjd, kuːjd?, kuːjk, kuːjk?, kuːjp, kuːjp?, kuːjt, kuːjt?, kuːjɡ, kuːjɡ?, kuːk, kuːkʷ, kuːp, kuːt, kɛ, kɛjd, kɛjd?, kɛjk, kɛjk?, kɛjp, kɛjp?, kɛjt, kɛjt?, kɛjɡ, kɛjɡ?, kɛk, kɛkʷ, kɛp, kɛt, kɛwd, kɛwd?, kɛwk, kɛwk?, kɛwp, kɛwp?, kɛwt, kɛwt?, kɛwɡ, kɛwɡ?, kʷa, kʷajd, kʷajd?, kʷajk, kʷajk?, kʷajp, kʷajp?, kʷajt, kʷajt?, kʷajɡ, kʷajɡ?, kʷak, kʷakʷ, kʷap, kʷat, kʷawd, kʷawd?, kʷawk, kʷawk?, kʷawp, kʷawp?, kʷawt, kʷawt?, kʷawɡ, kʷawɡ?, kʷaː, kʷaːjd, kʷaːjd?, kʷaːjk, kʷaːjk?, kʷaːjp, kʷaːjp?, kʷaːjt, kʷaːjt?, kʷaːjɡ, kʷaːjɡ?, kʷaːk, kʷaːkʷ, kʷaːp, kʷaːt, kʷaːwd, kʷaːwd?, kʷaːwk, kʷaːwk?, kʷaːwp, kʷaːwp?, kʷaːwt, kʷaːwt?, kʷaːwɡ, kʷaːwɡ?, kʷe, kʷejd, kʷejd?, kʷejk, kʷejk?, kʷejp, kʷejp?, kʷejt, kʷejt?, kʷejɡ, kʷejɡ?, kʷek, kʷekʷ, kʷep, kʷet, kʷewd, kʷewd?, kʷewk, kʷewk?, kʷewp, kʷewp?, kʷewt, kʷewt?, kʷewɡ, kʷewɡ?, kʷeː, kʷeːjd, kʷeːjd?, kʷeːjk, kʷeːjk?, kʷeːjp, kʷeːjp?, kʷeːjt, kʷeːjt?, kʷeːjɡ, kʷeːjɡ?, kʷeːk, kʷeːkʷ, kʷeːp, kʷeːt, kʷeːwd, kʷeːwd?, kʷeːwk, kʷeːwk?, kʷeːwp, kʷeːwp?, kʷeːwt, kʷeːwt?, kʷeːwɡ, kʷeːwɡ?, kʷi, kʷik, kʷikʷ, kʷip, kʷit, kʷiwd, kʷiwd?, kʷiwk, kʷiwk?, kʷiwp, kʷiwp?, kʷiwt, kʷiwt?, kʷiwɡ, kʷiwɡ?, kʷiː, kʷiːk, kʷiːkʷ, kʷiːp, kʷiːt, kʷiːwd, kʷiːwd?, kʷiːwk, kʷiːwk?, kʷiːwp, kʷiːwp?, kʷiːwt, kʷiːwt?, kʷiːwɡ, kʷiːwɡ?, kʷo, kʷojd, kʷojd?, kʷojk, kʷojk?, kʷojp, kʷojp?, kʷojt, kʷojt?, kʷojɡ, kʷojɡ?, kʷok, kʷokʷ, kʷop, kʷot, kʷowd, kʷowd?, kʷowk, kʷowk?, kʷowp, kʷowp?, kʷowt, kʷowt?, kʷowɡ, kʷowɡ?, kʷoː, kʷoːjd, kʷoːjd?, kʷoːjk, kʷoːjk?, kʷoːjp, kʷoːjp?, kʷoːjt, kʷoːjt?, kʷoːjɡ, kʷoːjɡ?, kʷoːk, kʷoːkʷ, kʷoːp, kʷoːt, kʷoːwd, kʷoːwd?, kʷoːwk, kʷoːwk?, kʷoːwp, kʷoːwp?, kʷoːwt, kʷoːwt?, kʷoːwɡ, kʷoːwɡ?, kʷu, kʷujd, kʷujd?, kʷujk, kʷujk?, kʷujp, kʷujp?, kʷujt, kʷujt?, kʷujɡ, kʷujɡ?, kʷuk, kʷukʷ, kʷup, kʷut, kʷuː, kʷuːjd, kʷuːjd?, kʷuːjk, kʷuːjk?, kʷuːjp, kʷuːjp?, kʷuːjt, kʷuːjt?, kʷuːjɡ, kʷuːjɡ?, kʷuːk, kʷuːkʷ, kʷuːp, kʷuːt, kʷɛ, kʷɛjd, kʷɛjd?, kʷɛjk, kʷɛjk?, kʷɛjp, kʷɛjp?, kʷɛjt, kʷɛjt?, kʷɛjɡ, kʷɛjɡ?, kʷɛk, kʷɛkʷ, kʷɛp, kʷɛt, kʷɛwd, kʷɛwd?, kʷɛwk, kʷɛwk?, kʷɛwp, kʷɛwp?, kʷɛwt, kʷɛwt?, kʷɛwɡ, kʷɛwɡ?, la, lajd, lajd?, lajk, lajk?, lajp, lajp?, lajt, lajt?, lajɡ, lajɡ?, lak, lakʷ, lap, lat, lawd, lawd?, lawk, lawk?, lawp, lawp?, lawt, lawt?, lawɡ, lawɡ?, laː, laːjd, laːjd?, laːjk, laːjk?, laːjp, laːjp?, laːjt, laːjt?, laːjɡ, laːjɡ?, laːk, laːkʷ, laːp, laːt, laːwd, laːwd?, laːwk, laːwk?, laːwp, laːwp?, laːwt, laːwt?, laːwɡ, laːwɡ?, le, lejd, lejd?, lejk, lejk?, lejp, lejp?, lejt, lejt?, lejɡ, lejɡ?, lek, lekʷ, lep, let, lewd, lewd?, lewk, lewk?, lewp, lewp?, lewt, lewt?, lewɡ, lewɡ?, leː, leːjd, leːjd?, leːjk, leːjk?, leːjp, leːjp?, leːjt, leːjt?, leːjɡ, leːjɡ?, leːk, leːkʷ, leːp, leːt, leːwd, leːwd?, leːwk, leːwk?, leːwp, leːwp?, leːwt, leːwt?, leːwɡ, leːwɡ?, li, lik, likʷ, lip, lit, liwd, liwd?, liwk, liwk?, liwp, liwp?, liwt, liwt?, liwɡ, liwɡ?, liː, liːk, liːkʷ, liːp, liːt, liːwd, liːwd?, liːwk, liːwk?, liːwp, liːwp?, liːwt, liːwt?, liːwɡ, liːwɡ?, lo, lojd, lojd?, lojk, lojk?, lojp, lojp?, lojt, lojt?, lojɡ, lojɡ?, lok, lokʷ, lop, lot, lowd, lowd?, lowk, lowk?, lowp, lowp?, lowt, lowt?, lowɡ, lowɡ?, loː, loːjd, loːjd?, loːjk, loːjk?, loːjp, loːjp?, loːjt, loːjt?, loːjɡ, loːjɡ?, loːk, loːkʷ, loːp, loːt, loːwd, loːwd?, loːwk, loːwk?, loːwp, loːwp?, loːwt, loːwt?, loːwɡ, loːwɡ?, lu, lujd, lujd?, lujk, lujk?, lujp, lujp?, lujt, lujt?, lujɡ, lujɡ?, luk, lukʷ, lup, lut, luː, luːjd, luːjd?, luːjk, luːjk?, luːjp, luːjp?, luːjt, luːjt?, luːjɡ, luːjɡ?, luːk, luːkʷ, luːp, luːt, lɛ, lɛjd, lɛjd?, lɛjk, lɛjk?, lɛjp, lɛjp?, lɛjt, lɛjt?, lɛjɡ, lɛjɡ?, lɛk, lɛkʷ, lɛp, lɛt, lɛwd, lɛwd?, lɛwk, lɛwk?, lɛwp, lɛwp?, lɛwt, lɛwt?, lɛwɡ, lɛwɡ?, ma, majd, majd?, majk, majk?, majp, majp?, majt, majt?, majɡ, majɡ?, mak, makʷ, map, mat, mawd, mawd?, mawk, mawk?, mawp, mawp?, mawt, mawt?, mawɡ, mawɡ?, maː, maːjd, maːjd?, maːjk, maːjk?, maːjp, maːjp?, maːjt, maːjt?, maːjɡ, maːjɡ?, maːk, maːkʷ, maːp, maːt, maːwd, maːwd?, maːwk, maːwk?, maːwp, maːwp?, maːwt, maːwt?, maːwɡ, maːw��?, me, mejd, mejd?, mejk, mejk?, mejp, mejp?, mejt, mejt?, mejɡ, mejɡ?, mek, mekʷ, mep, met, mewd, mewd?, mewk, mewk?, mewp, mewp?, mewt, mewt?, mewɡ, mewɡ?, meː, meːjd, meːjd?, meːjk, meːjk?, meːjp, meːjp?, meːjt, meːjt?, meːjɡ, meːjɡ?, meːk, meːkʷ, meːp, meːt, meːwd, meːwd?, meːwk, meːwk?, meːwp, meːwp?, meːwt, meːwt?, meːwɡ, meːwɡ?, mi, mik, mikʷ, mip, mit, miwd, miwd?, miwk, miwk?, miwp, miwp?, miwt, miwt?, miwɡ, miwɡ?, miː, miːk, miːkʷ, miːp, miːt, miːwd, miːwd?, miːwk, miːwk?, miːwp, miːwp?, miːwt, miːwt?, miːwɡ, miːwɡ?, mo, mojd, mojd?, mojk, mojk?, mojp, mojp?, mojt, mojt?, mojɡ, mojɡ?, mok, mokʷ, mop, mot, mowd, mowd?, mowk, mowk?, mowp, mowp?, mowt, mowt?, mowɡ, mowɡ?, moː, moːjd, moːjd?, moːjk, moːjk?, moːjp, moːjp?, moːjt, moːjt?, moːjɡ, moːjɡ?, moːk, moːkʷ, moːp, moːt, moːwd, moːwd?, moːwk, moːwk?, moːwp, moːwp?, moːwt, moːwt?, moːwɡ, moːwɡ?, mu, mujd, mujd?, mujk, mujk?, mujp, mujp?, mujt, mujt?, mujɡ, mujɡ?, muk, mukʷ, mup, mut, muː, muːjd, muːjd?, muːjk, muːjk?, muːjp, muːjp?, muːjt, muːjt?, muːjɡ, muːjɡ?, muːk, muːkʷ, muːp, muːt, mɛ, mɛjd, mɛjd?, mɛjk, mɛjk?, mɛjp, mɛjp?, mɛjt, mɛjt?, mɛjɡ, mɛjɡ?, mɛk, mɛkʷ, mɛp, mɛt, mɛwd, mɛwd?, mɛwk, mɛwk?, mɛwp, mɛwp?, mɛwt, mɛwt?, mɛwɡ, mɛwɡ?, na, najd, najd?, najk, najk?, najp, najp?, najt, najt?, najɡ, najɡ?, nak, nakʷ, nap, nat, nawd, nawd?, nawk, nawk?, nawp, nawp?, nawt, nawt?, nawɡ, nawɡ?, naː, naːjd, naːjd?, naːjk, naːjk?, naːjp, naːjp?, naːjt, naːjt?, naːjɡ, naːjɡ?, naːk, naːkʷ, naːp, naːt, naːwd, naːwd?, naːwk, naːwk?, naːwp, naːwp?, naːwt, naːwt?, naːwɡ, naːwɡ?, ne, nejd, nejd?, nejk, nejk?, nejp, nejp?, nejt, nejt?, nejɡ, nejɡ?, nek, nekʷ, nep, net, newd, newd?, newk, newk?, newp, newp?, newt, newt?, newɡ, newɡ?, neː, neːjd, neːjd?, neːjk, neːjk?, neːjp, neːjp?, neːjt, neːjt?, neːjɡ, neːjɡ?, neːk, neːkʷ, neːp, neːt, neːwd, neːwd?, neːwk, neːwk?, neːwp, neːwp?, neːwt, neːwt?, neːwɡ, neːwɡ?, ni, nik, nikʷ, nip, nit, niwd, niwd?, niwk, niwk?, niwp, niwp?, niwt, niwt?, niwɡ, niwɡ?, niː, niːk, niːkʷ, niːp, niːt, niːwd, niːwd?, niːwk, niːwk?, niːwp, niːwp?, niːwt, niːwt?, niːwɡ, niːwɡ?, no, nojd, nojd?, nojk, nojk?, nojp, nojp?, nojt, nojt?, nojɡ, nojɡ?, nok, nokʷ, nop, not, nowd, nowd?, nowk, nowk?, nowp, nowp?, nowt, nowt?, nowɡ, nowɡ?, noː, noːjd, noːjd?, noːjk, noːjk?, noːjp, noːjp?, noːjt, noːjt?, noːjɡ, noːjɡ?, noːk, noːkʷ, noːp, noːt, noːwd, noːwd?, noːwk, noːwk?, noːwp, noːwp?, noːwt, noːwt?, noːwɡ, noːwɡ?, nu, nujd, nujd?, nujk, nujk?, nujp, nujp?, nujt, nujt?, nujɡ, nujɡ?, nuk, nukʷ, nup, nut, nuː, nuːjd, nuːjd?, nuːjk, nuːjk?, nuːjp, nuːjp?, nuːjt, nuːjt?, nuːjɡ, nuːjɡ?, nuːk, nuːkʷ, nuːp, nuːt, nɛ, nɛjd, nɛjd?, nɛjk, nɛjk?, nɛjp, nɛjp?, nɛjt, nɛjt?, nɛjɡ, nɛjɡ?, nɛk, nɛkʷ, nɛp, nɛt, nɛwd, nɛwd?, nɛwk, nɛwk?, nɛwp, nɛwp?, nɛwt, nɛwt?, nɛwɡ, nɛwɡ?, o, ojd, ojd?, ojk, ojk?, ojp, ojp?, ojt, ojt?, ojɡ, ojɡ?, ok, okʷ, op, ot, owd, owd?, owk, owk?, owp, owp?, owt, owt?, owɡ, owɡ?, oː, oːjd, oːjd?, oːjk, oːjk?, oːjp, oːjp?, oːjt, oːjt?, oːjɡ, oːjɡ?, oːk, oːkʷ, oːp, oːt, oːwd, oːwd?, oːwk, oːwk?, oːwp, oːwp?, oːwt, oːwt?, oːwɡ, oːwɡ?, p?a, p?ajd, p?ajd?, p?ajk, p?ajk?, p?ajp, p?ajp?, p?ajt, p?ajt?, p?ajɡ, p?ajɡ?, p?ak, p?akʷ, p?ap, p?at, p?awd, p?awd?, p?awk, p?awk?, p?awp, p?awp?, p?awt, p?awt?, p?awɡ, p?awɡ?, p?aː, p?aːjd, p?aːjd?, p?aːjk, p?aːjk?, p?aːjp, p?aːjp?, p?aːjt, p?aːjt?, p?aːjɡ, p?aːjɡ?, p?aːk, p?aːkʷ, p?aːp, p?aːt, p?aːwd, p?aːwd?, p?aːwk, p?aːwk?, p?aːwp, p?aːwp?, p?aːwt, p?aːwt?, p?aːwɡ, p?aːwɡ?, p?e, p?ejd, p?ejd?, p?ejk, p?ejk?, p?ejp, p?ejp?, p?ejt, p?ejt?, p?ejɡ, p?ejɡ?, p?ek, p?ekʷ, p?ep, p?et, p?ewd, p?ewd?, p?ewk, p?ewk?, p?ewp, p?ewp?, p?ewt, p?ewt?, p?ewɡ, p?ewɡ?, p?eː, p?eːjd, p?eːjd?, p?eːjk, p?eːjk?, p?eːjp, p?eːjp?, p?eːjt, p?eːjt?, p?eːjɡ, p?eːjɡ?, p?eːk, p?eːkʷ, p?eːp, p?eːt, p?eːwd, p?eːwd?, p?eːwk, p?eːwk?, p?eːwp, p?eːwp?, p?eːwt, p?eːwt?, p?eːwɡ, p?eːwɡ?, p?i, p?ik, p?ikʷ, p?ip, p?it, p?iwd, p?iwd?, p?iwk, p?iwk?, p?iwp, p?iwp?, p?iwt, p?iwt?, p?iwɡ, p?iwɡ?, p?iː, p?iːk, p?iːkʷ, p?iːp, p?iːt, p?iːwd, p?iːwd?, p?iːwk, p?iːwk?, p?iːwp, p?iːwp?, p?iːwt, p?iːwt?, p?iːwɡ, p?iːwɡ?, p?o, p?ojd, p?ojd?, p?ojk, p?ojk?, p?ojp, p?ojp?, p?ojt, p?ojt?, p?ojɡ, p?ojɡ?, p?ok, p?okʷ, p?op, p?ot, p?owd, p?owd?, p?owk, p?owk?, p?owp, p?owp?, p?owt, p?owt?, p?owɡ, p?owɡ?, p?oː, p?oːjd, p?oːjd?, p?oːjk, p?oːjk?, p?oːjp, p?oːjp?, p?oːjt, p?oːjt?, p?oːjɡ, p?oːjɡ?, p?oːk, p?oːkʷ, p?oːp, p?oːt, p?oːwd, p?oːwd?, p?oːwk, p?oːwk?, p?oːwp, p?oːwp?, p?oːwt, p?oːwt?, p?oːwɡ, p?oːwɡ?, p?u, p?ujd, p?ujd?, p?ujk, p?ujk?, p?ujp, p?ujp?, p?ujt, p?ujt?, p?ujɡ, p?ujɡ?, p?uk, p?ukʷ, p?up, p?ut, p?uː, p?uːjd, p?uːjd?, p?uːjk, p?uːjk?, p?uːjp, p?uːjp?, p?uːjt, p?uːjt?, p?uːjɡ, p?uːjɡ?, p?uːk, p?uːkʷ, p?uːp, p?uːt, p?ɛ, p?ɛjd, p?ɛjd?, p?ɛjk, p?ɛjk?, p?ɛjp, p?ɛjp?, p?ɛjt, p?ɛjt?, p?ɛjɡ, p?ɛjɡ?, p?ɛk, p?ɛkʷ, p?ɛp, p?ɛt, p?ɛwd, p?ɛwd?, p?ɛwk, p?ɛwk?, p?ɛwp, p?ɛwp?, p?ɛwt, p?ɛwt?, p?ɛwɡ, p?ɛwɡ?, pa, pajd, pajd?, pajk, pajk?, pajp, pajp?, pajt, pajt?, pajɡ, pajɡ?, pak, pakʷ, pap, pat, pawd, pawd?, pawk, pawk?, pawp, pawp?, pawt, pawt?, pawɡ, pawɡ?, paː, paːjd, paːjd?, paːjk, paːjk?, paːjp, paːjp?, paːjt, paːjt?, paːjɡ, paːjɡ?, paːk, paːkʷ, paːp, paːt, paːwd, paːwd?, paːwk, paːwk?, paːwp, paːwp?, paːwt, paːwt?, paːwɡ, paːwɡ?, pe, pejd, pejd?, pejk, pejk?, pejp, pejp?, pejt, pejt?, pejɡ, pejɡ?, pek, pekʷ, pep, pet, pewd, pewd?, pewk, pewk?, pewp, pewp?, pewt, pewt?, pewɡ, pewɡ?, peː, peːjd, peːjd?, peːjk, peːjk?, peːjp, peːjp?, peːjt, peːjt?, peːjɡ, peːjɡ?, peːk, peːkʷ, peːp, peːt, peːwd, peːwd?, peːwk, peːwk?, peːwp, peːwp?, peːwt, peːwt?, peːwɡ, peːwɡ?, pi, pik, pikʷ, pip, pit, piwd, piwd?, piwk, piwk?, piwp, piwp?, piwt, piwt?, piwɡ, piwɡ?, piː, piːk, piːkʷ, piːp, piːt, piːwd, piːwd?, piːwk, piːwk?, piːwp, piːwp?, piːwt, piːwt?, piːwɡ, piːwɡ?, pma, pmajd, pmajd?, pmajk, pmajk?, pmajp, pmajp?, pmajt, pmajt?, pmajɡ, pmajɡ?, pmak, pmakʷ, pmap, pmat, pmawd, pmawd?, pmawk, pmawk?, pmawp, pmawp?, pmawt, pmawt?, pmawɡ, pmawɡ?, pmaː, pmaːjd, pmaːjd?, pmaːjk, pmaːjk?, pmaːjp, pmaːjp?, pmaːjt, pmaːjt?, pmaːjɡ, pmaːjɡ?, pmaːk, pmaːkʷ, pmaːp, pmaːt, pmaːwd, pmaːwd?, pmaːwk, pmaːwk?, pmaːwp, pmaːwp?, pmaːwt, pmaːwt?, pmaːwɡ, pmaːwɡ?, pme, pmejd, pmejd?, pmejk, pmejk?, pmejp, pmejp?, pmejt, pmejt?, pmejɡ, pmejɡ?, pmek, pmekʷ, pmep, pmet, pmewd, pmewd?, pmewk, pmewk?, pmewp, pmewp?, pmewt, pmewt?, pmewɡ, pmewɡ?, pmeː, pmeːjd, pmeːjd?, pmeːjk, pmeːjk?, pmeːjp, pmeːjp?, pmeːjt, pmeːjt?, pmeːjɡ, pmeːjɡ?, pmeːk, pmeːkʷ, pmeːp, pmeːt, pmeːwd, pmeːwd?, pmeːwk, pmeːwk?, pmeːwp, pmeːwp?, pmeːwt, pmeːwt?, pmeːwɡ, pmeːwɡ?, pmi, pmik, pmikʷ, pmip, pmit, pmiwd, pmiwd?, pmiwk, pmiwk?, pmiwp, pmiwp?, pmiwt, pmiwt?, pmiwɡ, pmiwɡ?, pmiː, pmiːk, pmiːkʷ, pmiːp, pmiːt, pmiːwd, pmiːwd?, pmiːwk, pmiːwk?, pmiːwp, pmiːwp?, pmiːwt, pmiːwt?, pmiːwɡ, pmiːwɡ?, pmo, pmojd, pmojd?, pmojk, pmojk?, pmojp, pmojp?, pmojt, pmojt?, pmojɡ, pmojɡ?, pmok, pmokʷ, pmop, pmot, pmowd, pmowd?, pmowk, pmowk?, pmowp, pmowp?, pmowt, pmowt?, pmowɡ, pmowɡ?, pmoː, pmoːjd, pmoːjd?, pmoːjk, pmoːjk?, pmoːjp, pmoːjp?, pmoːjt, pmoːjt?, pmoːjɡ, pmoːjɡ?, pmoːk, pmoːkʷ, pmoːp, pmoːt, pmoːwd, pmoːwd?, pmoːwk, pmoːwk?, pmoːwp, pmoːwp?, pmoːwt, pmoːwt?, pmoːwɡ, pmoːwɡ?, pmu, pmujd, pmujd?, pmujk, pmujk?, pmujp, pmujp?, pmujt, pmujt?, pmujɡ, pmujɡ?, pmuk, pmukʷ, pmup, pmut, pmuː, pmuːjd, pmuːjd?, pmuːjk, pmuːjk?, pmuːjp, pmuːjp?, pmuːjt, pmuːjt?, pmuːjɡ, pmuːjɡ?, pmuːk, pmuːkʷ, pmuːp, pmuːt, pmɛ, pmɛjd, pmɛjd?, pmɛjk, pmɛjk?, pmɛjp, pmɛjp?, pmɛjt, pmɛjt?, pmɛjɡ, pmɛjɡ?, pmɛk, pmɛkʷ, pmɛp, pmɛt, pmɛwd, pmɛwd?, pmɛwk, pmɛwk?, pmɛwp, pmɛwp?, pmɛwt, pmɛwt?, pmɛwɡ, pmɛwɡ?, po, pojd, pojd?, pojk, pojk?, pojp, pojp?, pojt, pojt?, pojɡ, pojɡ?, pok, pokʷ, pop, pot, powd, powd?, powk, powk?, powp, powp?, powt, powt?, powɡ, powɡ?, poː, poːjd, poːjd?, poːjk, poːjk?, poːjp, poːjp?, poːjt, poːjt?, poːjɡ, poːjɡ?, poːk, poːkʷ, poːp, poːt, poːwd, poːwd?, poːwk, poːwk?, poːwp, poːwp?, poːwt, poːwt?, poːwɡ, poːwɡ?, pu, pujd, pujd?, pujk, pujk?, pujp, pujp?, pujt, pujt?, pujɡ, pujɡ?, puk, pukʷ, pup, put, puː, puːjd, puːjd?, puːjk, puːjk?, puːjp, puːjp?, puːjt, puːjt?, puːjɡ, puːjɡ?, puːk, puːkʷ, puːp, puːt, pɛ, pɛjd, pɛjd?, pɛjk, pɛjk?, pɛjp, pɛjp?, pɛjt, pɛjt?, pɛjɡ, pɛjɡ?, pɛk, pɛkʷ, pɛp, pɛt, pɛwd, pɛwd?, pɛwk, pɛwk?, pɛwp, pɛwp?, pɛwt, pɛwt?, pɛwɡ, pɛwɡ?, s?a, s?ajd, s?ajd?, s?ajk, s?ajk?, s?ajp, s?ajp?, s?ajt, s?ajt?, s?ajɡ, s?ajɡ?, s?ak, s?akʷ, s?ap, s?at, s?awd, s?awd?, s?awk, s?awk?, s?awp, s?awp?, s?awt, s?awt?, s?awɡ, s?awɡ?, s?aː, s?aːjd, s?aːjd?, s?aːjk, s?aːjk?, s?aːjp, s?aːjp?, s?aːjt, s?aːjt?, s?aːjɡ, s?aːjɡ?, s?aːk, s?aːkʷ, s?aːp, s?aːt, s?aːwd, s?aːwd?, s?aːwk, s?aːwk?, s?aːwp, s?aːwp?, s?aːwt, s?aːwt?, s?aːwɡ, s?aːwɡ?, s?e, s?ejd, s?ejd?, s?ejk, s?ejk?, s?ejp, s?ejp?, s?ejt, s?ejt?, s?ejɡ, s?ejɡ?, s?ek, s?ekʷ, s?ep, s?et, s?ewd, s?ewd?, s?ewk, s?ewk?, s?ewp, s?ewp?, s?ewt, s?ewt?, s?ewɡ, s?ewɡ?, s?eː, s?eːjd, s?eːjd?, s?eːjk, s?eːjk?, s?eːjp, s?eːjp?, s?eːjt, s?eːjt?, s?eːjɡ, s?eːjɡ?, s?eːk, s?eːkʷ, s?eːp, s?eːt, s?eːwd, s?eːwd?, s?eːwk, s?eːwk?, s?eːwp, s?eːwp?, s?eːwt, s?eːwt?, s?eːwɡ, s?eːwɡ?, s?i, s?ik, s?ikʷ, s?ip, s?it, s?iwd, s?iwd?, s?iwk, s?iwk?, s?iwp, s?iwp?, s?iwt, s?iwt?, s?iwɡ, s?iwɡ?, s?iː, s?iːk, s?iːkʷ, s?iːp, s?iːt, s?iːwd, s?iːwd?, s?iːwk, s?iːwk?, s?iːwp, s?iːwp?, s?iːwt, s?iːwt?, s?iːwɡ, s?iːwɡ?, s?o, s?ojd, s?ojd?, s?ojk, s?ojk?, s?ojp, s?ojp?, s?ojt, s?ojt?, s?ojɡ, s?ojɡ?, s?ok, s?okʷ, s?op, s?ot, s?owd, s?owd?, s?owk, s?owk?, s?owp, s?owp?, s?owt, s?owt?, s?owɡ, s?owɡ?, s?oː, s?oːjd, s?oːjd?, s?oːjk, s?oːjk?, s?oːjp, s?oːjp?, s?oːjt, s?oːjt?, s?oːjɡ, s?oːjɡ?, s?oːk, s?oːkʷ, s?oːp, s?oːt, s?oːwd, s?oːwd?, s?oːwk, s?oːwk?, s?oːwp, s?oːwp?, s?oːwt, s?oːwt?, s?oːwɡ, s?oːwɡ?, s?u, s?ujd, s?ujd?, s?ujk, s?ujk?, s?ujp, s?ujp?, s?ujt, s?ujt?, s?ujɡ, s?ujɡ?, s?uk, s?ukʷ, s?up, s?ut, s?uː, s?uːjd, s?uːjd?, s?uːjk, s?uːjk?, s?uːjp, s?uːjp?, s?uːjt, s?uːjt?, s?uːjɡ, s?uːjɡ?, s?uːk, s?uːkʷ, s?uːp, s?uːt, s?ɛ, s?ɛjd, s?ɛjd?, s?ɛjk, s?ɛjk?, s?ɛjp, s?ɛjp?, s?ɛjt, s?ɛjt?, s?ɛjɡ, s?ɛjɡ?, s?ɛk, s?ɛkʷ, s?ɛp, s?ɛt, s?ɛwd, s?ɛwd?, s?ɛwk, s?ɛwk?, s?ɛwp, s?ɛwp?, s?ɛwt, s?ɛwt?, s?ɛwɡ, s?ɛwɡ?, sa, sajd, sajd?, sajk, sajk?, sajp, sajp?, sajt, sajt?, sajɡ, sajɡ?, sak, sakʷ, sap, sat, sawd, sawd?, sawk, sawk?, sawp, sawp?, sawt, sawt?, sawɡ, sawɡ?, saː, saːjd, saːjd?, saːjk, saːjk?, saːjp, saːjp?, saːjt, saːjt?, saːjɡ, saːjɡ?, saːk, saːkʷ, saːp, saːt, saːwd, saːwd?, saːwk, saːwk?, saːwp, saːwp?, saːwt, saːwt?, saːwɡ, saːwɡ?, se, sejd, sejd?, sejk, sejk?, sejp, sejp?, sejt, sejt?, sejɡ, sejɡ?, sek, sekʷ, sep, set, sewd, sewd?, sewk, sewk?, sewp, sewp?, sewt, sewt?, sewɡ, sewɡ?, seː, seːjd, seːjd?, seːjk, seːjk?, seːjp, seːjp?, seːjt, seːjt?, seːjɡ, seːjɡ?, seːk, seːkʷ, seːp, seːt, seːwd, seːwd?, seːwk, seːwk?, seːwp, seːwp?, seːwt, seːwt?, seːwɡ, seːwɡ?, si, sik, sikʷ, sip, sit, siwd, siwd?, siwk, siwk?, siwp, siwp?, siwt, siwt?, siwɡ, siwɡ?, siː, siːk, siːkʷ, siːp, siːt, siːwd, siːwd?, siːwk, siːwk?, siːwp, siːwp?, siːwt, siːwt?, siːwɡ, siːwɡ?, so, sojd, sojd?, sojk, sojk?, sojp, sojp?, sojt, sojt?, sojɡ, sojɡ?, sok, sokʷ, sop, sot, sowd, sowd?, sowk, sowk?, sowp, sowp?, sowt, sowt?, sowɡ, sowɡ?, soː, soːjd, soːjd?, soːjk, soːjk?, soːjp, soːjp?, soːjt, soːjt?, soːjɡ, soːjɡ?, soːk, soːkʷ, soːp, soːt, soːwd, soːwd?, soːwk, soːwk?, soːwp, soːwp?, soːwt, soːwt?, soːwɡ, soːwɡ?, su, sujd, sujd?, sujk, sujk?, sujp, sujp?, sujt, sujt?, sujɡ, sujɡ?, suk, sukʷ, sup, sut, suː, suːjd, suːjd?, suːjk, suːjk?, suːjp, suːjp?, suːjt, suːjt?, suːjɡ, suːjɡ?, suːk, suːkʷ, suːp, suːt, sɛ, sɛjd, sɛjd?, sɛjk, sɛjk?, sɛjp, sɛjp?, sɛjt, sɛjt?, sɛjɡ, sɛjɡ?, sɛk, sɛkʷ, sɛp, sɛt, sɛwd, sɛwd?, sɛwk, sɛwk?, sɛwp, sɛwp?, sɛwt, sɛwt?, sɛwɡ, sɛwɡ?, t?a, t?ajd, t?ajd?, t?ajk, t?ajk?, t?ajp, t?ajp?, t?ajt, t?ajt?, t?ajɡ, t?ajɡ?, t?ak, t?akʷ, t?ap, t?at, t?awd, t?awd?, t?awk, t?awk?, t?awp, t?awp?, t?awt, t?awt?, t?awɡ, t?awɡ?, t?aː, t?aːjd, t?aːjd?, t?aːjk, t?aːjk?, t?aːjp, t?aːjp?, t?aːjt, t?aːjt?, t?aːjɡ, t?aːjɡ?, t?aːk, t?aːkʷ, t?aːp, t?aːt, t?aːwd, t?aːwd?, t?aːwk, t?aːwk?, t?aːwp, t?aːwp?, t?aːwt, t?aːwt?, t?aːwɡ, t?aːwɡ?, t?e, t?ejd, t?ejd?, t?ejk, t?ejk?, t?ejp, t?ejp?, t?ejt, t?ejt?, t?ejɡ, t?ejɡ?, t?ek, t?ekʷ, t?ep, t?et, t?ewd, t?ewd?, t?ewk, t?ewk?, t?ewp, t?ewp?, t?ewt, t?ewt?, t?ewɡ, t?ewɡ?, t?eː, t?eːjd, t?eːjd?, t?eːjk, t?eːjk?, t?eːjp, t?eːjp?, t?eːjt, t?eːjt?, t?eːjɡ, t?eːjɡ?, t?eːk, t?eːkʷ, t?eːp, t?eːt, t?eːwd, t?eːwd?, t?eːwk, t?eːwk?, t?eːwp, t?eːwp?, t?eːwt, t?eːwt?, t?eːwɡ, t?eːwɡ?, t?i, t?ik, t?ikʷ, t?ip, t?it, t?iwd, t?iwd?, t?iwk, t?iwk?, t?iwp, t?iwp?, t?iwt, t?iwt?, t?iwɡ, t?iwɡ?, t?iː, t?iːk, t?iːkʷ, t?iːp, t?iːt, t?iːwd, t?iːwd?, t?iːwk, t?iːwk?, t?iːwp, t?iːwp?, t?iːwt, t?iːwt?, t?iːwɡ, t?iːwɡ?, t?o, t?ojd, t?ojd?, t?ojk, t?ojk?, t?ojp, t?ojp?, t?ojt, t?ojt?, t?ojɡ, t?ojɡ?, t?ok, t?okʷ, t?op, t?ot, t?owd, t?owd?, t?owk, t?owk?, t?owp, t?owp?, t?owt, t?owt?, t?owɡ, t?owɡ?, t?oː, t?oːjd, t?oːjd?, t?oːjk, t?oːjk?, t?oːjp, t?oːjp?, t?oːjt, t?oːjt?, t?oːjɡ, t?oːjɡ?, t?oːk, t?oːkʷ, t?oːp, t?oːt, t?oːwd, t?oːwd?, t?oːwk, t?oːwk?, t?oːwp, t?oːwp?, t?oːwt, t?oːwt?, t?oːwɡ, t?oːwɡ?, t?u, t?ujd, t?ujd?, t?ujk, t?ujk?, t?ujp, t?ujp?, t?ujt, t?ujt?, t?ujɡ, t?ujɡ?, t?uk, t?ukʷ, t?up, t?ut, t?uː, t?uːjd, t?uːjd?, t?uːjk, t?uːjk?, t?uːjp, t?uːjp?, t?uːjt, t?uːjt?, t?uːjɡ, t?uːjɡ?, t?uːk, t?uːkʷ, t?uːp, t?uːt, t?ɛ, t?ɛjd, t?ɛjd?, t?ɛjk, t?ɛjk?, t?ɛjp, t?ɛjp?, t?ɛjt, t?ɛjt?, t?ɛjɡ, t?ɛjɡ?, t?ɛk, t?ɛkʷ, t?ɛp, t?ɛt, t?ɛwd, t?ɛwd?, t?ɛwk, t?ɛwk?, t?ɛwp, t?ɛwp?, t?ɛwt, t?ɛwt?, t?ɛwɡ, t?ɛwɡ?, ta, tajd, tajd?, tajk, tajk?, tajp, tajp?, tajt, tajt?, tajɡ, tajɡ?, tak, takʷ, tap, tat, tawd, tawd?, tawk, tawk?, tawp, tawp?, tawt, tawt?, tawɡ, tawɡ?, taː, taːjd, taːjd?, taːjk, taːjk?, taːjp, taːjp?, taːjt, taːjt?, taːjɡ, taːjɡ?, taːk, taːkʷ, taːp, taːt, taːwd, taːwd?, taːwk, taːwk?, taːwp, taːwp?, taːwt, taːwt?, taːwɡ, taːwɡ?, te, tejd, tejd?, tejk, tejk?, tejp, tejp?, tejt, tejt?, tejɡ, tejɡ?, tek, tekʷ, tep, tet, tewd, tewd?, tewk, tewk?, tewp, tewp?, tewt, tewt?, tewɡ, tewɡ?, teː, teːjd, teːjd?, teːjk, teːjk?, teːjp, teːjp?, teːjt, teːjt?, teːjɡ, teːjɡ?, teːk, teːkʷ, teːp, teːt, teːwd, teːwd?, teːwk, teːwk?, teːwp, teːwp?, teːwt, teːwt?, teːwɡ, teːwɡ?, ti, tik, tikʷ, tip, tit, tiwd, tiwd?, tiwk, tiwk?, tiwp, tiwp?, tiwt, tiwt?, tiwɡ, tiwɡ?, tiː, tiːk, tiːkʷ, tiːp, tiːt, tiːwd, tiːwd?, tiːwk, tiːwk?, tiːwp, tiːwp?, tiːwt, tiːwt?, tiːwɡ, tiːwɡ?, to, tojd, tojd?, tojk, tojk?, tojp, tojp?, tojt, tojt?, tojɡ, tojɡ?, tok, tokʷ, top, tot, towd, towd?, towk, towk?, towp, towp?, towt, towt?, towɡ, towɡ?, toː, toːjd, toːjd?, toːjk, toːjk?, toːjp, toːjp?, toːjt, toːjt?, toːjɡ, toːjɡ?, toːk, toːkʷ, toːp, toːt, toːwd, toːwd?, toːwk, toːwk?, toːwp, toːwp?, toːwt, toːwt?, toːwɡ, toːwɡ?, tu, tujd, tujd?, tujk, tujk?, tujp, tujp?, tujt, tujt?, tujɡ, tujɡ?, tuk, tukʷ, tup, tut, tuː, tuːjd, tuːjd?, tuːjk, tuːjk?, tuːjp, tuːjp?, tuːjt, tuːjt?, tuːjɡ, tuːjɡ?, tuːk, tuːkʷ, tuːp, tuːt, tɛ, tɛjd, tɛjd?, tɛjk, tɛjk?, tɛjp, tɛjp?, tɛjt, tɛjt?, tɛjɡ, tɛjɡ?, tɛk, tɛkʷ, tɛp, tɛt, tɛwd, tɛwd?, tɛwk, tɛwk?, tɛwp, tɛwp?, tɛwt, tɛwt?, tɛwɡ, tɛwɡ?, u, ujd, ujd?, ujk, ujk?, ujp, ujp?, ujt, ujt?, ujɡ, ujɡ?, uk, ukʷ, up, ut, uː, uːjd, uːjd?, uːjk, uːjk?, uːjp, uːjp?, uːjt, uːjt?, uːjɡ, uːjɡ?, uːk, uːkʷ, uːp, uːt, ŋa, ŋajd, ŋajd?, ŋajk, ŋajk?, ŋajp, ŋajp?, ŋajt, ŋajt?, ŋajɡ, ŋajɡ?, ŋak, ŋakʷ, ŋap, ŋat, ŋawd, ŋawd?, ŋawk, ŋawk?, ŋawp, ŋawp?, ŋawt, ŋawt?, ŋawɡ, ŋawɡ?, ŋaː, ŋaːjd, ŋaːjd?, ŋaːjk, ŋaːjk?, ŋaːjp, ŋaːjp?, ŋaːjt, ŋaːjt?, ŋaːjɡ, ŋaːjɡ?, ŋaːk, ŋaːkʷ, ŋaːp, ŋaːt, ŋaːwd, ŋaːwd?, ŋaːwk, ŋaːwk?, ŋaːwp, ŋaːwp?, ŋaːwt, ŋaːwt?, ŋaːwɡ, ŋaːwɡ?, ŋe, ŋejd, ŋejd?, ŋejk, ŋejk?, ŋejp, ŋejp?, ŋejt, ŋejt?, ŋejɡ, ŋejɡ?, ŋek, ŋekʷ, ŋep, ŋet, ŋewd, ŋewd?, ŋewk, ŋewk?, ŋewp, ŋewp?, ŋewt, ŋewt?, ŋewɡ, ŋewɡ?, ŋeː, ŋeːjd, ŋeːjd?, ŋeːjk, ŋeːjk?, ŋeːjp, ŋeːjp?, ŋeːjt, ŋeːjt?, ŋeːjɡ, ŋeːjɡ?, ŋeːk, ŋeːkʷ, ŋeːp, ŋeːt, ŋeːwd, ŋeːwd?, ŋeːwk, ŋeːwk?, ŋeːwp, ŋeːwp?, ŋeːwt, ŋeːwt?, ŋeːwɡ, ŋeːwɡ?, ŋi, ŋik, ŋikʷ, ŋip, ŋit, ŋiwd, ŋiwd?, ŋiwk, ŋiwk?, ŋiwp, ŋiwp?, ŋiwt, ŋiwt?, ŋiwɡ, ŋiwɡ?, ŋiː, ŋiːk, ŋiːkʷ, ŋiːp, ŋiːt, ŋiːwd, ŋiːwd?, ŋiːwk, ŋiːwk?, ŋiːwp, ŋiːwp?, ŋiːwt, ŋiːwt?, ŋiːwɡ, ŋiːwɡ?, ŋo, ŋojd, ŋojd?, ŋojk, ŋojk?, ŋojp, ŋojp?, ŋojt, ŋojt?, ŋojɡ, ŋojɡ?, ŋok, ŋokʷ, ŋop, ŋot, ŋowd, ŋowd?, ŋowk, ŋowk?, ŋowp, ŋowp?, ŋowt, ŋowt?, ŋowɡ, ŋowɡ?, ŋoː, ŋoːjd, ŋoːjd?, ŋoːjk, ŋoːjk?, ŋoːjp, ŋoːjp?, ŋoːjt, ŋoːjt?, ŋoːjɡ, ŋoːjɡ?, ŋoːk, ŋoːkʷ, ŋoːp, ŋoːt, ŋoːwd, ŋoːwd?, ŋoːwk, ŋoːwk?, ŋoːwp, ŋoːwp?, ŋoːwt, ŋoːwt?, ŋoːwɡ, ŋoːwɡ?, ŋu, ŋujd, ŋujd?, ŋujk, ŋujk?, ŋujp, ŋujp?, ŋujt, ŋujt?, ŋujɡ, ŋujɡ?, ŋuk, ŋukʷ, ŋup, ŋut, ŋuː, ŋuːjd, ŋuːjd?, ŋuːjk, ŋuːjk?, ŋuːjp, ŋuːjp?, ŋuːjt, ŋuːjt?, ŋuːjɡ, ŋuːjɡ?, ŋuːk, ŋuːkʷ, ŋuːp, ŋuːt, ŋɛ, ŋɛjd, ŋɛjd?, ŋɛjk, ŋɛjk?, ŋɛjp, ŋɛjp?, ŋɛjt, ŋɛjt?, ŋɛjɡ, ŋɛjɡ?, ŋɛk, ŋɛkʷ, ŋɛp, ŋɛt, ŋɛwd, ŋɛwd?, ŋɛwk, ŋɛwk?, ŋɛwp, ŋɛwp?, ŋɛwt, ŋɛwt?, ŋɛwɡ, ŋɛwɡ?, ɛ, ɛjd, ɛjd?, ɛjk, ɛjk?, ɛjp, ɛjp?, ɛjt, ɛjt?, ɛjɡ, ɛjɡ?, ɛk, ɛkʷ, ɛp, ɛt, ɛwd, ɛwd?, ɛwk, ɛwk?, ɛwp, ɛwp?, ɛwt, ɛwt?, ɛwɡ, ɛwɡ?, ɡ?a, ɡ?ajd, ɡ?ajd?, ɡ?ajk, ɡ?ajk?, ɡ?ajp, ɡ?ajp?, ɡ?ajt, ɡ?ajt?, ɡ?ajɡ, ɡ?ajɡ?, ɡ?ak, ɡ?akʷ, ɡ?ap, ɡ?at, ɡ?awd, ɡ?awd?, ɡ?awk, ɡ?awk?, ɡ?awp, ɡ?awp?, ɡ?awt, ɡ?awt?, ɡ?awɡ, ɡ?awɡ?, ɡ?aː, ɡ?aːjd, ɡ?aːjd?, ɡ?aːjk, ɡ?aːjk?, ɡ?aːjp, ɡ?aːjp?, ɡ?aːjt, ɡ?aːjt?, ɡ?aːjɡ, ɡ?aːjɡ?, ɡ?aːk, ɡ?aːkʷ, ɡ?aːp, ɡ?aːt, ɡ?aːwd, ɡ?aːwd?, ɡ?aːwk, ɡ?aːwk?, ɡ?aːwp, ɡ?aːwp?, ɡ?aːwt, ɡ?aːwt?, ɡ?aːwɡ, ɡ?aːwɡ?, ɡ?e, ɡ?ejd, ɡ?ejd?, ɡ?ejk, ɡ?ejk?, ɡ?ejp, ɡ?ejp?, ɡ?ejt, ɡ?ejt?, ɡ?ejɡ, ɡ?ejɡ?, ɡ?ek, ɡ?ekʷ, ɡ?ep, ɡ?et, ɡ?ewd, ɡ?ewd?, ɡ?ewk, ɡ?ewk?, ɡ?ewp, ɡ?ewp?, ɡ?ewt, ɡ?ewt?, ɡ?ewɡ, ɡ?ewɡ?, ɡ?eː, ɡ?eːjd, ɡ?eːjd?, ɡ?eːjk, ɡ?eːjk?, ɡ?eːjp, ɡ?eːjp?, ɡ?eːjt, ɡ?eːjt?, ɡ?eːjɡ, ɡ?eːjɡ?, ɡ?eːk, ɡ?eːkʷ, ɡ?eːp, ɡ?eːt, ɡ?eːwd, ɡ?eːwd?, ɡ?eːwk, ɡ?eːwk?, ɡ?eːwp, ɡ?eːwp?, ɡ?eːwt, ɡ?eːwt?, ɡ?eːwɡ, ɡ?eːwɡ?, ɡ?i, ɡ?ik, ɡ?ikʷ, ɡ?ip, ɡ?it, ɡ?iwd, ɡ?iwd?, ɡ?iwk, ɡ?iwk?, ɡ?iwp, ɡ?iwp?, ɡ?iwt, ɡ?iwt?, ɡ?iwɡ, ɡ?iwɡ?, ɡ?iː, ɡ?iːk, ɡ?iːkʷ, ɡ?iːp, ɡ?iːt, ɡ?iːwd, ɡ?iːwd?, ɡ?iːwk, ɡ?iːwk?, ɡ?iːwp, ɡ?iːwp?, ɡ?iːwt, ɡ?iːwt?, ɡ?iːwɡ, ɡ?iːwɡ?, ɡ?o, ɡ?ojd, ɡ?ojd?, ɡ?ojk, ɡ?ojk?, ɡ?ojp, ɡ?ojp?, ɡ?ojt, ɡ?ojt?, ɡ?ojɡ, ɡ?ojɡ?, ɡ?ok, ɡ?okʷ, ɡ?op, ɡ?ot, ɡ?owd, ɡ?owd?, ɡ?owk, ɡ?owk?, ɡ?owp, ɡ?owp?, ɡ?owt, ɡ?owt?, ɡ?owɡ, ɡ?owɡ?, ɡ?oː, ɡ?oːjd, ɡ?oːjd?, ɡ?oːjk, ɡ?oːjk?, ɡ?oːjp, ɡ?oːjp?, ɡ?oːjt, ɡ?oːjt?, ɡ?oːjɡ, ɡ?oːjɡ?, ɡ?oːk, ɡ?oːkʷ, ɡ?oːp, ɡ?oːt, ɡ?oːwd, ɡ?oːwd?, ɡ?oːwk, ɡ?oːwk?, ɡ?oːwp, ɡ?oːwp?, ɡ?oːwt, ɡ?oːwt?, ɡ?oːwɡ, ɡ?oːwɡ?, ɡ?u, ɡ?ujd, ɡ?ujd?, ɡ?ujk, ɡ?ujk?, ɡ?ujp, ɡ?ujp?, ɡ?ujt, ɡ?ujt?, ɡ?ujɡ, ɡ?ujɡ?, ɡ?uk, ɡ?ukʷ, ɡ?up, ɡ?ut, ɡ?uː, ɡ?uːjd, ɡ?uːjd?, ɡ?uːjk, ɡ?uːjk?, ɡ?uːjp, ɡ?uːjp?, ɡ?uːjt, ɡ?uːjt?, ɡ?uːjɡ, ɡ?uːjɡ?, ɡ?uːk, ɡ?uːkʷ, ɡ?uːp, ɡ?uːt, ɡ?ɛ, ɡ?ɛjd, ɡ?ɛjd?, ɡ?ɛjk, ɡ?ɛjk?, ɡ?ɛjp, ɡ?ɛjp?, ɡ?ɛjt, ɡ?ɛjt?, ɡ?ɛjɡ, ɡ?ɛjɡ?, ɡ?ɛk, ɡ?ɛkʷ, ɡ?ɛp, ɡ?ɛt, ɡ?ɛwd, ɡ?ɛwd?, ɡ?ɛwk, ɡ?ɛwk?, ɡ?ɛwp, ɡ?ɛwp?, ɡ?ɛwt, ɡ?ɛwt?, ɡ?ɛwɡ, ɡ?ɛwɡ?, ɡa, ɡajd, ɡajd?, ɡajk, ɡajk?, ɡajp, ɡajp?, ɡajt, ��ajt?, ɡajɡ, ɡajɡ?, ɡak, ɡakʷ, ɡap, ɡat, ɡawd, ɡawd?, ɡawk, ɡawk?, ɡawp, ɡawp?, ɡawt, ɡawt?, ɡawɡ, ɡawɡ?, ɡaː, ɡaːjd, ɡaːjd?, ɡaːjk, ɡaːjk?, ɡaːjp, ɡaːjp?, ɡaːjt, ɡaːjt?, ɡaːjɡ, ɡaːjɡ?, ɡaːk, ɡaːkʷ, ɡaːp, ɡaːt, ɡaːwd, ɡaːwd?, ɡaːwk, ɡaːwk?, ɡaːwp, ɡaːwp?, ɡaːwt, ɡaːwt?, ɡaːwɡ, ɡaːwɡ?, ɡe, ɡejd, ɡejd?, ɡejk, ɡejk?, ɡejp, ɡejp?, ɡejt, ɡejt?, ɡejɡ, ɡejɡ?, ɡek, ɡekʷ, ɡep, ɡet, ɡewd, ɡewd?, ɡewk, ɡewk?, ɡewp, ɡewp?, ɡewt, ɡewt?, ɡewɡ, ɡewɡ?, ɡeː, ɡeːjd, ɡeːjd?, ɡeːjk, ɡeːjk?, ɡeːjp, ɡeːjp?, ɡeːjt, ɡeːjt?, ɡeːjɡ, ɡeːjɡ?, ɡeːk, ɡeːkʷ, ɡeːp, ɡeːt, ɡeːwd, ɡeːwd?, ɡeːwk, ɡeːwk?, ɡeːwp, ɡeːwp?, ɡeːwt, ɡeːwt?, ɡeːwɡ, ɡeːwɡ?, ɡi, ɡik, ɡikʷ, ɡip, ɡit, ɡiwd, ɡiwd?, ɡiwk, ɡiwk?, ɡiwp, ɡiwp?, ɡiwt, ɡiwt?, ɡiwɡ, ɡiwɡ?, ɡiː, ɡiːk, ɡiːkʷ, ɡiːp, ɡiːt, ɡiːwd, ɡiːwd?, ɡiːwk, ɡiːwk?, ɡiːwp, ɡiːwp?, ɡiːwt, ɡiːwt?, ɡiːwɡ, ɡiːwɡ?, ɡo, ɡojd, ɡojd?, ɡojk, ɡojk?, ɡojp, ɡojp?, ɡojt, ɡojt?, ɡojɡ, ɡojɡ?, ɡok, ɡokʷ, ɡop, ɡot, ɡowd, ɡowd?, ɡowk, ɡowk?, ɡowp, ɡowp?, ɡowt, ɡowt?, ɡowɡ, ɡowɡ?, ɡoː, ɡoːjd, ɡoːjd?, ɡoːjk, ɡoːjk?, ɡoːjp, ɡoːjp?, ɡoːjt, ɡoːjt?, ɡoːjɡ, ɡoːjɡ?, ɡoːk, ɡoːkʷ, ɡoːp, ɡoːt, ɡoːwd, ɡoːwd?, ɡoːwk, ɡoːwk?, ɡoːwp, ɡoːwp?, ɡoːwt, ɡoːwt?, ɡoːwɡ, ɡoːwɡ?, ɡu, ɡujd, ɡujd?, ɡujk, ɡujk?, ɡujp, ɡujp?, ɡujt, ɡujt?, ɡujɡ, ɡujɡ?, ɡuk, ɡukʷ, ɡup, ɡut, ɡuː, ɡuːjd, ɡuːjd?, ɡuːjk, ɡuːjk?, ɡuːjp, ɡuːjp?, ɡuːjt, ɡuːjt?, ɡuːjɡ, ɡuːjɡ?, ɡuːk, ɡuːkʷ, ɡuːp, ɡuːt, ɡɛ, ɡɛjd, ɡɛjd?, ɡɛjk, ɡɛjk?, ɡɛjp, ɡɛjp?, ɡɛjt, ɡɛjt?, ɡɛjɡ, ɡɛjɡ?, ɡɛk, ɡɛkʷ, ɡɛp, ɡɛt, ɡɛwd, ɡɛwd?, ɡɛwk, ɡɛwk?, ɡɛwp, ɡɛwp?, ɡɛwt, ɡɛwt?, ɡɛwɡ, ɡɛwɡ?\r\n"
     ]
    }
   ],
   "execution_count": 109
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-dev-4982",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectDependencies": [
    "Planet.main"
   ],
   "projectLibraries": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
