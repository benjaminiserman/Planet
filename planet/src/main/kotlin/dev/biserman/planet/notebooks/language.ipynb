{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:06.107576700Z",
     "start_time": "2025-12-18T12:18:06.056854800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Language\n",
    "import dev.biserman.planet.language.Segment\n",
    "import dev.biserman.planet.language.SyllableConstructor\n",
    "import dev.biserman.planet.language.InventoryTransformation\n",
    "import dev.biserman.planet.language.Manner\n",
    "import dev.biserman.planet.language.SegmentType\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:09.317391200Z",
     "start_time": "2025-12-18T12:18:06.125446800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Glide\n",
    "import dev.biserman.planet.language.Place\n",
    "import dev.biserman.planet.language.SegmentData\n",
    "import dev.biserman.planet.utils.toWeightedBag\n",
    "import kotlin.random.Random\n",
    "\n",
    "SyllableConstructor.languageFile = \"\"\"E:\\Users\\Winggar\\source\\repos\\Planet\\planet\\english.json\"\"\"\n",
    "SyllableConstructor.phonemeFile = \"\"\"E:\\Users\\Winggar\\source\\repos\\Planet\\planet\\phonemes.json\"\"\"\n",
    "\n",
    "val basicPhonemes = \"ptksmnljw\"\n",
    "val basicTransformation: InventoryTransformation = { inventory ->\n",
    "    inventory.plus(basicPhonemes.mapNotNull { SyllableConstructor.segments[it.toString()] })\n",
    "}\n",
    "\n",
    "fun (Set<Segment>).addSet(\n",
    "    from: (SegmentData) -> Boolean,\n",
    "    to: (SegmentData) -> SegmentData,\n",
    "    condition: Boolean = true\n",
    "): Set<Segment> {\n",
    "    if (!condition) return this\n",
    "\n",
    "    val new = this\n",
    "        .filter { from(it.data) }\n",
    "        .map { to(it.data) }\n",
    "    val matching = SyllableConstructor.segments.values.filter { it.data in new }\n",
    "    return this.plus(matching)\n",
    "}\n",
    "\n",
    "val random = Random(System.currentTimeMillis())\n",
    "\n",
    "val placeWeights = mapOf(\n",
    "    Place.LABIAL to 40,\n",
    "    Place.DENTAL to 5,\n",
    "    Place.ALVEOLAR to 50,\n",
    "    Place.POSTALVEOLAR to 35,\n",
    "    Place.PALATAL to 25,\n",
    "    Place.VELAR to 45,\n",
    "    Place.UVULAR to 5,\n",
    "    Place.GLOTTAL to 50,\n",
    ")\n",
    "\n",
    "val inversePlaceWeights = (placeWeights.values.max()).let { maxWeight ->\n",
    "    placeWeights.mapValues { (_, weight) -> maxWeight - weight + 1 }\n",
    "}\n",
    "\n",
    "//val affricates = mapOf(\n",
    "//    'ɸ' to Pair('p', 10),\n",
    "//    'β' to Pair('b', 10),\n",
    "//    'f' to Pair('p', 50),\n",
    "//    'v' to Pair('b', 50),\n",
    "//    'θ' to Pair('t', 10),\n",
    "//    'ð' to Pair('d', 10),\n",
    "//    's' to Pair('t', 100),\n",
    "//    'z' to Pair('d', 100),\n",
    "//    'ʃ' to Pair('t', 250),\n",
    "//    'ʒ' to Pair('d', 250),\n",
    "//    'x' to Pair('k', 100)\n",
    "//)\n",
    "\n",
    "fun center(x: Double) = 4 * (x - 0.5).pow(3) + 0.5\n",
    "\n",
    "val inventoryTransformations = listOf<Pair<InventoryTransformation, Int>>(\n",
    "    { inventory: Set<Segment> -> // add voicing\n",
    "        val chance = random.nextDouble()\n",
    "        val newInventory = inventory.let {\n",
    "            if (chance <= 0.9) {\n",
    "                inventory.addSet(\n",
    "                    from = { it.manner == Manner.PLOSIVE },\n",
    "                    to = { it.copy(voiced = true) },\n",
    "                    condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "            } else it\n",
    "        }.let {\n",
    "            if (chance <= 0.4 || chance > 0.9) {\n",
    "                inventory.addSet(\n",
    "                    from = { it.manner == Manner.FRICATIVE },\n",
    "                    to = { it.copy(voiced = true) },\n",
    "                    condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "            } else it\n",
    "        }\n",
    "        newInventory\n",
    "    } to 600,\n",
    "    { inventory: Set<Segment> -> // add aspiration\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(isAspirated = true, voiced = null) },\n",
    "            condition = inventory.all { it.data.manner != Manner.PLOSIVE || it.data.isAspirated != true } || random.nextDouble() <= 0.25)\n",
    "    } to 400,\n",
    "    { inventory: Set<Segment> -> // add ejectives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(isEjective = true, voiced = null) })\n",
    "    } to 100,\n",
    "\n",
    "    { inventory: Set<Segment> -> // add plosives from fricatives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.PLOSIVE) })\n",
    "    } to 300,\n",
    "    { inventory: Set<Segment> -> // add fricatives from plosives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE },\n",
    "            to = { it.copy(manner = Manner.FRICATIVE) })\n",
    "    } to 300,\n",
    "\n",
    "    { inventory: Set<Segment> -> // add rhotic\n",
    "        inventory.plus(SyllableConstructor.segments[\"ɹ\"]!!)\n",
    "    } to 500,\n",
    "    { inventory: Set<Segment> -> // add implosives\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.IMPLOSIVE) })\n",
    "    } to 100,\n",
    "    { inventory: Set<Segment> -> // add clicks\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.CLICK, voiced = null) })\n",
    "    } to 100,\n",
    "    { inventory: Set<Segment> -> // add nasals\n",
    "        inventory.addSet(\n",
    "            from = { it.manner == Manner.PLOSIVE || it.manner == Manner.FRICATIVE },\n",
    "            to = { it.copy(manner = Manner.NASAL, voiced = null) })\n",
    "    } to 250,\n",
    "    { inventory: Set<Segment> -> // remove randomly\n",
    "        inventory.filter { random.nextDouble() <= center(it.prevalence).pow(0.33) }.toSet()\n",
    "    } to 500,\n",
    "\n",
    "    affricate@{ inventory: Set<Segment> -> // add affricates\n",
    "        val fricative =\n",
    "            inventory.filter { it.data.manner == Manner.FRICATIVE && it.data.place != Place.GLOTTAL }\n",
    "                .randomOrNull(random) ?: return@affricate inventory\n",
    "        val glide = Glide.from(fricative.data, false)\n",
    "        val affricate = if (random.nextDouble() <= 0.75) {\n",
    "            val place = when (fricative.data.place) {\n",
    "                Place.LABIODENTAL -> Place.BILABIAL\n",
    "                Place.POSTALVEOLAR -> Place.ALVEOLAR\n",
    "                Place.PALATAL -> Place.ALVEOLAR\n",
    "                Place.DENTAL -> Place.ALVEOLAR\n",
    "                else -> fricative.data.place\n",
    "            }\n",
    "            fricative.copyData { it.copy(place = place, manner = Manner.PLOSIVE, consonantGlide = glide) }\n",
    "        } else {\n",
    "            val plosive =\n",
    "                inventory\n",
    "                    .filter {\n",
    "                        it.data.manner == Manner.PLOSIVE &&\n",
    "                                it.data.place != Place.GLOTTAL &&\n",
    "                                it.data.isAspirated == false &&\n",
    "                                it.data.isEjective == false &&\n",
    "                                it.data.voiced == fricative.data.voiced\n",
    "                    }\n",
    "                    .randomOrNull(random) ?: return@affricate inventory\n",
    "            plosive.copyData { it.copy(consonantGlide = glide) }\n",
    "        }\n",
    "        inventory.plus(affricate)\n",
    "    } to 300,\n",
    "\n",
    "    glideColoredSet@{ inventory: Set<Segment> -> // add a glide-colored set\n",
    "        val chance = random.nextDouble()\n",
    "        val glide = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.SEMIVOWEL || it.data.manner == Manner.LIQUID }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSet inventory\n",
    "\n",
    "        val newInventory = inventory.let {\n",
    "            if (chance <= 0.67) {\n",
    "                it.plus(it.filter { it.data.manner == Manner.FRICATIVE }\n",
    "                    .map { it.copyData { it.copy(offGlide = Glide.from(glide.data, false)) } })\n",
    "            } else it\n",
    "        }.let {\n",
    "            if (chance <= 0.33 || chance > 0.67) {\n",
    "                it.plus(it.filter { it.data.manner == Manner.PLOSIVE }\n",
    "                    .filter { it.data.place != Place.GLOTTAL }\n",
    "                    .map { it.copyData { it.copy(offGlide = Glide.from(glide.data, false)) } })\n",
    "            } else it\n",
    "        }\n",
    "\n",
    "        newInventory\n",
    "    } to 200,\n",
    "\n",
    "    glideColoredSingle@{ inventory: Set<Segment> ->\n",
    "        val glide = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.SEMIVOWEL || it.data.manner == Manner.LIQUID }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSingle inventory\n",
    "\n",
    "        val plosive = SyllableConstructor.segments.values\n",
    "            .filter { it.data.manner == Manner.PLOSIVE }\n",
    "            .filter { it.data.place != Place.GLOTTAL }\n",
    "            .filter { it in inventory }\n",
    "            .randomOrNull(random) ?: return@glideColoredSingle inventory\n",
    "\n",
    "        inventory.plus(plosive.copyData { it.copy(offGlide = Glide.from(glide.data, false)) })\n",
    "    } to 300,\n",
    "\n",
    "    { inventory: Set<Segment> -> // tʃ, dʒ\n",
    "        if (inventory.any { it.data.place == Place.ALVEOLAR && it.data.manner == Manner.PLOSIVE }) {\n",
    "            val tʃ = SyllableConstructor.segments[\"t\"]!!.copyData {\n",
    "                it.copy(\n",
    "                    consonantGlide = Glide(\n",
    "                        Place.POSTALVEOLAR,\n",
    "                        Manner.FRICATIVE,\n",
    "                        false\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "            val dʒ = SyllableConstructor.segments[\"d\"]!!.copyData {\n",
    "                it.copy(\n",
    "                    consonantGlide = Glide(\n",
    "                        Place.POSTALVEOLAR,\n",
    "                        Manner.FRICATIVE,\n",
    "                        false\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "\n",
    "            if (inventory.any { it.data.place == Place.ALVEOLAR && it.data.manner == Manner.PLOSIVE && it.data.voiced == true }) {\n",
    "                inventory.plus(listOf(tʃ, dʒ))\n",
    "            } else {\n",
    "                inventory.plus(tʃ)\n",
    "            }\n",
    "        } else {\n",
    "            inventory\n",
    "        }\n",
    "    } to 200,\n",
    ").plus(placeWeights.map { (place, weight) ->\n",
    "    { inventory: Set<Segment> ->\n",
    "        inventory.addSet(\n",
    "            from = { it.type == SegmentType.CONSONANT },\n",
    "            to = { it.copy(place = place) })\n",
    "\n",
    "    } to weight * 3\n",
    "}).plus(inversePlaceWeights.map { (place, weight) ->\n",
    "    { inventory: Set<Segment> ->\n",
    "        inventory.filter { it.data.place != place }.toSet()\n",
    "    } to weight\n",
    "})\n",
    "\n",
    "val bag = inventoryTransformations.toWeightedBag(random) { it.second }\n",
    "\n",
    "fun generateConsonants() = basicTransformation(setOf()).let {\n",
    "    (1..15).fold(it) { acc, _ -> bag.grab()!!.first.invoke(acc) }\n",
    "}.sortedBy { SyllableConstructor.segments.keys.indexOf(it.symbol) }\n",
    "\n",
    "for (_1 in 0..10) {\n",
    "    val testLanguage = generateConsonants()\n",
    "    println(\"${testLanguage.size} phonemes: ${testLanguage.map { it.display }}\")\n",
    "}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 phonemes: [m, n, ŋ, p, t, tʷ, k, k͡s, ɡ, ɡˡ, f, s, w, ɹ, l]\r\n",
      "24 phonemes: [m, n, ŋ, p, p͡s, p?, t͡ʃ, t͡s, t?, k, k?, b, b?, ɡ, ɡ?, f, f?, s, s?, v, z, z?, j, l]\r\n",
      "25 phonemes: [m, n, ŋ, p, p?, t, t͡ʃ, t?, k, k?, b, b?, d, dʷ, d͡ʒ, d?, ɡ, ɡ?, s, s?, z, z?, j, w, l]\r\n",
      "21 phonemes: [m, n, ŋ, p, pʷ, t, tʷ, t͡ʃ, k, kʷ, d, d͡ʒ, ɡ, s, sʷ, z, zʷ, j, w, ɹ, l]\r\n",
      "13 phonemes: [m, n, p, t, t͡ʃ, k, kʷ, f, s, j, w, ɹ, l]\r\n",
      "15 phonemes: [m, n, ŋ, p, t, tˡ, t͡s, k, k?, f, s, v, j, ɹ, l]\r\n",
      "26 phonemes: [m, n, ŋ, p, p?, t, tʷ, t?, k, kʷ, k?, b, b?, d?, ɡ, ɡ?, f, fʷ, s, v, vʷ, z, zʷ, j, w, l]\r\n",
      "16 phonemes: [m, n, ŋ, p, pˡ, t, t͡ʃ, k, s, ʃ, z, ʒ, j, w, ɹ, l]\r\n",
      "19 phonemes: [m, n, ŋ, p, pʷ, pʳ, t, tˡ, t͡s, tʷ, tʳ, k, kʳ, f, s, j, w, ɹ, l]\r\n",
      "19 phonemes: [m, n, ŋ, p, t, t͡ʃ, k, b, d, d͡ʒ, ɡ, f, s, v, z, ʔ, w, ɹ, l]\r\n",
      "17 phonemes: [m, n, p, t, t͡s, t?, k, k?, b, d, f, s, v, z, j, w, ɹ]\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:18:09.440949100Z",
     "start_time": "2025-12-18T12:18:09.327801100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SyllableConstructor.segments.entries.map {\n",
    "    println(\"${it.key} - ${it.value}\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m - Segment(symbol=m, data=SegmentData(type=CONSONANT, place=LABIAL, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.97)\r\n",
      "n - Segment(symbol=n, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.97)\r\n",
      "ŋ - Segment(symbol=ŋ, data=SegmentData(type=CONSONANT, place=VELAR, manner=NASAL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.69)\r\n",
      "p - Segment(symbol=p, data=SegmentData(type=CONSONANT, place=LABIAL, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.95)\r\n",
      "t - Segment(symbol=t, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.99)\r\n",
      "k - Segment(symbol=k, data=SegmentData(type=CONSONANT, place=VELAR, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.99)\r\n",
      "b - Segment(symbol=b, data=SegmentData(type=CONSONANT, place=LABIAL, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.7)\r\n",
      "d - Segment(symbol=d, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.7)\r\n",
      "ɡ - Segment(symbol=ɡ, data=SegmentData(type=CONSONANT, place=VELAR, manner=PLOSIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.64)\r\n",
      "f - Segment(symbol=f, data=SegmentData(type=CONSONANT, place=LABIAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.46)\r\n",
      "θ - Segment(symbol=θ, data=SegmentData(type=CONSONANT, place=DENTAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.04)\r\n",
      "s - Segment(symbol=s, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.8)\r\n",
      "ʃ - Segment(symbol=ʃ, data=SegmentData(type=CONSONANT, place=POSTALVEOLAR, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.54)\r\n",
      "v - Segment(symbol=v, data=SegmentData(type=CONSONANT, place=LABIAL, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.3)\r\n",
      "z - Segment(symbol=z, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.4)\r\n",
      "ʒ - Segment(symbol=ʒ, data=SegmentData(type=CONSONANT, place=POSTALVEOLAR, manner=FRICATIVE, voiced=true, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.37)\r\n",
      "ʔ - Segment(symbol=ʔ, data=SegmentData(type=CONSONANT, place=GLOTTAL, manner=PLOSIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.4)\r\n",
      "h - Segment(symbol=h, data=SegmentData(type=CONSONANT, place=GLOTTAL, manner=FRICATIVE, voiced=false, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.6)\r\n",
      "j - Segment(symbol=j, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=SEMIVOWEL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.92)\r\n",
      "w - Segment(symbol=w, data=SegmentData(type=CONSONANT, place=LABIAL, manner=SEMIVOWEL, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.86)\r\n",
      "ɹ - Segment(symbol=ɹ, data=SegmentData(type=CONSONANT, place=RETROFLEX, manner=LIQUID, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.06)\r\n",
      "l - Segment(symbol=l, data=SegmentData(type=CONSONANT, place=ALVEOLAR, manner=LIQUID, voiced=null, isAspirated=false, isEjective=false, height=null, depth=null, rounded=null, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.83)\r\n",
      "i - Segment(symbol=i, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.98)\r\n",
      "u - Segment(symbol=u, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE, depth=BACK, rounded=true, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.94)\r\n",
      "ɪ - Segment(symbol=ɪ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=NEAR_CLOSE, depth=NEAR_FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.18)\r\n",
      "e - Segment(symbol=e, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE_MID, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.78)\r\n",
      "o - Segment(symbol=o, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=CLOSE_MID, depth=BACK, rounded=true, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.77)\r\n",
      "ɛ - Segment(symbol=ɛ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN_MID, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.43)\r\n",
      "ʌ - Segment(symbol=ʌ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN_MID, depth=BACK, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.06)\r\n",
      "æ - Segment(symbol=æ, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=NEAR_OPEN, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.1)\r\n",
      "a - Segment(symbol=a, data=SegmentData(type=VOWEL, place=null, manner=null, voiced=null, isAspirated=null, isEjective=null, height=OPEN, depth=FRONT, rounded=false, consonantGlide=null, onGlide=null, offGlide=null, nasalized=null, lengthened=null), prevalence=0.95)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit, kotlin.Unit]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:41.009554500Z",
     "start_time": "2025-12-18T12:25:40.505977400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.geometry.scaleAndCoerceIn\n",
    "import dev.biserman.planet.language.Depth\n",
    "import dev.biserman.planet.language.Height\n",
    "\n",
    "val vowelDistanceFeatures = listOf(\n",
    "    SegmentData::depth,\n",
    "    SegmentData::height,\n",
    "    SegmentData::rounded,\n",
    "    SegmentData::lengthened,\n",
    "    SegmentData::nasalized,\n",
    "    SegmentData::onGlide,\n",
    "    SegmentData::offGlide,\n",
    ")\n",
    "\n",
    "inline fun <reified T : Enum<T>> center() = (enumValues<T>().size / 2.0).roundToInt()\n",
    "\n",
    "@JvmName(\"vowelNonNull\")\n",
    "fun (Glide).vowel(isOnGlide: Boolean): Segment = (this as Glide?).vowel(isOnGlide)!!\n",
    "fun (Glide?).vowel(isOnGlide: Boolean): Segment? {\n",
    "    return when {\n",
    "        this == null -> null\n",
    "        this.manner != Manner.SEMIVOWEL -> null\n",
    "        this.place == Place.PALATAL ->\n",
    "            SyllableConstructor.segments[\"i\"]!!\n",
    "        this.place == Place.LABIAL ->\n",
    "            if (isOnGlide) SyllableConstructor.segments[\"u\"]\n",
    "            else SyllableConstructor.segments[\"o\"]\n",
    "        else -> null\n",
    "    }\n",
    "}\n",
    "\n",
    "fun (Segment?).vowelDistanceTo(other: Segment?): Int = if (this == null || other == null) 0 else\n",
    "    (vowelDistanceFeatures.count { feature -> feature.get(this.data) != feature.get(other.data) }\n",
    "            + (this.data.height!!.ordinal - other.data.height!!.ordinal).absoluteValue\n",
    "            + (this.data.depth!!.ordinal - other.data.depth!!.ordinal).absoluteValue\n",
    "            + (this.data.onGlide.vowel(true).vowelDistanceTo(other.data.onGlide.vowel(true)))\n",
    "            + (this.data.offGlide.vowel(false).vowelDistanceTo(other.data.offGlide.vowel(false))))\n",
    "\n",
    "val (SegmentData).isFrontward get() = this.depth!!.ordinal < Depth.CENTRAL.ordinal\n",
    "val (SegmentData).isBackward get() = this.depth!!.ordinal > Depth.CENTRAL.ordinal\n",
    "val (SegmentData).isHigh get() = this.height!!.ordinal < Height.MID.ordinal\n",
    "val (SegmentData).isLow get() = this.height!!.ordinal > Height.MID.ordinal\n",
    "\n",
    "fun generateVowels(): List<Segment> {\n",
    "    val allVowels = SyllableConstructor.segments.values\n",
    "        .filter { it.data.type == SegmentType.VOWEL }\n",
    "\n",
    "    val baseVowels = allVowels\n",
    "        .filter { random.nextDouble() <= it.prevalence }\n",
    "\n",
    "    // adjusts for typo.uni-konstanz.de → Universal 1284\n",
    "    fun heightNasalityAdjustment(height: Height) = (-height.ordinal.toDouble()).scaleAndCoerceIn(-6.0..0.0, 0.7..1.3)\n",
    "\n",
    "    val nasalVowels = if (random.nextDouble() <= 0.2) {\n",
    "        baseVowels.filter {\n",
    "            val chance = random.nextDouble() * heightNasalityAdjustment(it.data.height!!)\n",
    "            chance <= it.prevalence * 1.5\n",
    "        }.map { it.copy(data = it.data.copy(nasalized = true)) }\n",
    "    } else allVowels.filter {\n",
    "        random.nextDouble() <= it.prevalence * 0.05 * heightNasalityAdjustment(it.data.height!!)\n",
    "    }.map { it.copy(data = it.data.copy(nasalized = true)) }\n",
    "\n",
    "    val longVowels = if (random.nextDouble() <= 0.35) {\n",
    "        baseVowels.plus(nasalVowels).filter {\n",
    "            val chance = random.nextDouble()\n",
    "            chance <= it.prevalence * 2.0\n",
    "        }.map { it.copy(data = it.data.copy(lengthened = true)) }\n",
    "    } else listOf()\n",
    "\n",
    "    val wOnGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"u\" }\n",
    "            .map { it.copy(data = it.data.copy(onGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, true))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"u\" }\n",
    "        .map { it.copy(data = it.data.copy(onGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, true))) }\n",
    "\n",
    "    val jOnGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"i\" }\n",
    "            .map { it.copy(data = it.data.copy(onGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, true))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"i\" }\n",
    "        .map { it.copy(data = it.data.copy(onGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, true))) }\n",
    "\n",
    "    val wOffGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .plus(jOnGlides)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"o\" }\n",
    "            .map { it.copy(data = it.data.copy(offGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, false))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"o\" }\n",
    "        .map { it.copy(data = it.data.copy(offGlide = Glide(Place.LABIAL, Manner.SEMIVOWEL, false))) }\n",
    "\n",
    "    val jOffGlides = if (random.nextDouble() <= 0.02) {\n",
    "        baseVowels.plus(nasalVowels)\n",
    "            .plus(wOnGlides)\n",
    "            .filter {\n",
    "                val chance = random.nextDouble()\n",
    "                chance <= it.prevalence * 2.0\n",
    "            }\n",
    "            .filter { it.symbol != \"i\" }\n",
    "            .map { it.copy(data = it.data.copy(offGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, false))) }\n",
    "    } else allVowels.filter { random.nextDouble() <= it.prevalence * 0.01 }\n",
    "        .filter { it.symbol != \"i\" }\n",
    "        .map { it.copy(data = it.data.copy(offGlide = Glide(Place.PALATAL, Manner.SEMIVOWEL, false))) }\n",
    "\n",
    "    return baseVowels + nasalVowels + longVowels + wOnGlides + jOnGlides + wOffGlides + jOffGlides\n",
    "}\n",
    "\n",
    "for (_1 in 0..10) {\n",
    "    println(generateVowels().map { it.display })\n",
    "}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i, u, e, o, a, ao̯]\r\n",
      "[i, u, e, o, a]\r\n",
      "[i, u, ɪ, o, ɛ, a]\r\n",
      "[i, u, e, ɛ, a, ĩ, ũ, ẽ, ɛ̃, ã]\r\n",
      "[i, u, ɪ, ɛ, æ, a, ĩ, ũ, ã, iː, uː, ɪː, ɛː, aː, ĩː, ũː, ãː]\r\n",
      "[i, u, e, o, ɛ, a]\r\n",
      "[i, u, e, o, a, iː, uː, eː, oː, aː]\r\n",
      "[i, u, e, a, io̯, uo̯, eo̯, ao̯]\r\n",
      "[i, o, ɛ, a]\r\n",
      "[i, u, e, o, a, ĩ, ũ, ẽ, õ, ã]\r\n",
      "[i, u, e, a, ĩ, ũ, ẽ, ã, u̯e]\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T22:51:43.769113200Z",
     "start_time": "2025-12-18T22:51:43.432518400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val allGlides = SyllableConstructor.segments.values\n",
    "    .filter { it.data.place != Place.GLOTTAL }\n",
    "    .filter {\n",
    "        it.data.manner in listOf(\n",
    "            Manner.FRICATIVE,\n",
    "            Manner.SEMIVOWEL,\n",
    "            Manner.LIQUID\n",
    "        )\n",
    "    }.flatMap { listOf(Glide.from(it.data, false), Glide.from(it.data, true)) }\n",
    "    .toSet()\n",
    "    .plus(null)\n",
    "\n",
    "data class ConsonantSlot(\n",
    "    val manner: Set<Manner> = Manner.values().toSet(),\n",
    "    val place: Set<Place> = Place.values().toSet(),\n",
    "    val voiced: Set<Boolean?> = setOf(true, false, null),\n",
    "    val consonantGlide: Set<Glide?> = allGlides.filter { it?.manner == Manner.FRICATIVE || it?.manner == null }.toSet(),\n",
    "    val offGlide: Set<Glide?> = allGlides.filter { it?.manner != Manner.FRICATIVE }.toSet()\n",
    ") {\n",
    "    fun getMatching(segments: List<Segment>) = segments.filter {\n",
    "        it.data.type == SegmentType.CONSONANT &&\n",
    "                it.data.manner in manner &&\n",
    "                it.data.place in place &&\n",
    "                it.data.voiced in voiced &&\n",
    "                it.data.consonantGlide in consonantGlide &&\n",
    "                it.data.offGlide in offGlide\n",
    "    }\n",
    "\n",
    "    companion object\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T22:51:44.844008700Z",
     "start_time": "2025-12-18T22:51:44.699292100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlin.random.nextInt\n",
    "\n",
    "fun (ConsonantSlot.Companion).gen(consonants: List<Segment>): ConsonantSlot {\n",
    "    val mainCandidates = (1..random.nextInt(1..2)).map { consonants.random() }\n",
    "    val secondaryCandidates = (1..random.nextInt(1..3)).map { consonants.random() }\n",
    "\n",
    "    return ConsonantSlot(\n",
    "        manner = mainCandidates.map { it.data.manner!! }.toSet(),\n",
    "        place = (mainCandidates + secondaryCandidates).map { it.data.place!! }.toSet(),\n",
    "        voiced = (mainCandidates + secondaryCandidates).map { it.data.voiced }.toSet(),\n",
    "        consonantGlide = mainCandidates.map { it.data.consonantGlide }.plus(null).toSet(),\n",
    "        offGlide = mainCandidates.map { it.data.offGlide }.plus(null).toSet()\n",
    "    )\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:41.811438800Z",
     "start_time": "2025-12-18T12:25:41.691592700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// adapted from: https://gist.github.com/erikhuizinga/d2ca2b501864df219fd7f25e4dd000a4\n",
    "\n",
    "import kotlin.reflect.KFunction\n",
    "\n",
    "/**\n",
    " * Create the cartesian product of any number of sets of any size. Useful for parameterized tests\n",
    " * to generate a large parameter space with little code. Note that any type information is lost, as\n",
    " * the returned set contains list of any combination of types in the input set.\n",
    " *\n",
    " * @param sets The sets.\n",
    " */\n",
    "fun <T> cartesianProduct(vararg sets: Set<T>) =\n",
    "    sets\n",
    "        .fold(listOf(listOf<T>())) { acc, set ->\n",
    "            acc.flatMap { list -> set.map { element -> list + element } }\n",
    "        }\n",
    "        .toSet()\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:42.479562200Z",
     "start_time": "2025-12-18T12:25:41.838356800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun isSonoritySequenced(cluster: List<ConsonantSlot>, isOnset: Boolean): Boolean = when {\n",
    "    isOnset -> cluster\n",
    "        .windowed(size = 2) { (a, b) ->\n",
    "            a.manner.minOf { it.ordinal } >= b.manner.maxOf { it.ordinal } &&\n",
    "                    (a.manner.maxOf { it.ordinal } < Manner.PLOSIVE.ordinal || b.manner.maxOf { it.ordinal } < Manner.PLOSIVE.ordinal)\n",
    "        }\n",
    "        .all { it }\n",
    "    else -> isSonoritySequenced(cluster.reversed(), !isOnset)\n",
    "}\n",
    "\n",
    "typealias Cluster = List<ConsonantSlot>\n",
    "\n",
    "fun generateClusters(\n",
    "    onsetMaxConsonants: Int,\n",
    "    codaMaxConsonants: Int,\n",
    "    fallOff: Double,\n",
    "    sonoritySequencingStrictness: Double,\n",
    "    consonants: List<Segment>\n",
    "): Pair<List<Cluster>, List<Cluster>> {\n",
    "    val onsetClusters = mutableListOf<List<ConsonantSlot>>(\n",
    "        listOf(\n",
    "            ConsonantSlot(\n",
    "                manner = consonants.mapNotNull { it.data.manner }.toSet(),\n",
    "                place = consonants.mapNotNull { it.data.place }.toSet(),\n",
    "                voiced = consonants.map { it.data.voiced }.toSet(),\n",
    "                consonantGlide = consonants.map { it.data.consonantGlide }.toSet(),\n",
    "                offGlide = consonants.map { it.data.offGlide }.toSet()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    val codaClusters = mutableListOf<List<ConsonantSlot>>(listOf())\n",
    "\n",
    "    if (random.nextDouble() < 0.98) onsetClusters.add(listOf())\n",
    "\n",
    "    for (i in 2..onsetMaxConsonants) {\n",
    "        val attempts = max(1.0, onsetMaxConsonants - i * fallOff + random.nextDouble(-2.0, 1.0)).roundToInt()\n",
    "        for (_j in 1..attempts) {\n",
    "            while (true) {\n",
    "                val newCluster =\n",
    "                    if (i >= 3 && random.nextDouble() < 0.5)\n",
    "                        listOf(ConsonantSlot.gen(consonants)) + onsetClusters.filter { it.size == i - 1 }.random()\n",
    "                    else (1..i).map { ConsonantSlot.gen(consonants) }\n",
    "                if (random.nextDouble() < sonoritySequencingStrictness.pow(1.0 / i) &&\n",
    "                    !isSonoritySequenced(newCluster, true)\n",
    "                ) continue\n",
    "                if (newCluster.any { it.getMatching(consonants).isEmpty() }) continue\n",
    "\n",
    "                onsetClusters.add(newCluster)\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for (i in 1..codaMaxConsonants) {\n",
    "        val attempts = max(1.0, codaMaxConsonants - i * fallOff + random.nextDouble(-2.0, 1.0)).roundToInt()\n",
    "        for (_j in 1..attempts) {\n",
    "            val mustBeSonoritySequenced = random.nextDouble() < sonoritySequencingStrictness\n",
    "            while (true) {\n",
    "                val newCluster = if (i >= 3 && random.nextDouble() < 0.5)\n",
    "                    codaClusters.filter { it.size == i - 1 }.random().plus(ConsonantSlot.gen(consonants))\n",
    "                else (1..i).map { ConsonantSlot.gen(consonants) }\n",
    "                if (mustBeSonoritySequenced && !isSonoritySequenced(newCluster, false)) {\n",
    "                    continue\n",
    "                }\n",
    "                if (newCluster.any { it.getMatching(consonants).isEmpty() }) continue\n",
    "\n",
    "                codaClusters.add(newCluster)\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return onsetClusters to codaClusters\n",
    "}\n",
    "\n",
    "data class Syllable(val onset: List<Segment>, val nucleus: List<Segment>, val coda: List<Segment>) {\n",
    "    val allConsonants by lazy { onset + coda }\n",
    "    val length get() = onset.size + nucleus.size + coda.size\n",
    "    override fun toString() =\n",
    "        \"${onset.joinToString(\"\") { it.display }}${nucleus.joinToString(\"\") { it.display }}${coda.joinToString(\"\") { it.display }}\"\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:28.429927200Z",
     "start_time": "2025-12-19T02:40:27.560420800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.SyllableConstructor\n",
    "import kotlin.reflect.KProperty1\n",
    "\n",
    "class SyllableRule(val name: String, val tag: String = \"\", val check: (Syllable) -> Boolean)\n",
    "\n",
    "class Prop<T, U>(val name: String, val get: (T) -> U) {\n",
    "    constructor(prop: KProperty1<T, U>) : this(prop.name, prop)\n",
    "}\n",
    "\n",
    "fun generateSyllableRules(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    maxOnset: Int,\n",
    "    maxCoda: Int\n",
    "): List<SyllableRule> {\n",
    "    val rules = mutableListOf<SyllableRule>()\n",
    "\n",
    "    class SidedRule(val segment: Segment, val allowedInOnset: Boolean, val allowedInCoda: Boolean)\n",
    "\n",
    "    val possibleOnsetClusters = onsetClusters.map { cluster -> cluster.flatMap { it.getMatching(consonants) } }\n",
    "    val possibleCodaClusters = codaClusters.map { cluster -> cluster.flatMap { it.getMatching(consonants) } }\n",
    "//    val allPossibleOnsets = possibleOnsetClusters.flatten().toSet()\n",
    "    val allPossibleCodas = possibleCodaClusters.flatten().toSet()\n",
    "\n",
    "    if (maxOnset > 0 && maxCoda > 0) {\n",
    "//        val isRareRestrictive = random.nextDouble() < 0.33\n",
    "        val sidedPhonemeRules = consonants\n",
    "            .filter { consonant -> (possibleOnsetClusters + possibleOnsetClusters).none { it.size == 1 && it.first() == consonant } }\n",
    "            .map { consonant ->\n",
    "                when (consonant.display[0]) {\n",
    "                    in \"ŋɳ\" -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.7 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.65 && consonant in allPossibleOnsets -> SidedRule(consonant, true, false)\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                    in \"ptkmnlr\" -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.97 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.85 && consonant in allPossibleOnsets -> SidedRule(consonant, true, false)\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                    else -> random.nextDouble().let {\n",
    "                        when {\n",
    "                            it >= 0.95 && consonant in allPossibleCodas -> SidedRule(consonant, false, true)\n",
    "//                            it >= 0.85 || isRareRestrictive && consonant in allPossibleOnsets -> SidedRule(\n",
    "//                                consonant,\n",
    "//                                true,\n",
    "//                                false\n",
    "//                            )\n",
    "                            else -> SidedRule(consonant, true, true)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }.filter { !it.allowedInOnset || !it.allowedInCoda }.map { rule ->\n",
    "                SyllableRule(\"${rule.segment.display} Sidedness (${rule.allowedInOnset}-${rule.allowedInCoda})\") {\n",
    "                    (rule.segment !in it.onset || rule.allowedInOnset) &&\n",
    "                            (rule.segment !in it.coda || rule.allowedInCoda)\n",
    "                }\n",
    "            }\n",
    "        rules.addAll(sidedPhonemeRules)\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.99 && maxOnset > 1 || maxCoda > 1) {\n",
    "        rules.add(SyllableRule(\"Offglide-Glide Adjacency\") { syllable ->\n",
    "            listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                cluster.windowed(size = 2) { (a, b) ->\n",
    "                    a.data.offGlide == null\n",
    "                            || a.data.offGlide!!.manner != Manner.SEMIVOWEL\n",
    "                            || a.data.offGlide!!.place != b.data.place\n",
    "                }.all { it }\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.8 && consonants.any { it.data.manner == Manner.SEMIVOWEL }) {\n",
    "        rules.add(SyllableRule(\"Semivowel-Vowel Adjacency\") { syllable ->\n",
    "            val onset = syllable.onset.size == 0 ||\n",
    "                    (syllable.onset.last().symbol != \"w\" || syllable.nucleus.first().symbol != \"u\") &&\n",
    "                    (syllable.onset.last().symbol != \"j\" || syllable.nucleus.first().symbol != \"i\")\n",
    "\n",
    "            val coda = syllable.coda.size == 0 ||\n",
    "                    (syllable.coda.first().symbol != \"w\" || syllable.nucleus.last().symbol != \"u\") &&\n",
    "                    (syllable.coda.first().symbol != \"j\" || syllable.nucleus.last().symbol != \"i\")\n",
    "            onset && coda\n",
    "        })\n",
    "    }\n",
    "\n",
    "    while (random.nextDouble() <= 0.33) {\n",
    "        val place = listOf(Syllable::onset, Syllable::coda, Syllable::allConsonants).random()\n",
    "        val consonantFeature = listOf(SegmentData::place, SegmentData::manner, SegmentData::voiced).random()\n",
    "        val vowelFeatures = listOf(\n",
    "            Prop(SegmentData::onGlide),\n",
    "            Prop(SegmentData::offGlide),\n",
    "            Prop(SegmentData::nasalized),\n",
    "            Prop(SegmentData::lengthened),\n",
    "            Prop(SegmentData::rounded),\n",
    "            Prop<SegmentData, Boolean>(\"isHigh\") { it.isHigh },\n",
    "            Prop<SegmentData, Boolean>(\"isLow\") { it.isLow },\n",
    "            Prop<SegmentData, Boolean>(\"isBackward\") { it.isBackward },\n",
    "            Prop<SegmentData, Boolean>(\"isFrontward\") { it.isFrontward },\n",
    "        ).filter { feature -> vowels.groupBy { feature.get(it.data) }.size > 1 }\n",
    "        if (vowelFeatures.isEmpty()) break\n",
    "        val vowelFeature = vowelFeatures.random()\n",
    "        val modelConsonant = consonants.random()\n",
    "        val modelVowel = vowels.random()\n",
    "        val vowelSet = vowels.filter { vowelFeature.get(it.data) == vowelFeature.get(modelVowel.data) }\n",
    "\n",
    "        rules.add(\n",
    "            SyllableRule(\n",
    "                \"${consonantFeature.name} ${consonantFeature.get(modelConsonant.data)} consonants cannot co-occur with {${vowelSet.joinToString { it.display }}} in ${place.name}\"\n",
    "            ) { syllable ->\n",
    "                place.get(syllable)\n",
    "                    .none { consonant -> consonantFeature.get(consonant.data) == consonantFeature.get(modelConsonant.data) } ||\n",
    "                        syllable.nucleus.none { vowel -> vowel in vowelSet }\n",
    "            })\n",
    "    }\n",
    "\n",
    "    if (vowels.any { it.data.nasalized == true }\n",
    "        && consonants.any { it.data.manner == Manner.NASAL }\n",
    "        && random.nextDouble() <= 0.5\n",
    "    ) random.nextDouble().let {\n",
    "        val onsetNasal =\n",
    "            onsetClusters.any { it.size > 0 && (Manner.NASAL in it.last().manner || it.last().offGlide.any { it?.manner == Manner.NASAL }) }\n",
    "        val codaNasal =\n",
    "            codaClusters.any { it.size > 0 && Manner.NASAL in it.first().manner }\n",
    "        when {\n",
    "            it <= 0.33 && onsetNasal && codaNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } ==\n",
    "                            (syllable.onset.lastOrNull()?.data?.manner == Manner.NASAL\n",
    "                                    || syllable.onset.lastOrNull()?.data?.offGlide?.manner == Manner.NASAL\n",
    "                                    || syllable.coda.lastOrNull()?.data?.manner == Manner.NASAL)\n",
    "                })\n",
    "            it <= 0.66 && codaNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals (Coda)\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } == (syllable.coda.firstOrNull()?.data?.manner == Manner.NASAL)\n",
    "                })\n",
    "            onsetNasal -> rules.add(\n",
    "                SyllableRule(\n",
    "                    \"Nasalized Vowels only adjacent to Nasals (Onset)\",\n",
    "                    \"restricted_nasal_vowels\"\n",
    "                ) { syllable ->\n",
    "                    syllable.nucleus.any { it.data.nasalized == true } ==\n",
    "                            (syllable.onset.lastOrNull()?.data?.manner == Manner.NASAL\n",
    "                                    || syllable.onset.lastOrNull()?.data?.offGlide?.manner == Manner.NASAL)\n",
    "                })\n",
    "            else -> {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (maxOnset > 1 || maxCoda > 1) {\n",
    "        // needs probability analysis\n",
    "        if (random.nextDouble() <= 0.95) {\n",
    "            rules.add(SyllableRule(\"Homorganic Consonant Voicing\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                    cluster.windowed(size = 2) { (a, b) -> a.data.voiced == b.data.voiced || a.data.voiced == null || b.data.voiced == null }\n",
    "                        .all { it }\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "\n",
    "        // geminate consonants should be represented phonemically or via cross-syllable rules\n",
    "        rules.add(SyllableRule(\"No Geminate Consonants\") { syllable ->\n",
    "            listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                cluster.windowed(size = 2) { (a, b) -> a.display.last() != b.display.first() && a.symbol != b.symbol && a.data != b.data }\n",
    "                    .all { it }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        // needs probability analysis\n",
    "        if (random.nextDouble() <= 0.95) {\n",
    "            rules.add(SyllableRule(\"All Offglides must be Cluster-final\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda)\n",
    "                    .all { cluster ->\n",
    "                        cluster.size <= 1 || cluster.take(cluster.size - 1)\n",
    "                            .all { it.data.consonantGlide == null || it.data.consonantGlide?.manner == Manner.FRICATIVE }\n",
    "                    }\n",
    "            })\n",
    "        }\n",
    "\n",
    "        // needs probability analysis\n",
    "        while (random.nextDouble() <= 0.66) {\n",
    "            val manners = (onsetClusters + codaClusters)\n",
    "                .filter { it.size >= 2 }.random()\n",
    "                .windowed(size = 2).random()\n",
    "                .map { it.manner.random() }\n",
    "                .sortedByDescending { it.ordinal }\n",
    "\n",
    "            if (manners[0] == manners[1]) {\n",
    "                continue\n",
    "            }\n",
    "\n",
    "            rules.add(SyllableRule(\"Homorganic ${manners[0]}-${manners[1]} Consonant Placing\") { syllable ->\n",
    "                listOf(syllable.onset, syllable.coda).all { cluster ->\n",
    "                    cluster.windowed(size = 2) { (a, b) -> a.data.place == b.data.place || a.data.manner !in manners || b.data.manner !in manners }\n",
    "                        .all { it }\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return rules.distinctBy { it.name }\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:28.607327100Z",
     "start_time": "2025-12-19T02:40:28.466168100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun generateSyllable(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    syllableRules: List<SyllableRule> = listOf()\n",
    "): Syllable {\n",
    "    while (true) {\n",
    "        val onset = onsetClusters.random()\n",
    "        val nucleus = vowels.random()\n",
    "        val coda = codaClusters.random()\n",
    "\n",
    "        val syllable = Syllable(\n",
    "            onset.map { it.getMatching(consonants).random() },\n",
    "            listOf(nucleus),\n",
    "            coda.map { it.getMatching(consonants).random() }\n",
    "        )\n",
    "\n",
    "        if (syllableRules.all { it.check(syllable) }) return syllable\n",
    "    }\n",
    "}\n",
    "\n",
    "fun generateAllSyllables(\n",
    "    consonants: List<Segment>,\n",
    "    vowels: List<Segment>,\n",
    "    onsetClusters: List<List<ConsonantSlot>>,\n",
    "    codaClusters: List<List<ConsonantSlot>>,\n",
    "    syllableRules: List<SyllableRule>\n",
    "): List<Syllable> {\n",
    "    val allOnsetClusters = onsetClusters.flatMap { cluster ->\n",
    "        cartesianProduct(*cluster.map { slot ->\n",
    "            slot.getMatching(consonants)\n",
    "                .toSet()\n",
    "        }.toTypedArray())\n",
    "    }.toSet()\n",
    "\n",
    "    val allCodaClusters = codaClusters.flatMap { cluster ->\n",
    "        cartesianProduct(*cluster.map { slot ->\n",
    "            slot.getMatching(consonants)\n",
    "                .toSet()\n",
    "        }.toTypedArray())\n",
    "    }.toSet()\n",
    "\n",
    "    return cartesianProduct(\n",
    "        allOnsetClusters,\n",
    "        vowels.map { listOf(it) }.toSet(),\n",
    "        allCodaClusters\n",
    "    ).map { (onset, nucleus, coda) ->\n",
    "        Syllable(onset, nucleus, coda)\n",
    "    }.filter { syllable -> syllableRules.all { it.check(syllable) } }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:28.787304500Z",
     "start_time": "2025-12-19T02:40:28.613883800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.UtilityExtensions.formatDigits\n",
    "\n",
    "fun weighSyllables(consonants: List<Segment>, vowels: List<Segment>, syllables: List<Syllable>): Map<Syllable, Double> {\n",
    "    fun (Segment).glideCount() = listOf(\n",
    "        this.data.onGlide,\n",
    "        this.data.offGlide,\n",
    "        this.data.consonantGlide\n",
    "    ).count { it != null }\n",
    "\n",
    "    fun weighSegments(segments: List<Segment>): Map<Segment, Double> {\n",
    "        val segmentOrdering =\n",
    "            segments.sortedByDescending { it.prevalence + (random.nextDouble().pow(2) - 0.5) }\n",
    "        val offset = random.nextDouble(1.5, 3.5)\n",
    "        val power = random.nextDouble(0.7, 1.3)\n",
    "        val segmentWeights = segmentOrdering.withIndex().associate { (index, segment) ->\n",
    "            segment to 1.0 / (index + offset).pow(power)\n",
    "        }\n",
    "\n",
    "        return segmentWeights\n",
    "    }\n",
    "\n",
    "    val consonantWeights = weighSegments(consonants)\n",
    "    val vowelWeights = weighSegments(vowels)\n",
    "\n",
    "    println(\"top consonants: ${consonantWeights.entries.sortedByDescending { it.value }.take(10).joinToString(\", \") { \"${it.key.display} (${it.value.formatDigits(2)})\" }}\")\n",
    "    println(\"top vowels: ${vowelWeights.entries.sortedByDescending { it.value }.take(10).joinToString(\", \") { \"${it.key.display} (${it.value.formatDigits()})\" }}\")\n",
    "\n",
    "    fun (Segment).complexity() = 1 + this.glideCount() +\n",
    "            (if (this.data.lengthened == true) 1 else 0) +\n",
    "            (if (this.data.nasalized == true) 1 else 0)\n",
    "\n",
    "    fun (Syllable).complexity() = (\n",
    "            (if (this.onset.size == 0) 1 else this.onset.sumOf { it.complexity() }) +\n",
    "                    this.nucleus.sumOf { it.complexity() } +\n",
    "                    this.coda.sumOf { it.complexity() }) *\n",
    "            max(1, this.length - 1)\n",
    "\n",
    "    return syllables.associateWith { syllable ->\n",
    "        val baseWeight = (syllable.onset.fold(1.0) { acc, it -> acc * consonantWeights.getValue(it) } +\n",
    "                syllable.nucleus.fold(1.0) { acc, it -> acc * vowelWeights.getValue(it) } +\n",
    "                syllable.coda.fold(1.0) { acc, it -> acc * consonantWeights.getValue(it) })\n",
    "        val nullOnsetAdjustment = if (syllable.onset.isEmpty()) consonantWeights.values.random() else 1.0\n",
    "        baseWeight * nullOnsetAdjustment * random.nextDouble(0.5, 1.5) / syllable.complexity().toDouble()\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:29.256244Z",
     "start_time": "2025-12-19T02:40:28.836802900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.language.Depth\n",
    "\n",
    "class WordTransformation(val name: String, val tag: String = \"\", val transform: (List<Syllable>) -> List<Syllable>)\n",
    "\n",
    "fun generateWordTransformations(\n",
    "    syllables: List<Syllable>,\n",
    "): List<WordTransformation> {\n",
    "    val consonants = syllables.flatMap { it.allConsonants }.toSet()\n",
    "    val vowels = syllables.flatMap { it.nucleus }.toSet()\n",
    "    val onsetClusters = syllables.map { it.onset }.toSet()\n",
    "//    val codaClusters = syllables.map { it.coda }.toSet()\n",
    "\n",
    "    val transformations = mutableListOf<WordTransformation>()\n",
    "\n",
    "    val glottalStop = SyllableConstructor.segments[\"ʔ\"]!!\n",
    "    if (random.nextDouble() <= 0.25\n",
    "        && onsetClusters.any { it.size == 0 }\n",
    "    ) {\n",
    "        transformations.add(WordTransformation(\"Add glottal stops to word-initial vowels\") { syllables ->\n",
    "            val first = syllables.first()\n",
    "            if (first.onset.isNotEmpty()) syllables else listOf(\n",
    "                first.copy(onset = listOf(glottalStop).plus(first.onset.drop(1)))\n",
    "            ).plus(syllables.drop(1))\n",
    "        })\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.25 && vowels.size >= 6) {\n",
    "        val vowelFeatures =\n",
    "            listOf(\n",
    "                Prop(SegmentData::depth),\n",
    "                Prop(SegmentData::height),\n",
    "                Prop(SegmentData::nasalized),\n",
    "                Prop(SegmentData::rounded),\n",
    "                Prop<SegmentData, Boolean>(\"isHigh\") { it.isHigh },\n",
    "                Prop<SegmentData, Boolean>(\"isLow\") { it.isLow },\n",
    "                Prop<SegmentData, Boolean>(\"isBackward\") { it.isBackward },\n",
    "                Prop<SegmentData, Boolean>(\"isFrontward\") { it.isFrontward },\n",
    "            ).associateWith { feature -> vowels.groupBy { feature.get(it.data) }.values.filter { it.size > 3 } }\n",
    "                .filterValues { featureGroups -> featureGroups.size == 2 }\n",
    "\n",
    "        if (vowelFeatures.isNotEmpty()) {\n",
    "            val (chosenFeature, groups) = vowelFeatures.entries.random()\n",
    "            val (firstGroup, secondGroup) = groups\n",
    "\n",
    "            val foreMap = firstGroup.associateWith { first -> secondGroup.minBy { first.vowelDistanceTo(it) } }\n",
    "            val aftMap = secondGroup.associateWith { second -> firstGroup.minBy { second.vowelDistanceTo(it) } }\n",
    "\n",
    "            transformations.add(WordTransformation(\"Vowel harmony via ${chosenFeature.name}\") { syllables ->\n",
    "                val primaryVowel = (syllables\n",
    "                    .firstOrNull { syllable -> syllable.nucleus.any { it.data.lengthened == true || it.data.onGlide != null || it.data.offGlide != null } }\n",
    "                    ?: syllables.first()).nucleus.first()\n",
    "\n",
    "                when (primaryVowel) {\n",
    "                    in firstGroup -> syllables.map { syllable ->\n",
    "                        syllable.copy(nucleus = syllable.nucleus.map {\n",
    "                            aftMap[it] ?: it\n",
    "                        })\n",
    "                    }\n",
    "                    in secondGroup -> syllables.map { syllable ->\n",
    "                        syllable.copy(nucleus = syllable.nucleus.map {\n",
    "                            foreMap[it] ?: it\n",
    "                        })\n",
    "                    }\n",
    "                    else -> syllables\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (random.nextDouble() <= 0.25) {\n",
    "        transformations.add(WordTransformation(\"Interject glottal stop between adjacent vowels\", \"intervocalic_glottal_stop\") { syllables ->\n",
    "            syllables.drop(1).fold(syllables.take(1)) { acc, syllable ->\n",
    "                if (acc.last().coda.isEmpty() && syllable.onset.isEmpty()) {\n",
    "                    acc.plus(syllable.copy(onset = listOf(glottalStop)))\n",
    "                } else acc.plus(syllable)\n",
    "            }\n",
    "        })\n",
    "    } else {\n",
    "        transformations.add(WordTransformation(\"Elide adjacent identical vowels\") { syllables ->\n",
    "            syllables.drop(1).fold(syllables.take(1)) { acc, syllable ->\n",
    "                val lastVowel = acc.last().nucleus.last()\n",
    "                val trueLastVowel =\n",
    "                    if (lastVowel.data.offGlide != null) lastVowel.data.offGlide.vowel(false)!! else lastVowel\n",
    "                val nextVowel = syllable.nucleus.first()\n",
    "                val trueNextVowel =\n",
    "                    if (nextVowel.data.onGlide != null) nextVowel.data.onGlide.vowel(true)!! else nextVowel\n",
    "                if (acc.last().coda.isEmpty()\n",
    "                    && syllable.onset.isEmpty()\n",
    "                    && (trueLastVowel.data.depth == trueNextVowel.data.depth\n",
    "                            && trueLastVowel.data.height == trueNextVowel.data.height\n",
    "                            && trueLastVowel.data.rounded == trueNextVowel.data.rounded)\n",
    "                ) {\n",
    "                    val canLengthen = vowels.any { it.data.lengthened == true }\n",
    "                    acc.dropLast(1).plus(\n",
    "                        acc.last()\n",
    "                            .copy(\n",
    "                                nucleus = if (canLengthen) syllable.nucleus.map { it.copy(data = it.data.copy(lengthened = true)) }\n",
    "                                else syllable.nucleus,\n",
    "                                coda = syllable.coda\n",
    "                            )\n",
    "                    )\n",
    "                } else acc.plus(syllable)\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    return transformations.toList()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:29.346717Z",
     "start_time": "2025-12-19T02:40:29.271705200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.WeightedBag\n",
    "\n",
    "fun generateWord(\n",
    "    length: Int,\n",
    "    syllableBag: WeightedBag<Syllable>,\n",
    "    wordTransformations: List<WordTransformation>\n",
    "): List<Syllable> {\n",
    "    return wordTransformations\n",
    "        .fold((1..length).map { syllableBag.grab()!! }) { syllables, transformation ->\n",
    "            transformation.transform(\n",
    "                syllables\n",
    "            )\n",
    "        }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:29.560077800Z",
     "start_time": "2025-12-19T02:40:29.358983900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Letter(val lowerCase: String, val titleCase: String, val upperCase: String) {\n",
    "    constructor (lowerCase: String) : this(lowerCase, lowerCase.uppercase(), lowerCase.uppercase())\n",
    "    constructor (lowerCase: String, upperCase: String) : this(lowerCase, upperCase, upperCase)\n",
    "}\n",
    "\n",
    "class EnglishOrthographyConfig(\n",
    "    val enableDiacritics: Boolean = true,\n",
    "    val enableDiaresis: Boolean = true,\n",
    "    val enableLigatures: Boolean = true,\n",
    "    val enableToneMarkers: Boolean = false,\n",
    "    val enableComplexSyllables: Boolean = false,\n",
    "    val enableSpecialCharacters: Boolean = false,\n",
    ")\n",
    "\n",
    "fun generateEnglishOrthography(\n",
    "    syllables: List<Syllable>,\n",
    "    wordTransformations: List<WordTransformation>,\n",
    "    config: EnglishOrthographyConfig = EnglishOrthographyConfig()\n",
    "): (List<Syllable>) -> (String) {\n",
    "    val consonants = syllables.flatMap { it.allConsonants }.toSet()\n",
    "    val vowels = syllables.flatMap { it.nucleus }.toSet()\n",
    "\n",
    "    val baseVowels = vowels\n",
    "        .filter { it.data.onGlide == null && it.data.offGlide == null }\n",
    "        .groupBy { it.copy(data = it.data.copy(nasalized = false, lengthened = false)) }\n",
    "        .values\n",
    "        .map { it.minBy { (if (it.data.nasalized == true) 2 else 0) + (if (it.data.lengthened == true) 1 else 0) } }\n",
    "\n",
    "    val baseLetters = mutableMapOf<String, Letter>()\n",
    "\n",
    "    // if this was the ONLY vowel, what letter would it have? ordered by priority\n",
    "    val preferredVowels = mapOf(\n",
    "        \"ɪ\" to \"i\",\n",
    "        \"i\" to \"i,y\",\n",
    "        \"ʏ\" to \"i,y\",\n",
    "\n",
    "        \"ɛ\" to \"e\",\n",
    "        \"e̞\" to \"e\",\n",
    "        \"ɘ\" to \"e\",\n",
    "        \"ɜ\" to \"e\",\n",
    "        \"e\" to \"e\",\n",
    "\n",
    "        \"u\" to \"u\",\n",
    "        \"ʉ\" to \"u\",\n",
    "        \"y\" to \"u\",\n",
    "        \"ʊ\" to \"u\",\n",
    "        \"ɯ\" to \"u\",\n",
    "        \"ɤ\" to \"u,e\",\n",
    "        \"ɤ̞\" to \"u,e\",\n",
    "        \"œ\" to \"u,e\",\n",
    "        \"ø\" to \"u\",\n",
    "        \"ø̞\" to \"u\",\n",
    "\n",
    "        \"o\" to \"o\",\n",
    "        \"o̞\" to \"o\",\n",
    "\n",
    "        \"ɵ\" to \"o\",\n",
    "\n",
    "        \"a\" to \"a\",\n",
    "        \"ɐ\" to \"a\",\n",
    "        \"ä\" to \"a\",\n",
    "        \"ɑ\" to \"a\",\n",
    "        \"ɒ\" to \"a\",\n",
    "        \"ʌ\" to \"a\",\n",
    "        \"æ\" to \"a\",\n",
    "        \"ɞ\" to \"a\",\n",
    "\n",
    "        \"ɨ\" to \"u,i\",\n",
    "        \"ɶ\" to \"u,a\",\n",
    "        \"ɔ\" to \"o,a\",\n",
    "        \"ə\" to \"e,u,o,a,i\",\n",
    "    )\n",
    "\n",
    "    preferredVowels.keys\n",
    "        .filter { vowel -> baseVowels.any { it.symbol == vowel } }\n",
    "        .forEach { vowel ->\n",
    "            val options = preferredVowels[vowel]!!.split(\",\")\n",
    "            val chosen = options.firstOrNull { option -> baseLetters.values.none { option in it.lowerCase } }\n",
    "            if (chosen != null) {\n",
    "                baseLetters[vowel] = Letter(chosen)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    val hasPolyphthongs = vowels.any { it.data.offGlide != null || it.data.onGlide != null }\n",
    "    val adjacentVowelsPossible =\n",
    "        wordTransformations.none { it.tag == \"intervocalic_glottal_stop\" } && syllables.any { it.onset.size == 0 }\n",
    "    val useDiaresis = config.enableDiaresis && adjacentVowelsPossible && random.nextDouble() < 0.5\n",
    "    val canDigraphVowels = !adjacentVowelsPossible || useDiaresis\n",
    "    val noCodaH = syllables.none { it.coda.first().symbol == \"h\" }\n",
    "\n",
    "    val weakI = baseVowels.firstOrNull { it.symbol == \"ɪ\" } ?: baseVowels.firstOrNull { it.symbol == \"ʏ\" }\n",
    "    val strongI = baseVowels.firstOrNull { it.symbol == \"i\" } ?: baseVowels.firstOrNull { it.symbol == \"ɨ\" }\n",
    "    if (weakI != null && strongI != null) {\n",
    "        if ((canDigraphVowels || noCodaH) && (random.nextDouble() <= 0.5 || !config.enableDiacritics)) {\n",
    "            if (!canDigraphVowels || random.nextDouble() <= 0.5) {\n",
    "                baseLetters[weakI.symbol] = Letter(\"ih\", \"Ih\", \"IH\")\n",
    "                baseLetters[strongI.symbol] = Letter(\"i\")\n",
    "            } else {\n",
    "                baseLetters[weakI.symbol] = Letter(\"i\")\n",
    "                baseLetters[strongI.symbol] = Letter(\"ee\", \"Ee\", \"EE\")\n",
    "            }\n",
    "        } else if (config.enableDiacritics) {\n",
    "            baseLetters[weakI.symbol] =\n",
    "                if (config.enableSpecialCharacters && random.nextDouble() <= 0.1) Letter(\"ɪ\", \"I\")\n",
    "                else Letter(\"ı\", \"I\")\n",
    "            baseLetters[strongI.symbol] = Letter(\"i\", \"İ\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val schwaLike = \"ə,ɘ,ɜ,ɐ,ɞ,ɤ,œ\".split(\",\")\n",
    "    val unallocatedSchwa =\n",
    "        schwaLike.firstOrNull { schwa -> schwa !in baseLetters && baseVowels.any { it.symbol == schwa } }\n",
    "    if (unallocatedSchwa != null && noCodaH) {\n",
    "        baseLetters[unallocatedSchwa] = Letter(\"uh\", \"Uh\", \"UH\")\n",
    "    }\n",
    "\n",
    "    val aLike = \"æ,a,ɐ,ä,ɑ,ɶ\".split(\",\")\n",
    "    val includedALike = aLike.filter { a -> baseVowels.any { it.symbol == a } }\n",
    "    val combineAllAh = !config.enableLigatures && !config.enableDiacritics\n",
    "    if (includedALike.size > 1\n",
    "        && noCodaH\n",
    "        && (combineAllAh || (random.nextDouble() <= 0.5 && includedALike.size == 2))\n",
    "    ) {\n",
    "        baseLetters[includedALike.first()] = Letter(\"a\")\n",
    "        includedALike.drop(1).forEach { baseLetters[it] = Letter(\"ah\", \"Ah\", \"AH\") }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    if (vowels.any { it.symbol !in baseLetters } && canDigraphVowels && (random.nextDouble() < 0.5 || !config.enableDiacritics)) {\n",
    "        val preferredVowelDigraphs = mapOf(\n",
    "            \"œ\" to \"eu\",\n",
    "            \"ʏ\" to \"eu\",\n",
    "\n",
    "            \"ɒ\" to \"au\",\n",
    "            \"ɶ\" to \"au\",\n",
    "\n",
    "            \"ɛ\" to \"e\",\n",
    "            \"e̞\" to \"e\",\n",
    "            \"ɘ\" to \"e\",\n",
    "            \"ɜ\" to \"e\",\n",
    "            \"e\" to \"e\",\n",
    "\n",
    "            \"u\" to \"u\",\n",
    "            \"ʉ\" to \"u\",\n",
    "            \"y\" to \"u\",\n",
    "            \"ʊ\" to \"u\",\n",
    "            \"ɯ\" to \"u\",\n",
    "            \"ɤ\" to \"u,e\",\n",
    "            \"ɤ̞\" to \"u,e\",\n",
    "            \"ø\" to \"u\",\n",
    "            \"ø̞\" to \"u\",\n",
    "\n",
    "            \"o\" to \"o\",\n",
    "            \"o̞\" to \"o\",\n",
    "\n",
    "            \"ɵ\" to \"o\",\n",
    "\n",
    "            \"a\" to \"a\",\n",
    "            \"ɐ\" to \"a\",\n",
    "            \"ä\" to \"a\",\n",
    "            \"ɑ\" to \"a\",\n",
    "            \"ʌ\" to \"a\",\n",
    "            \"æ\" to \"a\",\n",
    "            \"ɞ\" to \"a\",\n",
    "\n",
    "            \"ɨ\" to \"u,i\",\n",
    "            \"ɔ\" to \"o,a\",\n",
    "            \"ə\" to \"e,u,o,a,i\",\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    return ({ \"\" })\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:40:30.258261500Z",
     "start_time": "2025-12-19T02:40:29.651449600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.biserman.planet.utils.UtilityExtensions.formatDigits\n",
    "import kotlin.random.nextInt\n",
    "\n",
    "val consonants = generateConsonants()\n",
    "println(\"consonants: ${consonants.map { it.display }}\")\n",
    "\n",
    "val vowels = generateVowels()\n",
    "println(\"vowels: ${vowels.map { it.display }}\")\n",
    "\n",
    "val onsetMaxConsonants = random.nextDouble().let {\n",
    "    when {\n",
    "        it <= 0.2 -> 3\n",
    "        it <= 0.8 -> 2\n",
    "        else -> 1\n",
    "    }\n",
    "}\n",
    "val codaMaxConsonants = min(3, onsetMaxConsonants + random.nextInt(-1..1))\n",
    "println(\"max onset consonants: $onsetMaxConsonants, coda consonants: $codaMaxConsonants\")\n",
    "\n",
    "val fallOff = random.nextDouble()\n",
    "println(\"fall off: $fallOff\")\n",
    "\n",
    "val sonoritySequencingStrictness = random.nextDouble(0.5, 1.0).pow(0.33)\n",
    "println(\"sonority sequencing strictness: ${sonoritySequencingStrictness.formatDigits()}\")\n",
    "\n",
    "val (onsetClusters, codaClusters) = generateClusters(\n",
    "    onsetMaxConsonants,\n",
    "    codaMaxConsonants,\n",
    "    fallOff,\n",
    "    sonoritySequencingStrictness,\n",
    "    consonants\n",
    ")\n",
    "println(\"onset patterns (${onsetClusters.size}):\\n${onsetClusters.joinToString(\"\") { \" - $it\\n\" }}\")\n",
    "println(\"coda patterns (${codaClusters.size}):\\n${codaClusters.joinToString(\"\") { \" - $it\\n\" }}\")\n",
    "\n",
    "val syllableRules =\n",
    "    generateSyllableRules(consonants, vowels, onsetClusters, codaClusters, onsetMaxConsonants, codaMaxConsonants)\n",
    "println(\"syllable rules:\\n${syllableRules.joinToString(\"\") { \" - ${it.name}\\n\" }}\")\n",
    "\n",
    "\n",
    "val allSyllables = generateAllSyllables(consonants, vowels, onsetClusters, codaClusters, syllableRules)\n",
    "\n",
    "val trueOnsets = allSyllables.map { it.onset }.distinct()\n",
    "val trueCodas = allSyllables.map { it.coda }.distinct()\n",
    "\n",
    "println(\"onsets (${trueOnsets.size}): ${trueOnsets.map { it.joinToString(\"\") { it.display } }}\")\n",
    "println(\"codas (${trueCodas.size}): ${trueCodas.map { it.joinToString(\"\") { it.display } }}\")\n",
    "\n",
    "println(\n",
    "    \"sample syllables: ${\n",
    "        (1..20).map { allSyllables.random().toString() }.joinToString()\n",
    "    }\"\n",
    ")\n",
    "\n",
    "val syllableWeights = weighSyllables(consonants, vowels, allSyllables)\n",
    "println(\n",
    "    \"top 20 syllables:\\n${\n",
    "        syllableWeights.toList()\n",
    "            .sortedByDescending { it.second }\n",
    "            .take(20)\n",
    "            .joinToString(\"\") { \" - ${it.first}: ${it.second.formatDigits()}\\n\" }\n",
    "    }\"\n",
    ")\n",
    "\n",
    "val wordTransformations = generateWordTransformations(allSyllables)\n",
    "val syllableBag = syllableWeights.keys.toWeightedBag(random) { syllableWeights[it]!! }\n",
    "val averageWordLength = 20.0 / log(allSyllables.size.toDouble(), 2.0)\n",
    "\n",
    "if (wordTransformations.isEmpty()) println(\"No word transformations.\\n\")\n",
    "else {\n",
    "    println(\"word transformations:\\n${wordTransformations.joinToString(\"\") { \" - ${it.name}\\n\" }}\")\n",
    "    println(\n",
    "        \"example transformations:\\n${\n",
    "            (1..10).map {\n",
    "                val word = (1..ceil(averageWordLength).toInt()).map { syllableBag.grab()!! }\n",
    "                word.joinToString(\"\") to wordTransformations\n",
    "                    .fold(word) { word, transformation -> transformation.transform(word) }\n",
    "                    .joinToString(\"\")\n",
    "            }.joinToString(\"\") {\n",
    "                \" - ${it.first} → ${it.second}\\n\"\n",
    "\n",
    "            }\n",
    "        }\"\n",
    "    )\n",
    "}\n",
    "\n",
    "println(\n",
    "    \"example sentences:\\n${\n",
    "        (1..5).joinToString(\"\") {\n",
    "            \" - \" + (1..random.nextInt(\n",
    "                4,\n",
    "                12\n",
    "            )).joinToString(\" \") {\n",
    "                generateWord(\n",
    "                    (averageWordLength * (random.nextDouble() * random.nextDouble()).scaleAndCoerceIn(\n",
    "                        0.0..1.0,\n",
    "                        0.5..1.5\n",
    "                    )).roundToInt(), syllableBag, wordTransformations\n",
    "                ).joinToString(\"\")\n",
    "            } + \"\\n\"\n",
    "        }\n",
    "    }\"\n",
    ")\n",
    "\n",
    "println(\n",
    "    \"total possible syllables (${allSyllables.size}): ${\n",
    "        allSyllables.map { it.toString() }\n",
    "            .sorted()\n",
    "            .joinToString()\n",
    "    }\"\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consonants: [m, p, pʳ, p?, t, tʳ, k, kʳ, b, bʳ, d, ɡ, ɡʳ, f, s, v, z, j, l]\r\n",
      "vowels: [i, u, o, æ, a, ĩ, ũ, õ, ã, i̯u, i̯o, i̯a, i̯ũ, i̯õ, i̯ã, ui̯, oi̯, ai̯, ũi̯, õi̯, ãi̯]\r\n",
      "max onset consonants: 3, coda consonants: 3\r\n",
      "fall off: 0.49911956674283775\r\n",
      "sonority sequencing strictness: 0.95\r\n",
      "onset patterns (5):\n",
      " - [ConsonantSlot(manner=[NASAL, PLOSIVE, FRICATIVE, SEMIVOWEL, LIQUID], place=[LABIAL, ALVEOLAR, VELAR], voiced=[null, false, true], consonantGlide=[null, Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false)])]\n",
      " - []\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[VELAR, ALVEOLAR], voiced=[true, null], consonantGlide=[Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), null]), ConsonantSlot(manner=[LIQUID], place=[ALVEOLAR, LABIAL, VELAR], voiced=[null, false], consonantGlide=[null])]\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[VELAR], voiced=[true], consonantGlide=[Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), null]), ConsonantSlot(manner=[NASAL], place=[LABIAL, ALVEOLAR], voiced=[null, false], consonantGlide=[null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE, PLOSIVE], place=[LABIAL], voiced=[false], consonantGlide=[null, Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false)]), ConsonantSlot(manner=[FRICATIVE, NASAL], place=[LABIAL], voiced=[true, null, false], consonantGlide=[null]), ConsonantSlot(manner=[LIQUID, NASAL], place=[ALVEOLAR, LABIAL], voiced=[null, true, false], consonantGlide=[null])]\n",
      "\r\n",
      "coda patterns (9):\n",
      " - []\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[LABIAL], voiced=[false, true], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), null])]\n",
      " - [ConsonantSlot(manner=[PLOSIVE], place=[LABIAL, VELAR], voiced=[false, true], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[ALVEOLAR], voiced=[false], consonantGlide=[null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[LABIAL, ALVEOLAR], voiced=[true, false], consonantGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[ALVEOLAR, LABIAL], voiced=[true, false], consonantGlide=[null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[ALVEOLAR, VELAR], voiced=[true, false], consonantGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[LABIAL], voiced=[true], consonantGlide=[null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[ALVEOLAR, LABIAL], voiced=[false, null], consonantGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[LABIAL, VELAR], voiced=[false, true], consonantGlide=[Glide(place=ALVEOLAR, manner=SEMIVOWEL, isOnGlide=false), Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE], place=[ALVEOLAR, LABIAL], voiced=[true, null, false], consonantGlide=[null]), ConsonantSlot(manner=[FRICATIVE], place=[LABIAL], voiced=[true], consonantGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[ALVEOLAR, LABIAL, VELAR], voiced=[false, true], consonantGlide=[Glide(place=RETROFLEX, manner=LIQUID, isOnGlide=false), null])]\n",
      " - [ConsonantSlot(manner=[FRICATIVE, NASAL], place=[ALVEOLAR, LABIAL], voiced=[true, null, false], consonantGlide=[null]), ConsonantSlot(manner=[FRICATIVE], place=[ALVEOLAR], voiced=[false, null], consonantGlide=[null]), ConsonantSlot(manner=[PLOSIVE], place=[LABIAL, ALVEOLAR], voiced=[true, null], consonantGlide=[null])]\n",
      "\r\n",
      "syllable rules:\n",
      " - Offglide-Glide Adjacency\n",
      " - Semivowel-Vowel Adjacency\n",
      " - manner PLOSIVE consonants cannot co-occur with {i, æ, a, ĩ, ã, i̯a, i̯ã, ai̯, ãi̯} in coda\n",
      " - Nasalized Vowels only adjacent to Nasals (Coda)\n",
      " - Homorganic Consonant Voicing\n",
      " - No Geminate Consonants\n",
      " - All Offglides must be Cluster-final\n",
      "\r\n",
      "onsets (27): [m, p, pʳ, p?, t, tʳ, k, kʳ, b, bʳ, d, ɡ, ɡʳ, f, s, v, z, j, l, , dl, ɡl, ɡm, pml, pfm, pfl, fml]\r\n",
      "codas (32): [, s, p, p?, b, pʳ, k, kʳ, bʳ, ɡ, ɡʳ, fp, ft, sp, st, vb, vd, zb, zd, fpʳ, fp?, fk, fkʳ, spʳ, sp?, sk, skʳ, zvb, zvbʳ, zvd, zvɡ, zvɡʳ]\r\n",
      "sample syllables: dlui̯st, lai̯s, ɡʳi̯ofkʳ, jusp?, pʳofk, ki̯ovd, ɡʳi, p?uzvd, ɡlui̯bʳ, i̯uzvbʳ, zozvbʳ, bʳop?, ɡʳuvd, uvb, p?i̯osk, ti̯oɡʳ, pfli̯usk, bi̯ovb, bʳoi̯ɡʳ, ɡmui̯fp?\r\n",
      "top consonants: t (0.33), k (0.22), j (0.17), s (0.14), f (0.11), p (0.10), tʳ (0.08), ɡ (0.07), l (0.06), bʳ (0.06)\r\n",
      "top vowels: ũ (0.47), i (0.33), ai̯ (0.25), ui̯ (0.20), u (0.17), i̯ã (0.15), ĩ (0.13), i̯u (0.12), i̯ũ (0.11), ã (0.10)\r\n",
      "top 20 syllables:\n",
      " - ti: 1.12\n",
      " - si: 1.05\n",
      " - bi: 1.02\n",
      " - ki: 1.01\n",
      " - ju: 0.97\n",
      " - zi: 0.96\n",
      " - ko: 0.96\n",
      " - mi: 0.95\n",
      " - ku: 0.93\n",
      " - jo: 0.92\n",
      " - tæ: 0.91\n",
      " - su: 0.90\n",
      " - po: 0.87\n",
      " - di: 0.84\n",
      " - bo: 0.84\n",
      " - zo: 0.83\n",
      " - ma: 0.81\n",
      " - fi: 0.80\n",
      " - da: 0.80\n",
      " - tui̯: 0.75\n",
      "\r\n",
      "word transformations:\n",
      " - Elide adjacent identical vowels\n",
      "\r\n",
      "example transformations:\n",
      " - zokoi̯ft → zokoi̯ft\n",
      " - bi̯oftji̯o → bi̯oftji̯o\n",
      " - fmli̯okpmli̯a → fmli̯okpmli̯a\n",
      " - ɡæɡui̯ → ɡæɡui̯\n",
      " - pui̯za → pui̯za\n",
      " - boi̯fmli̯opʳ → boi̯fmli̯opʳ\n",
      " - fui̯sbi̯u → fui̯sbi̯u\n",
      " - ki̯uptʳoi̯ → ki̯uptʳoi̯\n",
      " - dui̯da → dui̯da\n",
      " - pmlitui̯vd → pmlitui̯vd\n",
      "\r\n",
      "example sentences:\n",
      " - ju vofpʳ za si̯ufp? lui̯ fu kʳai̯ ma tui̯ tobʳ do\n",
      " - p?itʳup? di pʳoi̯fi̯u joi̯ pʳok tupʳli̯up? tʳai̯ pai̯bæ bʳa\n",
      " - ɡʳæ zoji̯osk jo di̯o da\n",
      " - fai̯ ta fu fi̯op? ba jui̯zvbbʳu foi̯ lo fukʳlo\n",
      " - p?ui̯ mi tozvbʳvo pʳi̯op?po ti̯a\n",
      "\r\n",
      "total possible syllables (5452): a, ai̯, ai̯s, as, ba, bai̯, bai̯s, bas, bi, bis, bi̯a, bi̯as, bi̯o, bi̯ob, bi̯obʳ, bi̯ofk, bi̯ofkʳ, bi̯ofp, bi̯ofp?, bi̯ofpʳ, bi̯oft, bi̯ok, bi̯okʳ, bi̯op, bi̯op?, bi̯opʳ, bi̯os, bi̯osk, bi̯oskʳ, bi̯osp, bi̯osp?, bi̯ospʳ, bi̯ost, bi̯ovb, bi̯ovd, bi̯ozb, bi̯ozd, bi̯ozvb, bi̯ozvbʳ, bi̯ozvd, bi̯ozvɡ, bi̯ozvɡʳ, bi̯oɡ, bi̯oɡʳ, bi̯u, bi̯ub, bi̯ubʳ, bi̯ufk, bi̯ufkʳ, bi̯ufp, bi̯ufp?, bi̯ufpʳ, bi̯uft, bi̯uk, bi̯ukʳ, bi̯up, bi̯up?, bi̯upʳ, bi̯us, bi̯usk, bi̯uskʳ, bi̯usp, bi̯usp?, bi̯uspʳ, bi̯ust, bi̯uvb, bi̯uvd, bi̯uzb, bi̯uzd, bi̯uzvb, bi̯uzvbʳ, bi̯uzvd, bi̯uzvɡ, bi̯uzvɡʳ, bi̯uɡ, bi̯uɡʳ, bo, bob, bobʳ, bofk, bofkʳ, bofp, bofp?, bofpʳ, boft, boi̯, boi̯b, boi̯bʳ, boi̯fk, boi̯fkʳ, boi̯fp, boi̯fp?, boi̯fpʳ, boi̯ft, boi̯k, boi̯kʳ, boi̯p, boi̯p?, boi̯pʳ, boi̯s, boi̯sk, boi̯skʳ, boi̯sp, boi̯sp?, boi̯spʳ, boi̯st, boi̯vb, boi̯vd, boi̯zb, boi̯zd, boi̯zvb, boi̯zvbʳ, boi̯zvd, boi̯zvɡ, boi̯zvɡʳ, boi̯ɡ, boi̯ɡʳ, bok, bokʳ, bop, bop?, bopʳ, bos, bosk, boskʳ, bosp, bosp?, bospʳ, bost, bovb, bovd, bozb, bozd, bozvb, bozvbʳ, bozvd, bozvɡ, bozvɡʳ, boɡ, boɡʳ, bu, bub, bubʳ, bufk, bufkʳ, bufp, bufp?, bufpʳ, buft, bui̯, bui̯b, bui̯bʳ, bui̯fk, bui̯fkʳ, bui̯fp, bui̯fp?, bui̯fpʳ, bui̯ft, bui̯k, bui̯kʳ, bui̯p, bui̯p?, bui̯pʳ, bui̯s, bui̯sk, bui̯skʳ, bui̯sp, bui̯sp?, bui̯spʳ, bui̯st, bui̯vb, bui̯vd, bui̯zb, bui̯zd, bui̯zvb, bui̯zvbʳ, bui̯zvd, bui̯zvɡ, bui̯zvɡʳ, bui̯ɡ, bui̯ɡʳ, buk, bukʳ, bup, bup?, bupʳ, bus, busk, buskʳ, busp, busp?, buspʳ, bust, buvb, buvd, buzb, buzd, buzvb, buzvbʳ, buzvd, buzvɡ, buzvɡʳ, buɡ, buɡʳ, bæ, bæs, bʳa, bʳai̯, bʳai̯s, bʳas, bʳi, bʳis, bʳi̯a, bʳi̯as, bʳi̯o, bʳi̯ob, bʳi̯obʳ, bʳi̯ofk, bʳi̯ofkʳ, bʳi̯ofp, bʳi̯ofp?, bʳi̯ofpʳ, bʳi̯oft, bʳi̯ok, bʳi̯okʳ, bʳi̯op, bʳi̯op?, bʳi̯opʳ, bʳi̯os, bʳi̯osk, bʳi̯oskʳ, bʳi̯osp, bʳi̯osp?, bʳi̯ospʳ, bʳi̯ost, bʳi̯ovb, bʳi̯ovd, bʳi̯ozb, bʳi̯ozd, bʳi̯ozvb, bʳi̯ozvbʳ, bʳi̯ozvd, bʳi̯ozvɡ, bʳi̯ozvɡʳ, bʳi̯oɡ, bʳi̯oɡʳ, bʳi̯u, bʳi̯ub, bʳi̯ubʳ, bʳi̯ufk, bʳi̯ufkʳ, bʳi̯ufp, bʳi̯ufp?, bʳi̯ufpʳ, bʳi̯uft, bʳi̯uk, bʳi̯ukʳ, bʳi̯up, bʳi̯up?, bʳi̯upʳ, bʳi̯us, bʳi̯usk, bʳi̯uskʳ, bʳi̯usp, bʳi̯usp?, bʳi̯uspʳ, bʳi̯ust, bʳi̯uvb, bʳi̯uvd, bʳi̯uzb, bʳi̯uzd, bʳi̯uzvb, bʳi̯uzvbʳ, bʳi̯uzvd, bʳi̯uzvɡ, bʳi̯uzvɡʳ, bʳi̯uɡ, bʳi̯uɡʳ, bʳo, bʳob, bʳobʳ, bʳofk, bʳofkʳ, bʳofp, bʳofp?, bʳofpʳ, bʳoft, bʳoi̯, bʳoi̯b, bʳoi̯bʳ, bʳoi̯fk, bʳoi̯fkʳ, bʳoi̯fp, bʳoi̯fp?, bʳoi̯fpʳ, bʳoi̯ft, bʳoi̯k, bʳoi̯kʳ, bʳoi̯p, bʳoi̯p?, bʳoi̯pʳ, bʳoi̯s, bʳoi̯sk, bʳoi̯skʳ, bʳoi̯sp, bʳoi̯sp?, bʳoi̯spʳ, bʳoi̯st, bʳoi̯vb, bʳoi̯vd, bʳoi̯zb, bʳoi̯zd, bʳoi̯zvb, bʳoi̯zvbʳ, bʳoi̯zvd, bʳoi̯zvɡ, bʳoi̯zvɡʳ, bʳoi̯ɡ, bʳoi̯ɡʳ, bʳok, bʳokʳ, bʳop, bʳop?, bʳopʳ, bʳos, bʳosk, bʳoskʳ, bʳosp, bʳosp?, bʳospʳ, bʳost, bʳovb, bʳovd, bʳozb, bʳozd, bʳozvb, bʳozvbʳ, bʳozvd, bʳozvɡ, bʳozvɡʳ, bʳoɡ, bʳoɡʳ, bʳu, bʳub, bʳubʳ, bʳufk, bʳufkʳ, bʳufp, bʳufp?, bʳufpʳ, bʳuft, bʳui̯, bʳui̯b, bʳui̯bʳ, bʳui̯fk, bʳui̯fkʳ, bʳui̯fp, bʳui̯fp?, bʳui̯fpʳ, bʳui̯ft, bʳui̯k, bʳui̯kʳ, bʳui̯p, bʳui̯p?, bʳui̯pʳ, bʳui̯s, bʳui̯sk, bʳui̯skʳ, bʳui̯sp, bʳui̯sp?, bʳui̯spʳ, bʳui̯st, bʳui̯vb, bʳui̯vd, bʳui̯zb, bʳui̯zd, bʳui̯zvb, bʳui̯zvbʳ, bʳui̯zvd, bʳui̯zvɡ, bʳui̯zvɡʳ, bʳui̯ɡ, bʳui̯ɡʳ, bʳuk, bʳukʳ, bʳup, bʳup?, bʳupʳ, bʳus, bʳusk, bʳuskʳ, bʳusp, bʳusp?, bʳuspʳ, bʳust, bʳuvb, bʳuvd, bʳuzb, bʳuzd, bʳuzvb, bʳuzvbʳ, bʳuzvd, bʳuzvɡ, bʳuzvɡʳ, bʳuɡ, bʳuɡʳ, bʳæ, bʳæs, da, dai̯, dai̯s, das, di, dis, di̯a, di̯as, di̯o, di̯ob, di̯obʳ, di̯ofk, di̯ofkʳ, di̯ofp, di̯ofp?, di̯ofpʳ, di̯oft, di̯ok, di̯okʳ, di̯op, di̯op?, di̯opʳ, di̯os, di̯osk, di̯oskʳ, di̯osp, di̯osp?, di̯ospʳ, di̯ost, di̯ovb, di̯ovd, di̯ozb, di̯ozd, di̯ozvb, di̯ozvbʳ, di̯ozvd, di̯ozvɡ, di̯ozvɡʳ, di̯oɡ, di̯oɡʳ, di̯u, di̯ub, di̯ubʳ, di̯ufk, di̯ufkʳ, di̯ufp, di̯ufp?, di̯ufpʳ, di̯uft, di̯uk, di̯ukʳ, di̯up, di̯up?, di̯upʳ, di̯us, di̯usk, di̯uskʳ, di̯usp, di̯usp?, di̯uspʳ, di̯ust, di̯uvb, di̯uvd, di̯uzb, di̯uzd, di̯uzvb, di̯uzvbʳ, di̯uzvd, di̯uzvɡ, di̯uzvɡʳ, di̯uɡ, di̯uɡʳ, dla, dlai̯, dlai̯s, dlas, dli, dlis, dli̯a, dli̯as, dli̯o, dli̯ob, dli̯obʳ, dli̯ofk, dli̯ofkʳ, dli̯ofp, dli̯ofp?, dli̯ofpʳ, dli̯oft, dli̯ok, dli̯okʳ, dli̯op, dli̯op?, dli̯opʳ, dli̯os, dli̯osk, dli̯oskʳ, dli̯osp, dli̯osp?, dli̯ospʳ, dli̯ost, dli̯ovb, dli̯ovd, dli̯ozb, dli̯ozd, dli̯ozvb, dli̯ozvbʳ, dli̯ozvd, dli̯ozvɡ, dli̯ozvɡʳ, dli̯oɡ, dli̯oɡʳ, dli̯u, dli̯ub, dli̯ubʳ, dli̯ufk, dli̯ufkʳ, dli̯ufp, dli̯ufp?, dli̯ufpʳ, dli̯uft, dli̯uk, dli̯ukʳ, dli̯up, dli̯up?, dli̯upʳ, dli̯us, dli̯usk, dli̯uskʳ, dli̯usp, dli̯usp?, dli̯uspʳ, dli̯ust, dli̯uvb, dli̯uvd, dli̯uzb, dli̯uzd, dli̯uzvb, dli̯uzvbʳ, dli̯uzvd, dli̯uzvɡ, dli̯uzvɡʳ, dli̯uɡ, dli̯uɡʳ, dlo, dlob, dlobʳ, dlofk, dlofkʳ, dlofp, dlofp?, dlofpʳ, dloft, dloi̯, dloi̯b, dloi̯bʳ, dloi̯fk, dloi̯fkʳ, dloi̯fp, dloi̯fp?, dloi̯fpʳ, dloi̯ft, dloi̯k, dloi̯kʳ, dloi̯p, dloi̯p?, dloi̯pʳ, dloi̯s, dloi̯sk, dloi̯skʳ, dloi̯sp, dloi̯sp?, dloi̯spʳ, dloi̯st, dloi̯vb, dloi̯vd, dloi̯zb, dloi̯zd, dloi̯zvb, dloi̯zvbʳ, dloi̯zvd, dloi̯zvɡ, dloi̯zvɡʳ, dloi̯ɡ, dloi̯ɡʳ, dlok, dlokʳ, dlop, dlop?, dlopʳ, dlos, dlosk, dloskʳ, dlosp, dlosp?, dlospʳ, dlost, dlovb, dlovd, dlozb, dlozd, dlozvb, dlozvbʳ, dlozvd, dlozvɡ, dlozvɡʳ, dloɡ, dloɡʳ, dlu, dlub, dlubʳ, dlufk, dlufkʳ, dlufp, dlufp?, dlufpʳ, dluft, dlui̯, dlui̯b, dlui̯bʳ, dlui̯fk, dlui̯fkʳ, dlui̯fp, dlui̯fp?, dlui̯fpʳ, dlui̯ft, dlui̯k, dlui̯kʳ, dlui̯p, dlui̯p?, dlui̯pʳ, dlui̯s, dlui̯sk, dlui̯skʳ, dlui̯sp, dlui̯sp?, dlui̯spʳ, dlui̯st, dlui̯vb, dlui̯vd, dlui̯zb, dlui̯zd, dlui̯zvb, dlui̯zvbʳ, dlui̯zvd, dlui̯zvɡ, dlui̯zvɡʳ, dlui̯ɡ, dlui̯ɡʳ, dluk, dlukʳ, dlup, dlup?, dlupʳ, dlus, dlusk, dluskʳ, dlusp, dlusp?, dluspʳ, dlust, dluvb, dluvd, dluzb, dluzd, dluzvb, dluzvbʳ, dluzvd, dluzvɡ, dluzvɡʳ, dluɡ, dluɡʳ, dlæ, dlæs, do, dob, dobʳ, dofk, dofkʳ, dofp, dofp?, dofpʳ, doft, doi̯, doi̯b, doi̯bʳ, doi̯fk, doi̯fkʳ, doi̯fp, doi̯fp?, doi̯fpʳ, doi̯ft, doi̯k, doi̯kʳ, doi̯p, doi̯p?, doi̯pʳ, doi̯s, doi̯sk, doi̯skʳ, doi̯sp, doi̯sp?, doi̯spʳ, doi̯st, doi̯vb, doi̯vd, doi̯zb, doi̯zd, doi̯zvb, doi̯zvbʳ, doi̯zvd, doi̯zvɡ, doi̯zvɡʳ, doi̯ɡ, doi̯ɡʳ, dok, dokʳ, dop, dop?, dopʳ, dos, dosk, doskʳ, dosp, dosp?, dospʳ, dost, dovb, dovd, dozb, dozd, dozvb, dozvbʳ, dozvd, dozvɡ, dozvɡʳ, doɡ, doɡʳ, du, dub, dubʳ, dufk, dufkʳ, dufp, dufp?, dufpʳ, duft, dui̯, dui̯b, dui̯bʳ, dui̯fk, dui̯fkʳ, dui̯fp, dui̯fp?, dui̯fpʳ, dui̯ft, dui̯k, dui̯kʳ, dui̯p, dui̯p?, dui̯pʳ, dui̯s, dui̯sk, dui̯skʳ, dui̯sp, dui̯sp?, dui̯spʳ, dui̯st, dui̯vb, dui̯vd, dui̯zb, dui̯zd, dui̯zvb, dui̯zvbʳ, dui̯zvd, dui̯zvɡ, dui̯zvɡʳ, dui̯ɡ, dui̯ɡʳ, duk, dukʳ, dup, dup?, dupʳ, dus, dusk, duskʳ, dusp, dusp?, duspʳ, dust, duvb, duvd, duzb, duzd, duzvb, duzvbʳ, duzvd, duzvɡ, duzvɡʳ, duɡ, duɡʳ, dæ, dæs, fa, fai̯, fai̯s, fas, fi, fis, fi̯a, fi̯as, fi̯o, fi̯ob, fi̯obʳ, fi̯ofk, fi̯ofkʳ, fi̯ofp, fi̯ofp?, fi̯ofpʳ, fi̯oft, fi̯ok, fi̯okʳ, fi̯op, fi̯op?, fi̯opʳ, fi̯os, fi̯osk, fi̯oskʳ, fi̯osp, fi̯osp?, fi̯ospʳ, fi̯ost, fi̯ovb, fi̯ovd, fi̯ozb, fi̯ozd, fi̯ozvb, fi̯ozvbʳ, fi̯ozvd, fi̯ozvɡ, fi̯ozvɡʳ, fi̯oɡ, fi̯oɡʳ, fi̯u, fi̯ub, fi̯ubʳ, fi̯ufk, fi̯ufkʳ, fi̯ufp, fi̯ufp?, fi̯ufpʳ, fi̯uft, fi̯uk, fi̯ukʳ, fi̯up, fi̯up?, fi̯upʳ, fi̯us, fi̯usk, fi̯uskʳ, fi̯usp, fi̯usp?, fi̯uspʳ, fi̯ust, fi̯uvb, fi̯uvd, fi̯uzb, fi̯uzd, fi̯uzvb, fi̯uzvbʳ, fi̯uzvd, fi̯uzvɡ, fi̯uzvɡʳ, fi̯uɡ, fi̯uɡʳ, fmla, fmlai̯, fmlai̯s, fmlas, fmli, fmlis, fmli̯a, fmli̯as, fmli̯o, fmli̯ob, fmli̯obʳ, fmli̯ofk, fmli̯ofkʳ, fmli̯ofp, fmli̯ofp?, fmli̯ofpʳ, fmli̯oft, fmli̯ok, fmli̯okʳ, fmli̯op, fmli̯op?, fmli̯opʳ, fmli̯os, fmli̯osk, fmli̯oskʳ, fmli̯osp, fmli̯osp?, fmli̯ospʳ, fmli̯ost, fmli̯ovb, fmli̯ovd, fmli̯ozb, fmli̯ozd, fmli̯ozvb, fmli̯ozvbʳ, fmli̯ozvd, fmli̯ozvɡ, fmli̯ozvɡʳ, fmli̯oɡ, fmli̯oɡʳ, fmli̯u, fmli̯ub, fmli̯ubʳ, fmli̯ufk, fmli̯ufkʳ, fmli̯ufp, fmli̯ufp?, fmli̯ufpʳ, fmli̯uft, fmli̯uk, fmli̯ukʳ, fmli̯up, fmli̯up?, fmli̯upʳ, fmli̯us, fmli̯usk, fmli̯uskʳ, fmli̯usp, fmli̯usp?, fmli̯uspʳ, fmli̯ust, fmli̯uvb, fmli̯uvd, fmli̯uzb, fmli̯uzd, fmli̯uzvb, fmli̯uzvbʳ, fmli̯uzvd, fmli̯uzvɡ, fmli̯uzvɡʳ, fmli̯uɡ, fmli̯uɡʳ, fmlo, fmlob, fmlobʳ, fmlofk, fmlofkʳ, fmlofp, fmlofp?, fmlofpʳ, fmloft, fmloi̯, fmloi̯b, fmloi̯bʳ, fmloi̯fk, fmloi̯fkʳ, fmloi̯fp, fmloi̯fp?, fmloi̯fpʳ, fmloi̯ft, fmloi̯k, fmloi̯kʳ, fmloi̯p, fmloi̯p?, fmloi̯pʳ, fmloi̯s, fmloi̯sk, fmloi̯skʳ, fmloi̯sp, fmloi̯sp?, fmloi̯spʳ, fmloi̯st, fmloi̯vb, fmloi̯vd, fmloi̯zb, fmloi̯zd, fmloi̯zvb, fmloi̯zvbʳ, fmloi̯zvd, fmloi̯zvɡ, fmloi̯zvɡʳ, fmloi̯ɡ, fmloi̯ɡʳ, fmlok, fmlokʳ, fmlop, fmlop?, fmlopʳ, fmlos, fmlosk, fmloskʳ, fmlosp, fmlosp?, fmlospʳ, fmlost, fmlovb, fmlovd, fmlozb, fmlozd, fmlozvb, fmlozvbʳ, fmlozvd, fmlozvɡ, fmlozvɡʳ, fmloɡ, fmloɡʳ, fmlu, fmlub, fmlubʳ, fmlufk, fmlufkʳ, fmlufp, fmlufp?, fmlufpʳ, fmluft, fmlui̯, fmlui̯b, fmlui̯bʳ, fmlui̯fk, fmlui̯fkʳ, fmlui̯fp, fmlui̯fp?, fmlui̯fpʳ, fmlui̯ft, fmlui̯k, fmlui̯kʳ, fmlui̯p, fmlui̯p?, fmlui̯pʳ, fmlui̯s, fmlui̯sk, fmlui̯skʳ, fmlui̯sp, fmlui̯sp?, fmlui̯spʳ, fmlui̯st, fmlui̯vb, fmlui̯vd, fmlui̯zb, fmlui̯zd, fmlui̯zvb, fmlui̯zvbʳ, fmlui̯zvd, fmlui̯zvɡ, fmlui̯zvɡʳ, fmlui̯ɡ, fmlui̯ɡʳ, fmluk, fmlukʳ, fmlup, fmlup?, fmlupʳ, fmlus, fmlusk, fmluskʳ, fmlusp, fmlusp?, fmluspʳ, fmlust, fmluvb, fmluvd, fmluzb, fmluzd, fmluzvb, fmluzvbʳ, fmluzvd, fmluzvɡ, fmluzvɡʳ, fmluɡ, fmluɡʳ, fmlæ, fmlæs, fo, fob, fobʳ, fofk, fofkʳ, fofp, fofp?, fofpʳ, foft, foi̯, foi̯b, foi̯bʳ, foi̯fk, foi̯fkʳ, foi̯fp, foi̯fp?, foi̯fpʳ, foi̯ft, foi̯k, foi̯kʳ, foi̯p, foi̯p?, foi̯pʳ, foi̯s, foi̯sk, foi̯skʳ, foi̯sp, foi̯sp?, foi̯spʳ, foi̯st, foi̯vb, foi̯vd, foi̯zb, foi̯zd, foi̯zvb, foi̯zvbʳ, foi̯zvd, foi̯zvɡ, foi̯zvɡʳ, foi̯ɡ, foi̯ɡʳ, fok, fokʳ, fop, fop?, fopʳ, fos, fosk, foskʳ, fosp, fosp?, fospʳ, fost, fovb, fovd, fozb, fozd, fozvb, fozvbʳ, fozvd, fozvɡ, fozvɡʳ, foɡ, foɡʳ, fu, fub, fubʳ, fufk, fufkʳ, fufp, fufp?, fufpʳ, fuft, fui̯, fui̯b, fui̯bʳ, fui̯fk, fui̯fkʳ, fui̯fp, fui̯fp?, fui̯fpʳ, fui̯ft, fui̯k, fui̯kʳ, fui̯p, fui̯p?, fui̯pʳ, fui̯s, fui̯sk, fui̯skʳ, fui̯sp, fui̯sp?, fui̯spʳ, fui̯st, fui̯vb, fui̯vd, fui̯zb, fui̯zd, fui̯zvb, fui̯zvbʳ, fui̯zvd, fui̯zvɡ, fui̯zvɡʳ, fui̯ɡ, fui̯ɡʳ, fuk, fukʳ, fup, fup?, fupʳ, fus, fusk, fuskʳ, fusp, fusp?, fuspʳ, fust, fuvb, fuvd, fuzb, fuzd, fuzvb, fuzvbʳ, fuzvd, fuzvɡ, fuzvɡʳ, fuɡ, fuɡʳ, fæ, fæs, i, is, i̯a, i̯as, i̯o, i̯ob, i̯obʳ, i̯ofk, i̯ofkʳ, i̯ofp, i̯ofp?, i̯ofpʳ, i̯oft, i̯ok, i̯okʳ, i̯op, i̯op?, i̯opʳ, i̯os, i̯osk, i̯oskʳ, i̯osp, i̯osp?, i̯ospʳ, i̯ost, i̯ovb, i̯ovd, i̯ozb, i̯ozd, i̯ozvb, i̯ozvbʳ, i̯ozvd, i̯ozvɡ, i̯ozvɡʳ, i̯oɡ, i̯oɡʳ, i̯u, i̯ub, i̯ubʳ, i̯ufk, i̯ufkʳ, i̯ufp, i̯ufp?, i̯ufpʳ, i̯uft, i̯uk, i̯ukʳ, i̯up, i̯up?, i̯upʳ, i̯us, i̯usk, i̯uskʳ, i̯usp, i̯usp?, i̯uspʳ, i̯ust, i̯uvb, i̯uvd, i̯uzb, i̯uzd, i̯uzvb, i̯uzvbʳ, i̯uzvd, i̯uzvɡ, i̯uzvɡʳ, i̯uɡ, i̯uɡʳ, ja, jai̯, jai̯s, jas, ji̯a, ji̯as, ji̯o, ji̯ob, ji̯obʳ, ji̯ofk, ji̯ofkʳ, ji̯ofp, ji̯ofp?, ji̯ofpʳ, ji̯oft, ji̯ok, ji̯okʳ, ji̯op, ji̯op?, ji̯opʳ, ji̯os, ji̯osk, ji̯oskʳ, ji̯osp, ji̯osp?, ji̯ospʳ, ji̯ost, ji̯ovb, ji̯ovd, ji̯ozb, ji̯ozd, ji̯ozvb, ji̯ozvbʳ, ji̯ozvd, ji̯ozvɡ, ji̯ozvɡʳ, ji̯oɡ, ji̯oɡʳ, ji̯u, ji̯ub, ji̯ubʳ, ji̯ufk, ji̯ufkʳ, ji̯ufp, ji̯ufp?, ji̯ufpʳ, ji̯uft, ji̯uk, ji̯ukʳ, ji̯up, ji̯up?, ji̯upʳ, ji̯us, ji̯usk, ji̯uskʳ, ji̯usp, ji̯usp?, ji̯uspʳ, ji̯ust, ji̯uvb, ji̯uvd, ji̯uzb, ji̯uzd, ji̯uzvb, ji̯uzvbʳ, ji̯uzvd, ji̯uzvɡ, ji̯uzvɡʳ, ji̯uɡ, ji̯uɡʳ, jo, job, jobʳ, jofk, jofkʳ, jofp, jofp?, jofpʳ, joft, joi̯, joi̯b, joi̯bʳ, joi̯fk, joi̯fkʳ, joi̯fp, joi̯fp?, joi̯fpʳ, joi̯ft, joi̯k, joi̯kʳ, joi̯p, joi̯p?, joi̯pʳ, joi̯s, joi̯sk, joi̯skʳ, joi̯sp, joi̯sp?, joi̯spʳ, joi̯st, joi̯vb, joi̯vd, joi̯zb, joi̯zd, joi̯zvb, joi̯zvbʳ, joi̯zvd, joi̯zvɡ, joi̯zvɡʳ, joi̯ɡ, joi̯ɡʳ, jok, jokʳ, jop, jop?, jopʳ, jos, josk, joskʳ, josp, josp?, jospʳ, jost, jovb, jovd, jozb, jozd, jozvb, jozvbʳ, jozvd, jozvɡ, jozvɡʳ, joɡ, joɡʳ, ju, jub, jubʳ, jufk, jufkʳ, jufp, jufp?, jufpʳ, juft, jui̯, jui̯b, jui̯bʳ, jui̯fk, jui̯fkʳ, jui̯fp, jui̯fp?, jui̯fpʳ, jui̯ft, jui̯k, jui̯kʳ, jui̯p, jui̯p?, jui̯pʳ, jui̯s, jui̯sk, jui̯skʳ, jui̯sp, jui̯sp?, jui̯spʳ, jui̯st, jui̯vb, jui̯vd, jui̯zb, jui̯zd, jui̯zvb, jui̯zvbʳ, jui̯zvd, jui̯zvɡ, jui̯zvɡʳ, jui̯ɡ, jui̯ɡʳ, juk, jukʳ, jup, jup?, jupʳ, jus, jusk, juskʳ, jusp, jusp?, juspʳ, just, juvb, juvd, juzb, juzd, juzvb, juzvbʳ, juzvd, juzvɡ, juzvɡʳ, juɡ, juɡʳ, jæ, jæs, ka, kai̯, kai̯s, kas, ki, kis, ki̯a, ki̯as, ki̯o, ki̯ob, ki̯obʳ, ki̯ofk, ki̯ofkʳ, ki̯ofp, ki̯ofp?, ki̯ofpʳ, ki̯oft, ki̯ok, ki̯okʳ, ki̯op, ki̯op?, ki̯opʳ, ki̯os, ki̯osk, ki̯oskʳ, ki̯osp, ki̯osp?, ki̯ospʳ, ki̯ost, ki̯ovb, ki̯ovd, ki̯ozb, ki̯ozd, ki̯ozvb, ki̯ozvbʳ, ki̯ozvd, ki̯ozvɡ, ki̯ozvɡʳ, ki̯oɡ, ki̯oɡʳ, ki̯u, ki̯ub, ki̯ubʳ, ki̯ufk, ki̯ufkʳ, ki̯ufp, ki̯ufp?, ki̯ufpʳ, ki̯uft, ki̯uk, ki̯ukʳ, ki̯up, ki̯up?, ki̯upʳ, ki̯us, ki̯usk, ki̯uskʳ, ki̯usp, ki̯usp?, ki̯uspʳ, ki̯ust, ki̯uvb, ki̯uvd, ki̯uzb, ki̯uzd, ki̯uzvb, ki̯uzvbʳ, ki̯uzvd, ki̯uzvɡ, ki̯uzvɡʳ, ki̯uɡ, ki̯uɡʳ, ko, kob, kobʳ, kofk, kofkʳ, kofp, kofp?, kofpʳ, koft, koi̯, koi̯b, koi̯bʳ, koi̯fk, koi̯fkʳ, koi̯fp, koi̯fp?, koi̯fpʳ, koi̯ft, koi̯k, koi̯kʳ, koi̯p, koi̯p?, koi̯pʳ, koi̯s, koi̯sk, koi̯skʳ, koi̯sp, koi̯sp?, koi̯spʳ, koi̯st, koi̯vb, koi̯vd, koi̯zb, koi̯zd, koi̯zvb, koi̯zvbʳ, koi̯zvd, koi̯zvɡ, koi̯zvɡʳ, koi̯ɡ, koi̯ɡʳ, kok, kokʳ, kop, kop?, kopʳ, kos, kosk, koskʳ, kosp, kosp?, kospʳ, kost, kovb, kovd, kozb, kozd, kozvb, kozvbʳ, kozvd, kozvɡ, kozvɡʳ, koɡ, koɡʳ, ku, kub, kubʳ, kufk, kufkʳ, kufp, kufp?, kufpʳ, kuft, kui̯, kui̯b, kui̯bʳ, kui̯fk, kui̯fkʳ, kui̯fp, kui̯fp?, kui̯fpʳ, kui̯ft, kui̯k, kui̯kʳ, kui̯p, kui̯p?, kui̯pʳ, kui̯s, kui̯sk, kui̯skʳ, kui̯sp, kui̯sp?, kui̯spʳ, kui̯st, kui̯vb, kui̯vd, kui̯zb, kui̯zd, kui̯zvb, kui̯zvbʳ, kui̯zvd, kui̯zvɡ, kui̯zvɡʳ, kui̯ɡ, kui̯ɡʳ, kuk, kukʳ, kup, kup?, kupʳ, kus, kusk, kuskʳ, kusp, kusp?, kuspʳ, kust, kuvb, kuvd, kuzb, kuzd, kuzvb, kuzvbʳ, kuzvd, kuzvɡ, kuzvɡʳ, kuɡ, kuɡʳ, kæ, kæs, kʳa, kʳai̯, kʳai̯s, kʳas, kʳi, kʳis, kʳi̯a, kʳi̯as, kʳi̯o, kʳi̯ob, kʳi̯obʳ, kʳi̯ofk, kʳi̯ofkʳ, kʳi̯ofp, kʳi̯ofp?, kʳi̯ofpʳ, kʳi̯oft, kʳi̯ok, kʳi̯okʳ, kʳi̯op, kʳi̯op?, kʳi̯opʳ, kʳi̯os, kʳi̯osk, kʳi̯oskʳ, kʳi̯osp, kʳi̯osp?, kʳi̯ospʳ, kʳi̯ost, kʳi̯ovb, kʳi̯ovd, kʳi̯ozb, kʳi̯ozd, kʳi̯ozvb, kʳi̯ozvbʳ, kʳi̯ozvd, kʳi̯ozvɡ, kʳi̯ozvɡʳ, kʳi̯oɡ, kʳi̯oɡʳ, kʳi̯u, kʳi̯ub, kʳi̯ubʳ, kʳi̯ufk, kʳi̯ufkʳ, kʳi̯ufp, kʳi̯ufp?, kʳi̯ufpʳ, kʳi̯uft, kʳi̯uk, kʳi̯ukʳ, kʳi̯up, kʳi̯up?, kʳi̯upʳ, kʳi̯us, kʳi̯usk, kʳi̯uskʳ, kʳi̯usp, kʳi̯usp?, kʳi̯uspʳ, kʳi̯ust, kʳi̯uvb, kʳi̯uvd, kʳi̯uzb, kʳi̯uzd, kʳi̯uzvb, kʳi̯uzvbʳ, kʳi̯uzvd, kʳi̯uzvɡ, kʳi̯uzvɡʳ, kʳi̯uɡ, kʳi̯uɡʳ, kʳo, kʳob, kʳobʳ, kʳofk, kʳofkʳ, kʳofp, kʳofp?, kʳofpʳ, kʳoft, kʳoi̯, kʳoi̯b, kʳoi̯bʳ, kʳoi̯fk, kʳoi̯fkʳ, kʳoi̯fp, kʳoi̯fp?, kʳoi̯fpʳ, kʳoi̯ft, kʳoi̯k, kʳoi̯kʳ, kʳoi̯p, kʳoi̯p?, kʳoi̯pʳ, kʳoi̯s, kʳoi̯sk, kʳoi̯skʳ, kʳoi̯sp, kʳoi̯sp?, kʳoi̯spʳ, kʳoi̯st, kʳoi̯vb, kʳoi̯vd, kʳoi̯zb, kʳoi̯zd, kʳoi̯zvb, kʳoi̯zvbʳ, kʳoi̯zvd, kʳoi̯zvɡ, kʳoi̯zvɡʳ, kʳoi̯ɡ, kʳoi̯ɡʳ, kʳok, kʳokʳ, kʳop, kʳop?, kʳopʳ, kʳos, kʳosk, kʳoskʳ, kʳosp, kʳosp?, kʳospʳ, kʳost, kʳovb, kʳovd, kʳozb, kʳozd, kʳozvb, kʳozvbʳ, kʳozvd, kʳozvɡ, kʳozvɡʳ, kʳoɡ, kʳoɡʳ, kʳu, kʳub, kʳubʳ, kʳufk, kʳufkʳ, kʳufp, kʳufp?, kʳufpʳ, kʳuft, kʳui̯, kʳui̯b, kʳui̯bʳ, kʳui̯fk, kʳui̯fkʳ, kʳui̯fp, kʳui̯fp?, kʳui̯fpʳ, kʳui̯ft, kʳui̯k, kʳui̯kʳ, kʳui̯p, kʳui̯p?, kʳui̯pʳ, kʳui̯s, kʳui̯sk, kʳui̯skʳ, kʳui̯sp, kʳui̯sp?, kʳui̯spʳ, kʳui̯st, kʳui̯vb, kʳui̯vd, kʳui̯zb, kʳui̯zd, kʳui̯zvb, kʳui̯zvbʳ, kʳui̯zvd, kʳui̯zvɡ, kʳui̯zvɡʳ, kʳui̯ɡ, kʳui̯ɡʳ, kʳuk, kʳukʳ, kʳup, kʳup?, kʳupʳ, kʳus, kʳusk, kʳuskʳ, kʳusp, kʳusp?, kʳuspʳ, kʳust, kʳuvb, kʳuvd, kʳuzb, kʳuzd, kʳuzvb, kʳuzvbʳ, kʳuzvd, kʳuzvɡ, kʳuzvɡʳ, kʳuɡ, kʳuɡʳ, kʳæ, kʳæs, la, lai̯, lai̯s, las, li, lis, li̯a, li̯as, li̯o, li̯ob, li̯obʳ, li̯ofk, li̯ofkʳ, li̯ofp, li̯ofp?, li̯ofpʳ, li̯oft, li̯ok, li̯okʳ, li̯op, li̯op?, li̯opʳ, li̯os, li̯osk, li̯oskʳ, li̯osp, li̯osp?, li̯ospʳ, li̯ost, li̯ovb, li̯ovd, li̯ozb, li̯ozd, li̯ozvb, li̯ozvbʳ, li̯ozvd, li̯ozvɡ, li̯ozvɡʳ, li̯oɡ, li̯oɡʳ, li̯u, li̯ub, li̯ubʳ, li̯ufk, li̯ufkʳ, li̯ufp, li̯ufp?, li̯ufpʳ, li̯uft, li̯uk, li̯ukʳ, li̯up, li̯up?, li̯upʳ, li̯us, li̯usk, li̯uskʳ, li̯usp, li̯usp?, li��uspʳ, li̯ust, li̯uvb, li̯uvd, li̯uzb, li̯uzd, li̯uzvb, li̯uzvbʳ, li̯uzvd, li̯uzvɡ, li̯uzvɡʳ, li̯uɡ, li̯uɡʳ, lo, lob, lobʳ, lofk, lofkʳ, lofp, lofp?, lofpʳ, loft, loi̯, loi̯b, loi̯bʳ, loi̯fk, loi̯fkʳ, loi̯fp, loi̯fp?, loi̯fpʳ, loi̯ft, loi̯k, loi̯kʳ, loi̯p, loi̯p?, loi̯pʳ, loi̯s, loi̯sk, loi̯skʳ, loi̯sp, loi̯sp?, loi̯spʳ, loi̯st, loi̯vb, loi̯vd, loi̯zb, loi̯zd, loi̯zvb, loi̯zvbʳ, loi̯zvd, loi̯zvɡ, loi̯zvɡʳ, loi̯ɡ, loi̯ɡʳ, lok, lokʳ, lop, lop?, lopʳ, los, losk, loskʳ, losp, losp?, lospʳ, lost, lovb, lovd, lozb, lozd, lozvb, lozvbʳ, lozvd, lozvɡ, lozvɡʳ, loɡ, loɡʳ, lu, lub, lubʳ, lufk, lufkʳ, lufp, lufp?, lufpʳ, luft, lui̯, lui̯b, lui̯bʳ, lui̯fk, lui̯fkʳ, lui̯fp, lui̯fp?, lui̯fpʳ, lui̯ft, lui̯k, lui̯kʳ, lui̯p, lui̯p?, lui̯pʳ, lui̯s, lui̯sk, lui̯skʳ, lui̯sp, lui̯sp?, lui̯spʳ, lui̯st, lui̯vb, lui̯vd, lui̯zb, lui̯zd, lui̯zvb, lui̯zvbʳ, lui̯zvd, lui̯zvɡ, lui̯zvɡʳ, lui̯��, lui̯ɡʳ, luk, lukʳ, lup, lup?, lupʳ, lus, lusk, luskʳ, lusp, lusp?, luspʳ, lust, luvb, luvd, luzb, luzd, luzvb, luzvbʳ, luzvd, luzvɡ, luzvɡʳ, luɡ, luɡʳ, læ, læs, ma, mai̯, mai̯s, mas, mi, mis, mi̯a, mi̯as, mi̯o, mi̯ob, mi̯obʳ, mi̯ofk, mi̯ofkʳ, mi̯ofp, mi̯ofp?, mi̯ofpʳ, mi̯oft, mi̯ok, mi̯okʳ, mi̯op, mi̯op?, mi̯opʳ, mi̯os, mi̯osk, mi̯oskʳ, mi̯osp, mi̯osp?, mi̯ospʳ, mi̯ost, mi̯ovb, mi̯ovd, mi̯ozb, mi̯ozd, mi̯ozvb, mi̯ozvbʳ, mi̯ozvd, mi̯ozvɡ, mi̯ozvɡʳ, mi̯oɡ, mi̯oɡʳ, mi̯u, mi̯ub, mi̯ubʳ, mi̯ufk, mi̯ufkʳ, mi̯ufp, mi̯ufp?, mi̯ufpʳ, mi̯uft, mi̯uk, mi̯ukʳ, mi̯up, mi̯up?, mi̯upʳ, mi̯us, mi̯usk, mi̯uskʳ, mi̯usp, mi̯usp?, mi̯uspʳ, mi̯ust, mi̯uvb, mi̯uvd, mi̯uzb, mi̯uzd, mi̯uzvb, mi̯uzvbʳ, mi̯uzvd, mi̯uzvɡ, mi̯uzvɡʳ, mi̯uɡ, mi̯uɡʳ, mo, mob, mobʳ, mofk, mofkʳ, mofp, mofp?, mofpʳ, moft, moi̯, moi̯b, moi̯bʳ, moi̯fk, moi̯fkʳ, moi̯fp, moi̯fp?, moi̯fpʳ, moi̯ft, moi̯k, moi̯k��, moi̯p, moi̯p?, moi̯pʳ, moi̯s, moi̯sk, moi̯skʳ, moi̯sp, moi̯sp?, moi̯spʳ, moi̯st, moi̯vb, moi̯vd, moi̯zb, moi̯zd, moi̯zvb, moi̯zvbʳ, moi̯zvd, moi̯zvɡ, moi̯zvɡʳ, moi̯ɡ, moi̯ɡʳ, mok, mokʳ, mop, mop?, mopʳ, mos, mosk, moskʳ, mosp, mosp?, mospʳ, most, movb, movd, mozb, mozd, mozvb, mozvbʳ, mozvd, mozvɡ, mozvɡʳ, moɡ, moɡʳ, mu, mub, mubʳ, mufk, mufkʳ, mufp, mufp?, mufpʳ, muft, mui̯, mui̯b, mui̯bʳ, mui̯fk, mui̯fkʳ, mui̯fp, mui̯fp?, mui̯fpʳ, mui̯ft, mui̯k, mui̯kʳ, mui̯p, mui̯p?, mui̯pʳ, mui̯s, mui̯sk, mui̯skʳ, mui̯sp, mui̯sp?, mui̯spʳ, mui̯st, mui̯vb, mui̯vd, mui̯zb, mui̯zd, mui̯zvb, mui̯zvbʳ, mui̯zvd, mui̯zvɡ, mui̯zvɡʳ, mui̯ɡ, mui̯ɡʳ, muk, mukʳ, mup, mup?, mupʳ, mus, musk, muskʳ, musp, musp?, muspʳ, must, muvb, muvd, muzb, muzd, muzvb, muzvbʳ, muzvd, muzvɡ, muzvɡʳ, muɡ, muɡʳ, mæ, mæs, o, ob, obʳ, ofk, ofkʳ, ofp, ofp?, ofpʳ, oft, oi̯, oi̯b, oi̯bʳ, oi̯fk, oi̯fkʳ, oi̯fp, oi̯fp?, oi̯fpʳ, oi̯ft, oi̯k, oi̯kʳ, oi̯p, oi̯p?, oi̯pʳ, oi̯s, oi̯sk, oi̯skʳ, oi̯sp, oi̯sp?, oi̯spʳ, oi̯st, oi̯vb, oi̯vd, oi̯zb, oi̯zd, oi̯zvb, oi̯zvbʳ, oi̯zvd, oi̯zvɡ, oi̯zvɡʳ, oi̯ɡ, oi̯ɡʳ, ok, okʳ, op, op?, opʳ, os, osk, oskʳ, osp, osp?, ospʳ, ost, ovb, ovd, ozb, ozd, ozvb, ozvbʳ, ozvd, ozvɡ, ozvɡʳ, oɡ, oɡʳ, p?a, p?ai̯, p?ai̯s, p?as, p?i, p?is, p?i̯a, p?i̯as, p?i̯o, p?i̯ob, p?i̯obʳ, p?i̯ofk, p?i̯ofkʳ, p?i̯ofp, p?i̯ofp?, p?i̯ofpʳ, p?i̯oft, p?i̯ok, p?i̯okʳ, p?i̯op, p?i̯op?, p?i̯opʳ, p?i̯os, p?i̯osk, p?i̯oskʳ, p?i̯osp, p?i̯osp?, p?i̯ospʳ, p?i̯ost, p?i̯ovb, p?i̯ovd, p?i̯ozb, p?i̯ozd, p?i̯ozvb, p?i̯ozvbʳ, p?i̯ozvd, p?i̯ozvɡ, p?i̯ozvɡʳ, p?i̯oɡ, p?i̯oɡʳ, p?i̯u, p?i̯ub, p?i̯ubʳ, p?i̯ufk, p?i̯ufkʳ, p?i̯ufp, p?i̯ufp?, p?i̯ufpʳ, p?i̯uft, p?i̯uk, p?i̯ukʳ, p?i̯up, p?i̯up?, p?i̯upʳ, p?i̯us, p?i̯usk, p?i̯uskʳ, p?i̯usp, p?i̯usp?, p?i̯uspʳ, p?i̯ust, p?i̯uvb, p?i̯uvd, p?i̯uzb, p?i̯uzd, p?i̯uzvb, p?i̯uzvbʳ, p?i̯uzvd, p?i̯uzvɡ, p?i̯uzvɡʳ, p?i̯uɡ, p?i̯uɡʳ, p?o, p?ob, p?obʳ, p?ofk, p?ofkʳ, p?ofp, p?ofp?, p?ofpʳ, p?oft, p?oi̯, p?oi̯b, p?oi̯bʳ, p?oi̯fk, p?oi̯fkʳ, p?oi̯fp, p?oi̯fp?, p?oi̯fpʳ, p?oi̯ft, p?oi̯k, p?oi̯kʳ, p?oi̯p, p?oi̯p?, p?oi̯pʳ, p?oi̯s, p?oi̯sk, p?oi̯skʳ, p?oi̯sp, p?oi̯sp?, p?oi̯spʳ, p?oi̯st, p?oi̯vb, p?oi̯vd, p?oi̯zb, p?oi̯zd, p?oi̯zvb, p?oi̯zvbʳ, p?oi̯zvd, p?oi̯zvɡ, p?oi̯zvɡʳ, p?oi̯ɡ, p?oi̯ɡʳ, p?ok, p?okʳ, p?op, p?op?, p?opʳ, p?os, p?osk, p?oskʳ, p?osp, p?osp?, p?ospʳ, p?ost, p?ovb, p?ovd, p?ozb, p?ozd, p?ozvb, p?ozvbʳ, p?ozvd, p?ozvɡ, p?ozvɡʳ, p?oɡ, p?oɡʳ, p?u, p?ub, p?ubʳ, p?ufk, p?ufkʳ, p?ufp, p?ufp?, p?ufpʳ, p?uft, p?ui̯, p?ui̯b, p?ui̯bʳ, p?ui̯fk, p?ui̯fkʳ, p?ui̯fp, p?ui̯fp?, p?ui̯fpʳ, p?ui̯ft, p?ui̯k, p?ui̯kʳ, p?ui̯p, p?ui̯p?, p?ui̯pʳ, p?ui̯s, p?ui̯sk, p?ui̯skʳ, p?ui̯sp, p?ui̯sp?, p?ui̯spʳ, p?ui̯st, p?ui̯vb, p?ui̯vd, p?ui̯zb, p?ui̯zd, p?ui̯zvb, p?ui̯zvbʳ, p?ui̯zvd, p?ui̯zvɡ, p?ui̯zvɡʳ, p?ui̯ɡ, p?ui̯ɡʳ, p?uk, p?ukʳ, p?up, p?up?, p?upʳ, p?us, p?usk, p?uskʳ, p?usp, p?usp?, p?uspʳ, p?ust, p?uvb, p?uvd, p?uzb, p?uzd, p?uzvb, p?uzvbʳ, p?uzvd, p?uzvɡ, p?uzvɡʳ, p?uɡ, p?uɡʳ, p?æ, p?æs, pa, pai̯, pai̯s, pas, pfla, pflai̯, pflai̯s, pflas, pfli, pflis, pfli̯a, pfli̯as, pfli̯o, pfli̯ob, pfli̯obʳ, pfli̯ofk, pfli̯ofkʳ, pfli̯ofp, pfli̯ofp?, pfli̯ofpʳ, pfli̯oft, pfli̯ok, pfli̯okʳ, pfli̯op, pfli̯op?, pfli̯opʳ, pfli̯os, pfli̯osk, pfli̯oskʳ, pfli̯osp, pfli̯osp?, pfli̯ospʳ, pfli̯ost, pfli̯ovb, pfli̯ovd, pfli̯ozb, pfli̯ozd, pfli̯ozvb, pfli̯ozvbʳ, pfli̯ozvd, pfli̯ozvɡ, pfli̯ozvɡʳ, pfli̯oɡ, pfli̯oɡʳ, pfli̯u, pfli̯ub, pfli̯ubʳ, pfli̯ufk, pfli̯ufkʳ, pfli̯ufp, pfli̯ufp?, pfli̯ufpʳ, pfli̯uft, pfli̯uk, pfli̯ukʳ, pfli̯up, pfli̯up?, pfli̯upʳ, pfli̯us, pfli̯usk, pfli̯uskʳ, pfli̯usp, pfli̯usp?, pfli̯uspʳ, pfli̯ust, pfli̯uvb, pfli̯uvd, pfli̯uzb, pfli̯uzd, pfli̯uzvb, pfli̯uzvbʳ, pfli̯uzvd, pfli̯uzvɡ, pfli̯uzvɡʳ, pfli̯uɡ, pfli̯uɡʳ, pflo, pflob, pflobʳ, pflofk, pflofkʳ, pflofp, pflofp?, pflofpʳ, pfloft, pfloi̯, pfloi̯b, pfloi̯bʳ, pfloi̯fk, pfloi̯fkʳ, pfloi̯fp, pfloi̯fp?, pfloi̯fpʳ, pfloi̯ft, pfloi̯k, pfloi̯kʳ, pfloi̯p, pfloi̯p?, pfloi̯pʳ, pfloi̯s, pfloi̯sk, pfloi̯skʳ, pfloi̯sp, pfloi̯sp?, pfloi̯spʳ, pfloi̯st, pfloi̯vb, pfloi̯vd, pfloi̯zb, pfloi̯zd, pfloi̯zvb, pfloi̯zvbʳ, pfloi̯zvd, pfloi̯zvɡ, pfloi̯zvɡʳ, pfloi̯ɡ, pfloi̯ɡʳ, pflok, pflokʳ, pflop, pflop?, pflopʳ, pflos, pflosk, pfloskʳ, pflosp, pflosp?, pflospʳ, pflost, pflovb, pflovd, pflozb, pflozd, pflozvb, pflozvbʳ, pflozvd, pflozvɡ, pflozvɡʳ, pfloɡ, pfloɡʳ, pflu, pflub, pflubʳ, pflufk, pflufkʳ, pflufp, pflufp?, pflufpʳ, pfluft, pflui̯, pflui̯b, pflui̯bʳ, pflui̯fk, pflui̯fkʳ, pflui̯fp, pflui̯fp?, pflui̯fpʳ, pflui̯ft, pflui̯k, pflui̯kʳ, pflui̯p, pflui̯p?, pflui̯pʳ, pflui̯s, pflui̯sk, pflui̯skʳ, pflui̯sp, pflui̯sp?, pflui̯spʳ, pflui̯st, pflui̯vb, pflui̯vd, pflui̯zb, pflui̯zd, pflui̯zvb, pflui̯zvbʳ, pflui̯zvd, pflui̯zvɡ, pflui̯zvɡʳ, pflui̯ɡ, pflui̯ɡʳ, pfluk, pflukʳ, pflup, pflup?, pflupʳ, pflus, pflusk, pfluskʳ, pflusp, pflusp?, pfluspʳ, pflust, pfluvb, pfluvd, pfluzb, pfluzd, pfluzvb, pfluzvbʳ, pfluzvd, pfluzvɡ, pfluzvɡʳ, pfluɡ, pfluɡʳ, pflæ, pflæs, pfma, pfmai̯, pfmai̯s, pfmas, pfmi, pfmis, pfmi̯a, pfmi̯as, pfmi̯o, pfmi̯ob, pfmi̯obʳ, pfmi̯ofk, pfmi̯ofkʳ, pfmi̯ofp, pfmi̯ofp?, pfmi̯ofpʳ, pfmi̯oft, pfmi̯ok, pfmi̯okʳ, pfmi̯op, pfmi̯op?, pfmi̯opʳ, pfmi̯os, pfmi̯osk, pfmi̯oskʳ, pfmi̯osp, pfmi̯osp?, pfmi̯ospʳ, pfmi̯ost, pfmi̯ovb, pfmi̯ovd, pfmi̯ozb, pfmi̯ozd, pfmi̯ozvb, pfmi̯ozvbʳ, pfmi̯ozvd, pfmi̯ozvɡ, pfmi̯ozvɡʳ, pfmi̯oɡ, pfmi̯oɡʳ, pfmi̯u, pfmi̯ub, pfmi̯ubʳ, pfmi̯ufk, pfmi̯ufkʳ, pfmi̯ufp, pfmi̯ufp?, pfmi̯ufpʳ, pfmi̯uft, pfmi̯uk, pfmi̯ukʳ, pfmi̯up, pfmi̯up?, pfmi̯upʳ, pfmi̯us, pfmi̯usk, pfmi̯uskʳ, pfmi̯usp, pfmi̯usp?, pfmi̯uspʳ, pfmi̯ust, pfmi̯uvb, pfmi̯uvd, pfmi̯uzb, pfmi̯uzd, pfmi̯uzvb, pfmi̯uzvbʳ, pfmi̯uzvd, pfmi̯uzvɡ, pfmi̯uzvɡʳ, pfmi̯uɡ, pfmi̯uɡʳ, pfmo, pfmob, pfmobʳ, pfmofk, pfmofkʳ, pfmofp, pfmofp?, pfmofpʳ, pfmoft, pfmoi̯, pfmoi̯b, pfmoi̯bʳ, pfmoi̯fk, pfmoi̯fkʳ, pfmoi̯fp, pfmoi̯fp?, pfmoi̯fpʳ, pfmoi̯ft, pfmoi̯k, pfmoi̯kʳ, pfmoi̯p, pfmoi̯p?, pfmoi̯pʳ, pfmoi̯s, pfmoi̯sk, pfmoi̯skʳ, pfmoi̯sp, pfmoi̯sp?, pfmoi̯spʳ, pfmoi̯st, pfmoi̯vb, pfmoi̯vd, pfmoi̯zb, pfmoi̯zd, pfmoi̯zvb, pfmoi̯zvbʳ, pfmoi̯zvd, pfmoi̯zvɡ, pfmoi̯zvɡʳ, pfmoi̯ɡ, pfmoi̯ɡʳ, pfmok, pfmokʳ, pfmop, pfmop?, pfmopʳ, pfmos, pfmosk, pfmoskʳ, pfmosp, pfmosp?, pfmospʳ, pfmost, pfmovb, pfmovd, pfmozb, pfmozd, pfmozvb, pfmozvbʳ, pfmozvd, pfmozvɡ, pfmozvɡʳ, pfmoɡ, pfmoɡʳ, pfmu, pfmub, pfmubʳ, pfmufk, pfmufkʳ, pfmufp, pfmufp?, pfmufpʳ, pfmuft, pfmui̯, pfmui̯b, pfmui̯bʳ, pfmui̯fk, pfmui̯fkʳ, pfmui̯fp, pfmui̯fp?, pfmui̯fpʳ, pfmui̯ft, pfmui̯k, pfmui̯kʳ, pfmui̯p, pfmui̯p?, pfmui̯pʳ, pfmui̯s, pfmui̯sk, pfmui̯skʳ, pfmui̯sp, pfmui̯sp?, pfmui̯spʳ, pfmui̯st, pfmui̯vb, pfmui̯vd, pfmui̯zb, pfmui̯zd, pfmui̯zvb, pfmui̯zvbʳ, pfmui̯zvd, pfmui̯zvɡ, pfmui̯zvɡʳ, pfmui̯ɡ, pfmui̯ɡʳ, pfmuk, pfmukʳ, pfmup, pfmup?, pfmupʳ, pfmus, pfmusk, pfmuskʳ, pfmusp, pfmusp?, pfmuspʳ, pfmust, pfmuvb, pfmuvd, pfmuzb, pfmuzd, pfmuzvb, pfmuzvbʳ, pfmuzvd, pfmuzvɡ, pfmuzvɡʳ, pfmuɡ, pfmuɡʳ, pfmæ, pfmæs, pi, pis, pi̯a, pi̯as, pi̯o, pi̯ob, pi̯obʳ, pi̯ofk, pi̯ofkʳ, pi̯ofp, pi̯ofp?, pi̯ofpʳ, pi̯oft, pi̯ok, pi̯okʳ, pi̯op, pi̯op?, pi̯opʳ, pi̯os, pi̯osk, pi̯oskʳ, pi̯osp, pi̯osp?, pi̯ospʳ, pi̯ost, pi̯ovb, pi̯ovd, pi̯ozb, pi̯ozd, pi̯ozvb, pi̯ozvbʳ, pi̯ozvd, pi̯ozvɡ, pi̯ozvɡʳ, pi̯oɡ, pi̯oɡʳ, pi̯u, pi̯ub, pi̯ubʳ, pi̯ufk, pi̯ufkʳ, pi̯ufp, pi̯ufp?, pi̯ufpʳ, pi̯uft, pi̯uk, pi̯ukʳ, pi̯up, pi̯up?, pi̯upʳ, pi̯us, pi̯usk, pi̯uskʳ, pi̯usp, pi̯usp?, pi̯uspʳ, pi̯ust, pi̯uvb, pi̯uvd, pi̯uzb, pi̯uzd, pi̯uzvb, pi̯uzvbʳ, pi̯uzvd, pi̯uzvɡ, pi̯uzvɡʳ, pi̯uɡ, pi̯uɡʳ, pmla, pmlai̯, pmlai̯s, pmlas, pmli, pmlis, pmli̯a, pmli̯as, pmli̯o, pmli̯ob, pmli̯obʳ, pmli̯ofk, pmli̯ofkʳ, pmli̯ofp, pmli̯ofp?, pmli̯ofpʳ, pmli̯oft, pmli̯ok, pmli̯okʳ, pmli̯op, pmli̯op?, pmli̯opʳ, pmli̯os, pmli̯osk, pmli̯oskʳ, pmli̯osp, pmli̯osp?, pmli̯ospʳ, pmli̯ost, pmli̯ovb, pmli̯ovd, pmli̯ozb, pmli̯ozd, pmli̯ozvb, pmli̯ozvbʳ, pmli̯ozvd, pmli̯ozvɡ, pmli̯ozvɡʳ, pmli̯oɡ, pmli̯oɡʳ, pmli̯u, pmli̯ub, pmli̯ubʳ, pmli̯ufk, pmli̯ufkʳ, pmli̯ufp, pmli̯ufp?, pmli̯ufpʳ, pmli̯uft, pmli̯uk, pmli̯ukʳ, pmli̯up, pmli̯up?, pmli̯upʳ, pmli̯us, pmli̯usk, pmli̯uskʳ, pmli̯usp, pmli̯usp?, pmli̯uspʳ, pmli̯ust, pmli̯uvb, pmli̯uvd, pmli̯uzb, pmli̯uzd, pmli̯uzvb, pmli̯uzvbʳ, pmli̯uzvd, pmli̯uzvɡ, pmli̯uzvɡʳ, pmli̯uɡ, pmli̯uɡʳ, pmlo, pmlob, pmlobʳ, pmlofk, pmlofkʳ, pmlofp, pmlofp?, pmlofpʳ, pmloft, pmloi̯, pmloi̯b, pmloi̯bʳ, pmloi̯fk, pmloi̯fkʳ, pmloi̯fp, pmloi̯fp?, pmloi̯fpʳ, pmloi̯ft, pmloi̯k, pmloi̯kʳ, pmloi̯p, pmloi̯p?, pmloi̯pʳ, pmloi̯s, pmloi̯sk, pmloi̯skʳ, pmloi̯sp, pmloi̯sp?, pmloi̯spʳ, pmloi̯st, pmloi̯vb, pmloi̯vd, pmloi̯zb, pmloi̯zd, pmloi̯zvb, pmloi̯zvbʳ, pmloi̯zvd, pmloi̯zvɡ, pmloi̯zvɡʳ, pmloi̯ɡ, pmloi̯ɡʳ, pmlok, pmlokʳ, pmlop, pmlop?, pmlopʳ, pmlos, pmlosk, pmloskʳ, pmlosp, pmlosp?, pmlospʳ, pmlost, pmlovb, pmlovd, pmlozb, pmlozd, pmlozvb, pmlozvbʳ, pmlozvd, pmlozvɡ, pmlozvɡʳ, pmloɡ, pmloɡʳ, pmlu, pmlub, pmlubʳ, pmlufk, pmlufkʳ, pmlufp, pmlufp?, pmlufpʳ, pmluft, pmlui̯, pmlui̯b, pmlui̯bʳ, pmlui̯fk, pmlui̯fkʳ, pmlui̯fp, pmlui̯fp?, pmlui̯fpʳ, pmlui̯ft, pmlui̯k, pmlui̯kʳ, pmlui̯p, pmlui̯p?, pmlui̯pʳ, pmlui̯s, pmlui̯sk, pmlui̯skʳ, pmlui̯sp, pmlui̯sp?, pmlui̯spʳ, pmlui̯st, pmlui̯vb, pmlui̯vd, pmlui̯zb, pmlui̯zd, pmlui̯zvb, pmlui̯zvbʳ, pmlui̯zvd, pmlui̯zvɡ, pmlui̯zvɡʳ, pmlui̯ɡ, pmlui̯ɡʳ, pmluk, pmlukʳ, pmlup, pmlup?, pmlupʳ, pmlus, pmlusk, pmluskʳ, pmlusp, pmlusp?, pmluspʳ, pmlust, pmluvb, pmluvd, pmluzb, pmluzd, pmluzvb, pmluzvbʳ, pmluzvd, pmluzvɡ, pmluzvɡʳ, pmluɡ, pmluɡʳ, pmlæ, pmlæs, po, pob, pobʳ, pofk, pofkʳ, pofp, pofp?, pofpʳ, poft, poi̯, poi̯b, poi̯bʳ, poi̯fk, poi̯fkʳ, poi̯fp, poi̯fp?, poi̯fpʳ, poi̯ft, poi̯k, poi̯kʳ, poi̯p, poi̯p?, poi̯pʳ, poi̯s, poi̯sk, poi̯skʳ, poi̯sp, poi̯sp?, poi̯spʳ, poi̯st, poi̯vb, poi̯vd, poi̯zb, poi̯zd, poi̯zvb, poi̯zvbʳ, poi̯zvd, poi̯zvɡ, poi̯zvɡʳ, poi̯ɡ, poi̯ɡʳ, pok, pokʳ, pop, pop?, popʳ, pos, posk, poskʳ, posp, posp?, pospʳ, post, povb, povd, pozb, pozd, pozvb, pozvbʳ, pozvd, pozvɡ, pozvɡʳ, poɡ, poɡʳ, pu, pub, pubʳ, pufk, pufkʳ, pufp, pufp?, pufpʳ, puft, pui̯, pui̯b, pui̯bʳ, pui̯fk, pui̯fkʳ, pui̯fp, pui̯fp?, pui̯fpʳ, pui̯ft, pui̯k, pui̯kʳ, pui̯p, pui̯p?, pui̯pʳ, pui̯s, pui̯sk, pui̯skʳ, pui̯sp, pui̯sp?, pui̯spʳ, pui̯st, pui̯vb, pui̯vd, pui̯zb, pui̯zd, pui̯zvb, pui̯zvbʳ, pui̯zvd, pui̯zvɡ, pui̯zvɡʳ, pui̯ɡ, pui̯ɡʳ, puk, pukʳ, pup, pup?, pupʳ, pus, pusk, puskʳ, pusp, pusp?, puspʳ, pust, puvb, puvd, puzb, puzd, puzvb, puzvbʳ, puzvd, puzvɡ, puzvɡʳ, puɡ, puɡʳ, pæ, pæs, pʳa, pʳai̯, pʳai̯s, pʳas, pʳi, pʳis, pʳi̯a, pʳi̯as, pʳi̯o, pʳi̯ob, pʳi̯obʳ, pʳi̯ofk, pʳi̯ofkʳ, pʳi̯ofp, pʳi̯ofp?, pʳi̯ofpʳ, pʳi̯oft, pʳi̯ok, pʳi̯okʳ, pʳi̯op, pʳi̯op?, pʳi̯opʳ, pʳi̯os, pʳi̯osk, pʳi̯oskʳ, pʳi̯osp, pʳi̯osp?, pʳi̯ospʳ, pʳi̯ost, pʳi̯ovb, pʳi̯ovd, pʳi̯ozb, pʳi̯ozd, pʳi̯ozvb, pʳi̯ozvbʳ, pʳi̯ozvd, pʳi̯ozvɡ, pʳi̯ozvɡʳ, pʳi̯oɡ, pʳi̯oɡʳ, pʳi̯u, pʳi̯ub, pʳi̯ubʳ, pʳi̯ufk, pʳi̯ufkʳ, pʳi̯ufp, pʳi̯ufp?, pʳi̯ufpʳ, pʳi̯uft, pʳi̯uk, pʳi̯ukʳ, pʳi̯up, pʳi̯up?, pʳi̯upʳ, pʳi̯us, pʳi̯usk, pʳi̯uskʳ, pʳi̯usp, pʳi̯usp?, pʳi̯usp��, pʳi̯ust, pʳi̯uvb, pʳi̯uvd, pʳi̯uzb, pʳi̯uzd, pʳi̯uzvb, pʳi̯uzvbʳ, pʳi̯uzvd, pʳi̯uzvɡ, pʳi̯uzvɡʳ, pʳi̯uɡ, pʳi̯uɡʳ, pʳo, pʳob, pʳobʳ, pʳofk, pʳofkʳ, pʳofp, pʳofp?, pʳofpʳ, pʳoft, pʳoi̯, pʳoi̯b, pʳoi̯bʳ, pʳoi̯fk, pʳoi̯fkʳ, pʳoi̯fp, pʳoi̯fp?, pʳoi̯fpʳ, pʳoi̯ft, pʳoi̯k, pʳoi̯kʳ, pʳoi̯p, pʳoi̯p?, pʳoi̯pʳ, pʳoi̯s, pʳoi̯sk, pʳoi̯skʳ, pʳoi̯sp, pʳoi̯sp?, pʳoi̯spʳ, pʳoi̯st, pʳoi̯vb, pʳoi̯vd, pʳoi̯zb, pʳoi̯zd, pʳoi̯zvb, pʳoi̯zvbʳ, pʳoi̯zvd, pʳoi̯zvɡ, pʳoi̯zvɡʳ, pʳoi̯ɡ, pʳoi̯ɡʳ, pʳok, pʳokʳ, pʳop, pʳop?, pʳopʳ, pʳos, pʳosk, pʳoskʳ, pʳosp, pʳosp?, pʳospʳ, pʳost, pʳovb, pʳovd, pʳozb, pʳozd, pʳozvb, pʳozvbʳ, pʳozvd, pʳozvɡ, pʳozvɡʳ, pʳoɡ, pʳoɡʳ, pʳu, pʳub, pʳubʳ, pʳufk, pʳufkʳ, pʳufp, pʳufp?, pʳufpʳ, pʳuft, pʳui̯, pʳui̯b, pʳui̯bʳ, pʳui̯fk, pʳui̯fkʳ, pʳui̯fp, pʳui̯fp?, pʳui̯fpʳ, pʳui̯ft, pʳui̯k, pʳui̯kʳ, pʳui̯p, pʳui̯p?, pʳui̯pʳ, pʳui̯s, pʳui̯sk, pʳui̯skʳ, pʳui̯sp, pʳui̯sp?, pʳui̯spʳ, pʳui̯st, pʳui̯vb, pʳui̯vd, pʳui̯zb, pʳui̯zd, pʳui̯zvb, pʳui̯zvbʳ, pʳui̯zvd, pʳui̯zvɡ, pʳui̯zvɡʳ, pʳui̯ɡ, pʳui̯ɡʳ, pʳuk, pʳukʳ, pʳup, pʳup?, pʳupʳ, pʳus, pʳusk, pʳuskʳ, pʳusp, pʳusp?, pʳuspʳ, pʳust, pʳuvb, pʳuvd, pʳuzb, pʳuzd, pʳuzvb, pʳuzvbʳ, pʳuzvd, pʳuzvɡ, pʳuzvɡʳ, pʳuɡ, pʳuɡʳ, pʳæ, pʳæs, sa, sai̯, sai̯s, sas, si, sis, si̯a, si̯as, si̯o, si̯ob, si̯obʳ, si̯ofk, si̯ofkʳ, si̯ofp, si̯ofp?, si̯ofpʳ, si̯oft, si̯ok, si̯okʳ, si̯op, si̯op?, si̯opʳ, si̯os, si̯osk, si̯oskʳ, si̯osp, si̯osp?, si̯ospʳ, si̯ost, si̯ovb, si̯ovd, si̯ozb, si̯ozd, si̯ozvb, si̯ozvbʳ, si̯ozvd, si̯ozvɡ, si̯ozvɡʳ, si̯oɡ, si̯oɡʳ, si̯u, si̯ub, si̯ubʳ, si̯ufk, si̯ufkʳ, si̯ufp, si̯ufp?, si̯ufpʳ, si̯uft, si̯uk, si̯ukʳ, si̯up, si̯up?, si̯upʳ, si̯us, si̯usk, si̯uskʳ, si̯usp, si̯usp?, si̯uspʳ, si̯ust, si̯uvb, si̯uvd, si̯uzb, si̯uzd, si̯uzvb, si̯uzvbʳ, si̯uzvd, si̯uzvɡ, si̯uzvɡʳ, si̯uɡ, si̯uɡʳ, so, sob, sobʳ, sofk, sofkʳ, sofp, sofp?, sofpʳ, soft, soi̯, soi̯b, soi̯bʳ, soi̯fk, soi̯fkʳ, soi̯fp, soi̯fp?, soi̯fpʳ, soi̯ft, soi̯k, soi̯kʳ, soi̯p, soi̯p?, soi̯pʳ, soi̯s, soi̯sk, soi̯skʳ, soi̯sp, soi̯sp?, soi̯spʳ, soi̯st, soi̯vb, soi̯vd, soi̯zb, soi̯zd, soi̯zvb, soi̯zvbʳ, soi̯zvd, soi̯zvɡ, soi̯zvɡʳ, soi̯ɡ, soi̯ɡʳ, sok, sokʳ, sop, sop?, sopʳ, sos, sosk, soskʳ, sosp, sosp?, sospʳ, sost, sovb, sovd, sozb, sozd, sozvb, sozvbʳ, sozvd, sozvɡ, sozvɡʳ, soɡ, soɡʳ, su, sub, subʳ, sufk, sufkʳ, sufp, sufp?, sufpʳ, suft, sui̯, sui̯b, sui̯bʳ, sui̯fk, sui̯fkʳ, sui̯fp, sui̯fp?, sui̯fpʳ, sui̯ft, sui̯k, sui̯kʳ, sui̯p, sui̯p?, sui̯pʳ, sui̯s, sui̯sk, sui̯skʳ, sui̯sp, sui̯sp?, sui̯spʳ, sui̯st, sui̯vb, sui̯vd, sui̯zb, sui̯zd, sui̯zvb, sui̯zvbʳ, sui̯zvd, sui̯zvɡ, sui̯zvɡʳ, sui̯ɡ, sui̯ɡʳ, suk, sukʳ, sup, sup?, supʳ, sus, susk, suskʳ, susp, susp?, suspʳ, sust, suvb, suvd, suzb, suzd, suzvb, suzvbʳ, suzvd, suzvɡ, suzvɡʳ, suɡ, suɡʳ, sæ, sæs, ta, tai̯, tai̯s, tas, ti, tis, ti̯a, ti̯as, ti̯o, ti̯ob, ti̯obʳ, ti̯ofk, ti̯ofkʳ, ti̯ofp, ti̯ofp?, ti̯ofpʳ, ti̯oft, ti̯ok, ti̯okʳ, ti̯op, ti̯op?, ti̯opʳ, ti̯os, ti̯osk, ti̯oskʳ, ti̯osp, ti̯osp?, ti̯ospʳ, ti̯ost, ti̯ovb, ti̯ovd, ti̯ozb, ti̯ozd, ti̯ozvb, ti̯ozvbʳ, ti̯ozvd, ti̯ozvɡ, ti̯ozvɡʳ, ti̯oɡ, ti̯oɡʳ, ti̯u, ti̯ub, ti̯ubʳ, ti̯ufk, ti̯ufkʳ, ti̯ufp, ti̯ufp?, ti̯ufpʳ, ti̯uft, ti̯uk, ti̯ukʳ, ti̯up, ti̯up?, ti̯upʳ, ti̯us, ti̯usk, ti̯uskʳ, ti̯usp, ti̯usp?, ti̯uspʳ, ti̯ust, ti̯uvb, ti̯uvd, ti̯uzb, ti̯uzd, ti̯uzvb, ti̯uzvbʳ, ti̯uzvd, ti̯uzvɡ, ti̯uzvɡʳ, ti̯uɡ, ti̯uɡʳ, to, tob, tobʳ, tofk, tofkʳ, tofp, tofp?, tofpʳ, toft, toi̯, toi̯b, toi̯bʳ, toi̯fk, toi̯fkʳ, toi̯fp, toi̯fp?, toi̯fpʳ, toi̯ft, toi̯k, toi̯kʳ, toi̯p, toi̯p?, toi̯pʳ, toi̯s, toi̯sk, toi̯skʳ, toi̯sp, toi̯sp?, toi̯spʳ, toi̯st, toi̯vb, toi̯vd, toi̯zb, toi̯zd, toi̯zvb, toi̯zvbʳ, toi̯zvd, toi̯zvɡ, toi̯zvɡʳ, toi̯ɡ, toi̯ɡʳ, tok, tokʳ, top, top?, topʳ, tos, tosk, toskʳ, tosp, tosp?, tospʳ, tost, tovb, tovd, tozb, tozd, tozvb, tozvbʳ, tozvd, tozvɡ, tozvɡʳ, toɡ, toɡʳ, tu, tub, tubʳ, tufk, tufkʳ, tufp, tufp?, tufpʳ, tuft, tui̯, tui̯b, tui̯bʳ, tui̯fk, tui̯fkʳ, tui̯fp, tui̯fp?, tui̯fpʳ, tui̯ft, tui̯k, tui̯kʳ, tui̯p, tui̯p?, tui̯pʳ, tui̯s, tui̯sk, tui̯skʳ, tui̯sp, tui̯sp?, tui̯spʳ, tui̯st, tui̯vb, tui̯vd, tui̯zb, tui̯zd, tui̯zvb, tui̯zvbʳ, tui̯zvd, tui̯zvɡ, tui̯zvɡʳ, tui̯ɡ, tui̯ɡʳ, tuk, tukʳ, tup, tup?, tupʳ, tus, tusk, tuskʳ, tusp, tusp?, tuspʳ, tust, tuvb, tuvd, tuzb, tuzd, tuzvb, tuzvbʳ, tuzvd, tuzvɡ, tuzvɡʳ, tuɡ, tuɡʳ, tæ, tæs, tʳa, tʳai̯, tʳai̯s, tʳas, tʳi, tʳis, tʳi̯a, tʳi̯as, tʳi̯o, tʳi̯ob, tʳi̯obʳ, tʳi̯ofk, tʳi��ofkʳ, tʳi̯ofp, tʳi̯ofp?, tʳi̯ofpʳ, tʳi̯oft, tʳi̯ok, tʳi̯okʳ, tʳi̯op, tʳi̯op?, tʳi̯opʳ, tʳi̯os, tʳi̯osk, tʳi̯oskʳ, tʳi̯osp, tʳi̯osp?, tʳi̯ospʳ, tʳi̯ost, tʳi̯ovb, tʳi̯ovd, tʳi̯ozb, tʳi̯ozd, tʳi̯ozvb, tʳi̯ozvbʳ, tʳi̯ozvd, tʳi̯ozvɡ, tʳi̯ozvɡʳ, tʳi̯oɡ, tʳi̯oɡʳ, tʳi̯u, tʳi̯ub, tʳi̯ubʳ, tʳi̯ufk, tʳi̯ufkʳ, tʳi̯ufp, tʳi̯ufp?, tʳi̯ufpʳ, tʳi̯uft, tʳi̯uk, tʳi̯ukʳ, tʳi̯up, tʳi̯up?, tʳi̯upʳ, tʳi̯us, tʳi̯usk, tʳi̯uskʳ, tʳi̯usp, tʳi̯usp?, tʳi̯uspʳ, tʳi̯ust, tʳi̯uvb, tʳi̯uvd, tʳi̯uzb, tʳi̯uzd, tʳi̯uzvb, tʳi̯uzvbʳ, tʳi̯uzvd, tʳi̯uzvɡ, tʳi̯uzvɡʳ, tʳi̯uɡ, tʳi̯uɡʳ, tʳo, tʳob, tʳobʳ, tʳofk, tʳofkʳ, tʳofp, tʳofp?, tʳofpʳ, tʳoft, tʳoi̯, tʳoi̯b, tʳoi̯bʳ, tʳoi̯fk, tʳoi̯fkʳ, tʳoi̯fp, tʳoi̯fp?, tʳoi̯fpʳ, tʳoi̯ft, tʳoi̯k, tʳoi̯kʳ, tʳoi̯p, tʳoi̯p?, tʳoi̯pʳ, tʳoi̯s, tʳoi̯sk, tʳoi̯skʳ, tʳoi̯sp, tʳoi̯sp?, tʳoi̯spʳ, tʳoi̯st, tʳoi̯vb, tʳoi̯vd, tʳoi̯zb, tʳoi̯zd, tʳoi̯zvb, tʳoi̯zvbʳ, tʳoi̯zvd, tʳoi̯zvɡ, tʳoi̯zvɡʳ, tʳoi̯ɡ, tʳoi̯ɡʳ, tʳok, tʳokʳ, tʳop, tʳop?, tʳopʳ, tʳos, tʳosk, tʳoskʳ, tʳosp, tʳosp?, tʳospʳ, tʳost, tʳovb, tʳovd, tʳozb, tʳozd, tʳozvb, tʳozvbʳ, tʳozvd, tʳozvɡ, tʳozvɡʳ, tʳoɡ, tʳoɡʳ, tʳu, tʳub, tʳubʳ, tʳufk, tʳufkʳ, tʳufp, tʳufp?, tʳufpʳ, tʳuft, tʳui̯, tʳui̯b, tʳui̯bʳ, tʳui̯fk, tʳui̯fkʳ, tʳui̯fp, tʳui̯fp?, tʳui̯fpʳ, tʳui̯ft, tʳui̯k, tʳui̯kʳ, tʳui̯p, tʳui̯p?, tʳui̯pʳ, tʳui̯s, tʳui̯sk, tʳui̯skʳ, tʳui̯sp, tʳui̯sp?, tʳui̯spʳ, tʳui̯st, tʳui̯vb, tʳui̯vd, tʳui̯zb, tʳui̯zd, tʳui̯zvb, tʳui̯zvbʳ, tʳui̯zvd, tʳui̯zvɡ, tʳui̯zvɡʳ, tʳui̯ɡ, tʳui̯ɡʳ, tʳuk, tʳukʳ, tʳup, tʳup?, tʳupʳ, tʳus, tʳusk, tʳuskʳ, tʳusp, tʳusp?, tʳuspʳ, tʳust, tʳuvb, tʳuvd, tʳuzb, tʳuzd, tʳuzvb, tʳuzvbʳ, tʳuzvd, tʳuzvɡ, tʳuzvɡʳ, tʳuɡ, tʳuɡʳ, tʳæ, tʳæs, u, ub, ubʳ, ufk, ufkʳ, ufp, ufp?, ufpʳ, uft, ui̯, ui̯b, ui̯bʳ, ui̯fk, ui̯fkʳ, ui̯fp, ui̯fp?, ui̯fpʳ, ui̯ft, ui̯k, ui̯kʳ, ui̯p, ui̯p?, ui̯pʳ, ui̯s, ui̯sk, ui̯skʳ, ui̯sp, ui̯sp?, ui̯spʳ, ui̯st, ui̯vb, ui̯vd, ui̯zb, ui̯zd, ui̯zvb, ui̯zvbʳ, ui̯zvd, ui̯zvɡ, ui̯zvɡʳ, ui̯ɡ, ui̯ɡʳ, uk, ukʳ, up, up?, upʳ, us, usk, uskʳ, usp, usp?, uspʳ, ust, uvb, uvd, uzb, uzd, uzvb, uzvbʳ, uzvd, uzvɡ, uzvɡʳ, uɡ, uɡʳ, va, vai̯, vai̯s, vas, vi, vis, vi̯a, vi̯as, vi̯o, vi̯ob, vi̯obʳ, vi̯ofk, vi̯ofkʳ, vi̯ofp, vi̯ofp?, vi̯ofpʳ, vi̯oft, vi̯ok, vi̯okʳ, vi̯op, vi̯op?, vi̯opʳ, vi̯os, vi̯osk, vi̯oskʳ, vi̯osp, vi̯osp?, vi̯ospʳ, vi̯ost, vi̯ovb, vi̯ovd, vi̯ozb, vi̯ozd, vi̯ozvb, vi̯ozvbʳ, vi̯ozvd, vi̯ozvɡ, vi̯ozvɡʳ, vi̯oɡ, vi̯oɡʳ, vi̯u, vi̯ub, vi̯ubʳ, vi̯ufk, vi̯ufkʳ, vi̯ufp, vi̯ufp?, vi̯ufpʳ, vi̯uft, vi̯uk, vi̯ukʳ, vi̯up, vi̯up?, vi̯upʳ, vi̯us, vi̯usk, vi̯uskʳ, vi̯usp, vi̯usp?, vi̯uspʳ, vi̯ust, vi̯uvb, vi̯uvd, vi̯uzb, vi̯uzd, vi̯uzvb, vi̯uzvbʳ, vi̯uzvd, vi̯uzvɡ, vi̯uzvɡʳ, vi̯uɡ, vi̯uɡʳ, vo, vob, vobʳ, vofk, vofkʳ, vofp, vofp?, vofpʳ, voft, voi̯, voi̯b, voi̯bʳ, voi̯fk, voi̯fkʳ, voi̯fp, voi̯fp?, voi̯fpʳ, voi̯ft, voi̯k, voi̯kʳ, voi̯p, voi̯p?, voi̯pʳ, voi̯s, voi̯sk, voi̯skʳ, voi̯sp, voi̯sp?, voi̯spʳ, voi̯st, voi̯vb, voi̯vd, voi̯zb, voi̯zd, voi̯zvb, voi̯zvbʳ, voi̯zvd, voi̯zvɡ, voi̯zvɡʳ, voi̯ɡ, voi̯ɡʳ, vok, vokʳ, vop, vop?, vopʳ, vos, vosk, voskʳ, vosp, vosp?, vospʳ, vost, vovb, vovd, vozb, vozd, vozvb, vozvbʳ, vozvd, vozvɡ, vozvɡʳ, voɡ, voɡʳ, vu, vub, vubʳ, vufk, vufkʳ, vufp, vufp?, vufpʳ, vuft, vui̯, vui̯b, vui̯bʳ, vui̯fk, vui̯fkʳ, vui̯fp, vui̯fp?, vui̯fpʳ, vui̯ft, vui̯k, vui̯kʳ, vui̯p, vui̯p?, vui̯pʳ, vui̯s, vui̯sk, vui̯skʳ, vui̯sp, vui̯sp?, vui̯spʳ, vui̯st, vui̯vb, vui̯vd, vui̯zb, vui̯zd, vui̯zvb, vui̯zvbʳ, vui̯zvd, vui̯zvɡ, vui̯zvɡʳ, vui̯ɡ, vui̯ɡʳ, vuk, vukʳ, vup, vup?, vupʳ, vus, vusk, vuskʳ, vusp, vusp?, vuspʳ, vust, vuvb, vuvd, vuzb, vuzd, vuzvb, vuzvbʳ, vuzvd, vuzvɡ, vuzvɡʳ, vuɡ, vuɡʳ, væ, væs, za, zai̯, zai̯s, zas, zi, zis, zi̯a, zi̯as, zi̯o, zi̯ob, zi̯obʳ, zi̯ofk, zi̯ofkʳ, zi̯ofp, zi̯ofp?, zi̯ofpʳ, zi̯oft, zi̯ok, zi̯okʳ, zi̯op, zi̯op?, zi̯opʳ, zi̯os, zi̯osk, zi̯oskʳ, zi̯osp, zi̯osp?, zi̯ospʳ, zi̯ost, zi̯ovb, zi̯ovd, zi̯ozb, zi̯ozd, zi̯ozvb, zi̯ozvbʳ, zi̯ozvd, zi̯ozvɡ, zi̯ozvɡʳ, zi̯oɡ, zi̯oɡʳ, zi̯u, zi̯ub, zi̯ubʳ, zi̯ufk, zi̯ufkʳ, zi̯ufp, zi̯ufp?, zi̯ufpʳ, zi̯uft, zi̯uk, zi̯ukʳ, zi̯up, zi̯up?, zi̯upʳ, zi̯us, zi̯usk, zi̯uskʳ, zi̯usp, zi̯usp?, zi̯uspʳ, zi̯ust, zi̯uvb, zi̯uvd, zi̯uzb, zi̯uzd, zi̯uzvb, zi̯uzvbʳ, zi̯uzvd, zi̯uzvɡ, zi̯uzvɡʳ, zi̯uɡ, zi̯uɡʳ, zo, zob, zobʳ, zofk, zofkʳ, zofp, zofp?, zofpʳ, zoft, zoi̯, zoi̯b, zoi̯bʳ, zoi̯fk, zoi̯fkʳ, zoi̯fp, zoi̯fp?, zoi̯fpʳ, zoi̯ft, zoi̯k, zoi̯kʳ, zoi̯p, zoi̯p?, zoi̯pʳ, zoi̯s, zoi̯sk, zoi̯skʳ, zoi̯sp, zoi̯sp?, zoi̯spʳ, zoi̯st, zoi̯vb, zoi̯vd, zoi̯zb, zoi̯zd, zoi̯zvb, zoi̯zvbʳ, zoi̯zvd, zoi̯zvɡ, zoi̯zvɡʳ, zoi̯ɡ, zoi̯ɡʳ, zok, zokʳ, zop, zop?, zopʳ, zos, zosk, zoskʳ, zosp, zosp?, zospʳ, zost, zovb, zovd, zozb, zozd, zozvb, zozvbʳ, zozvd, zozvɡ, zozvɡʳ, zoɡ, zoɡʳ, zu, zub, zubʳ, zufk, zufkʳ, zufp, zufp?, zufpʳ, zuft, zui̯, zui̯b, zui̯bʳ, zui̯fk, zui̯fkʳ, zui̯fp, zui̯fp?, zui̯fpʳ, zui̯ft, zui̯k, zui̯kʳ, zui̯p, zui̯p?, zui̯pʳ, zui̯s, zui̯sk, zui̯skʳ, zui̯sp, zui̯sp?, zui̯spʳ, zui̯st, zui̯vb, zui̯vd, zui̯zb, zui̯zd, zui̯zvb, zui̯zvbʳ, zui̯zvd, zui̯zvɡ, zui̯zvɡʳ, zui̯ɡ, zui̯ɡʳ, zuk, zukʳ, zup, zup?, zupʳ, zus, zusk, zuskʳ, zusp, zusp?, zuspʳ, zust, zuvb, zuvd, zuzb, zuzd, zuzvb, zuzvbʳ, zuzvd, zuzvɡ, zuzvɡʳ, zuɡ, zuɡʳ, zæ, zæs, æ, æs, ɡa, ɡai̯, ɡai̯s, ɡas, ɡi, ɡis, ɡi̯a, ɡi̯as, ɡi̯o, ɡi̯ob, ɡi̯obʳ, ɡi̯ofk, ɡi̯ofkʳ, ɡi̯ofp, ɡi̯ofp?, ɡi̯ofpʳ, ɡi̯oft, ɡi̯ok, ɡi̯okʳ, ɡi̯op, ɡi̯op?, ɡi̯opʳ, ɡi̯os, ɡi̯osk, ɡi̯oskʳ, ɡi̯osp, ɡi̯osp?, ɡi̯ospʳ, ɡi̯ost, ɡi̯ovb, ɡi̯ovd, ɡi̯ozb, ɡi̯ozd, ɡi̯ozvb, ɡi̯ozvbʳ, ɡi̯ozvd, ɡi̯ozvɡ, ɡi̯ozvɡʳ, ɡi̯oɡ, ɡi̯oɡʳ, ɡi̯u, ɡi̯ub, ɡi̯ubʳ, ɡi̯ufk, ɡi̯ufkʳ, ɡi̯ufp, ɡi̯ufp?, ɡi̯ufpʳ, ɡi̯uft, ɡi̯uk, ɡi̯ukʳ, ɡi̯up, ɡi̯up?, ɡi̯upʳ, ɡi̯us, ɡi̯usk, ɡi̯uskʳ, ɡi̯usp, ɡi̯usp?, ɡi̯uspʳ, ɡi̯ust, ɡi̯uvb, ɡi̯uvd, ɡi̯uzb, ɡi̯uzd, ɡi̯uzvb, ɡi̯uzvbʳ, ɡi̯uzvd, ɡi̯uzvɡ, ɡi̯uzvɡʳ, ɡi̯uɡ, ɡi̯uɡʳ, ɡla, ɡlai̯, ɡlai̯s, ɡlas, ɡli, ɡlis, ɡli̯a, ɡli̯as, ɡli̯o, ɡli̯ob, ɡli̯obʳ, ɡli̯ofk, ɡli̯ofkʳ, ɡli̯ofp, ɡli̯ofp?, ɡli̯ofpʳ, ɡli̯oft, ɡli̯ok, ɡli̯okʳ, ɡli̯op, ɡli̯op?, ɡli̯opʳ, ɡli̯os, ɡli̯osk, ɡli̯oskʳ, ɡli̯osp, ɡli̯osp?, ɡli̯ospʳ, ɡli̯ost, ɡli̯ovb, ɡli̯ovd, ɡli̯ozb, ɡli̯ozd, ɡli̯ozvb, ɡli̯ozvbʳ, ɡli̯ozvd, ɡli̯ozvɡ, ɡli̯ozvɡʳ, ɡli̯oɡ, ɡli̯oɡʳ, ɡli̯u, ɡli̯ub, ɡli̯ubʳ, ɡli̯ufk, ɡli̯ufkʳ, ɡli̯ufp, ɡli̯ufp?, ɡli̯ufpʳ, ɡli̯uft, ɡli̯uk, ɡli̯ukʳ, ɡli̯up, ɡli̯up?, ɡli̯upʳ, ɡli̯us, ɡli̯usk, ɡli̯uskʳ, ɡli̯usp, ɡli̯usp?, ɡli̯uspʳ, ɡli̯ust, ɡli̯uvb, ɡli̯uvd, ɡli̯uzb, ɡli̯uzd, ɡli̯uzvb, ɡli̯uzvbʳ, ɡli̯uzvd, ɡli̯uzvɡ, ɡli̯uzvɡʳ, ɡli̯uɡ, ɡli̯uɡʳ, ɡlo, ɡlob, ɡlobʳ, ɡlofk, ɡlofkʳ, ɡlofp, ɡlofp?, ɡlofpʳ, ɡloft, ɡloi̯, ɡloi̯b, ɡloi̯bʳ, ɡloi̯fk, ɡloi̯fkʳ, ɡloi̯fp, ɡloi̯fp?, ɡloi̯fpʳ, ɡloi̯ft, ɡloi̯k, ɡloi̯kʳ, ɡloi̯p, ɡloi̯p?, ɡloi̯pʳ, ɡloi̯s, ɡloi̯sk, ɡloi̯skʳ, ɡloi̯sp, ɡloi̯sp?, ɡloi̯spʳ, ɡloi̯st, ɡloi̯vb, ɡloi̯vd, ɡloi̯zb, ɡloi̯zd, ɡloi̯zvb, ɡloi̯zvbʳ, ɡloi̯zvd, ɡloi̯zvɡ, ɡloi̯zvɡʳ, ɡloi̯ɡ, ɡloi̯ɡʳ, ɡlok, ɡlokʳ, ɡlop, ɡlop?, ɡlopʳ, ɡlos, ɡlosk, ɡloskʳ, ɡlosp, ɡlosp?, ɡlospʳ, ɡlost, ɡlovb, ɡlovd, ɡlozb, ɡlozd, ɡlozvb, ɡlozvbʳ, ɡlozvd, ɡlozvɡ, ɡlozvɡʳ, ɡloɡ, ɡloɡʳ, ɡlu, ɡlub, ɡlubʳ, ɡlufk, ɡlufkʳ, ɡlufp, ɡlufp?, ɡlufpʳ, ɡluft, ɡlui̯, ɡlui̯b, ɡlui̯bʳ, ɡlui̯fk, ɡlui̯fkʳ, ɡlui̯fp, ɡlui̯fp?, ɡlui̯fpʳ, ɡlui̯ft, ɡlui̯k, ɡlui̯kʳ, ɡlui̯p, ɡlui̯p?, ɡlui̯pʳ, ɡlui̯s, ɡlui̯sk, ɡlui̯skʳ, ɡlui̯sp, ɡlui̯sp?, ɡlui̯spʳ, ɡlui̯st, ɡlui̯vb, ɡlui̯vd, ɡlui̯zb, ɡlui̯zd, ɡlui̯zvb, ɡlui̯zvbʳ, ɡlui̯zvd, ɡlui̯zvɡ, ɡlui̯zvɡʳ, ɡlui̯ɡ, ɡlui̯ɡʳ, ɡluk, ɡlukʳ, ɡlup, ɡlup?, ɡlupʳ, ɡlus, ɡlusk, ɡluskʳ, ɡlusp, ɡlusp?, ɡluspʳ, ɡlust, ɡluvb, ɡluvd, ɡluzb, ɡluzd, ɡluzvb, ɡluzvbʳ, ɡluzvd, ɡluzvɡ, ɡluzvɡʳ, ɡluɡ, ɡluɡʳ, ɡlæ, ɡlæs, ɡma, ɡmai̯, ɡmai̯s, ɡmas, ɡmi, ɡmis, ɡmi̯a, ɡmi̯as, ɡmi̯o, ɡmi̯ob, ɡmi̯obʳ, ɡmi̯ofk, ɡmi̯ofkʳ, ɡmi̯ofp, ɡmi̯ofp?, ɡmi̯ofpʳ, ɡmi̯oft, ɡmi̯ok, ɡmi̯okʳ, ɡmi̯op, ɡmi̯op?, ɡmi̯opʳ, ɡmi̯os, ɡmi̯osk, ɡmi̯oskʳ, ɡmi̯osp, ɡmi̯osp?, ɡmi̯ospʳ, ɡmi̯ost, ɡmi̯ovb, ɡmi̯ovd, ɡmi̯ozb, ɡmi̯ozd, ɡmi̯ozvb, ɡmi̯ozvbʳ, ɡmi̯ozvd, ɡmi̯ozvɡ, ɡmi̯ozvɡʳ, ɡmi̯oɡ, ɡmi̯oɡʳ, ɡmi̯u, ɡmi̯ub, ɡmi̯ubʳ, ɡmi̯ufk, ɡmi̯ufkʳ, ɡmi̯ufp, ɡmi̯ufp?, ɡmi̯ufpʳ, ɡmi̯uft, ɡmi̯uk, ɡmi̯ukʳ, ɡmi̯up, ɡmi̯up?, ɡmi̯upʳ, ɡmi̯us, ɡmi̯usk, ɡmi̯uskʳ, ɡmi̯usp, ɡmi̯usp?, ɡmi̯uspʳ, ɡmi̯ust, ɡmi̯uvb, ɡmi̯uvd, ɡmi̯uzb, ɡmi̯uzd, ɡmi̯uzvb, ɡmi̯uzvbʳ, ɡmi̯uzvd, ɡmi̯uzvɡ, ɡmi̯uzvɡʳ, ɡmi̯uɡ, ɡmi̯uɡʳ, ɡmo, ɡmob, ɡmobʳ, ɡmofk, ɡmofkʳ, ɡmofp, ɡmofp?, ɡmofpʳ, ɡmoft, ɡmoi̯, ɡmoi̯b, ɡmoi̯bʳ, ɡmoi̯fk, ɡmoi̯fkʳ, ɡmoi̯fp, ɡmoi̯fp?, ɡmoi̯fpʳ, ɡmoi̯ft, ɡmoi̯k, ɡmoi̯kʳ, ɡmoi̯p, ɡmoi̯p?, ɡmoi̯pʳ, ɡmoi̯s, ɡmoi̯sk, ɡmoi̯skʳ, ɡmoi̯sp, ɡmoi̯sp?, ɡmoi̯spʳ, ɡmoi̯st, ɡmoi̯vb, ɡmoi̯vd, ɡmoi̯zb, ɡmoi̯zd, ɡmoi̯zvb, ɡmoi̯zvbʳ, ɡmoi̯zvd, ɡmoi̯zvɡ, ɡmoi̯zvɡʳ, ɡmoi̯ɡ, ɡmoi̯ɡʳ, ɡmok, ɡmokʳ, ɡmop, ɡmop?, ɡmopʳ, ɡmos, ɡmosk, ɡmoskʳ, ɡmosp, ɡmosp?, ɡmospʳ, ɡmost, ɡmovb, ɡmovd, ɡmozb, ɡmozd, ɡmozvb, ɡmozvbʳ, ɡmozvd, ɡmozvɡ, ɡmozvɡʳ, ɡmoɡ, ɡmoɡʳ, ɡmu, ɡmub, ɡmubʳ, ɡmufk, ɡmufkʳ, ɡmufp, ɡmufp?, ɡmufpʳ, ɡmuft, ɡmui̯, ɡmui̯b, ɡmui̯bʳ, ɡmui̯fk, ɡmui̯fkʳ, ɡmui̯fp, ɡmui̯fp?, ɡmui̯fpʳ, ɡmui̯ft, ɡmui̯k, ɡmui̯kʳ, ɡmui̯p, ɡmui̯p?, ɡmui̯pʳ, ɡmui̯s, ɡmui̯sk, ɡmui̯skʳ, ɡmui̯sp, ɡmui̯sp?, ɡmui̯spʳ, ɡmui̯st, ɡmui̯vb, ɡmui̯vd, ɡmui̯zb, ɡmui̯zd, ɡmui̯zvb, ɡmui̯zvbʳ, ɡmui̯zvd, ɡmui̯zvɡ, ɡmui̯zvɡʳ, ɡmui̯ɡ, ɡmui̯ɡʳ, ɡmuk, ɡmukʳ, ɡmup, ɡmup?, ɡmupʳ, ɡmus, ɡmusk, ɡmuskʳ, ɡmusp, ɡmusp?, ɡmuspʳ, ɡmust, ɡmuvb, ɡmuvd, ɡmuzb, ɡmuzd, ɡmuzvb, ɡmuzvbʳ, ɡmuzvd, ɡmuzvɡ, ɡmuzvɡʳ, ɡmuɡ, ɡmuɡʳ, ɡmæ, ɡmæs, ɡo, ɡob, ɡobʳ, ɡofk, ɡofkʳ, ɡofp, ɡofp?, ɡofpʳ, ɡoft, ɡoi̯, ɡoi̯b, ɡoi̯bʳ, ɡoi̯fk, ɡoi̯fkʳ, ɡoi̯fp, ɡoi̯fp?, ɡoi̯fpʳ, ɡoi̯ft, ɡoi̯k, ɡoi̯kʳ, ɡoi̯p, ɡoi̯p?, ɡoi̯pʳ, ɡoi̯s, ɡoi̯sk, ɡoi̯skʳ, ɡoi̯sp, ɡoi̯sp?, ɡoi̯spʳ, ɡoi̯st, ɡoi̯vb, ɡoi̯vd, ɡoi̯zb, ɡoi̯zd, ɡoi̯zvb, ɡoi̯zvbʳ, ɡoi̯zvd, ɡoi̯zvɡ, ɡoi̯zvɡʳ, ɡoi̯ɡ, ɡoi̯ɡʳ, ɡok, ɡokʳ, ɡop, ɡop?, ɡopʳ, ɡos, ɡosk, ɡoskʳ, ɡosp, ɡosp?, ɡospʳ, ɡost, ɡovb, ɡovd, ɡozb, ɡozd, ɡozvb, ɡozvbʳ, ɡozvd, ɡozvɡ, ɡozvɡʳ, ɡoɡ, ɡoɡʳ, ɡu, ɡub, ɡubʳ, ɡufk, ɡufkʳ, ɡufp, ɡufp?, ɡufpʳ, ɡuft, ɡui̯, ɡui̯b, ɡui̯bʳ, ɡui̯fk, ɡui̯fkʳ, ɡui̯fp, ɡui̯fp?, ɡui̯fpʳ, ɡui̯ft, ɡui̯k, ɡui̯kʳ, ɡui̯p, ɡui̯p?, ɡui̯pʳ, ɡui̯s, ɡui̯sk, ɡui̯skʳ, ɡui̯sp, ɡui̯sp?, ɡui̯spʳ, ɡui̯st, ɡui̯vb, ɡui̯vd, ɡui̯zb, ɡui̯zd, ɡui̯zvb, ɡui̯zvbʳ, ɡui̯zvd, ɡui̯zvɡ, ɡui̯zvɡʳ, ɡui̯ɡ, ɡui̯ɡʳ, ɡuk, ɡukʳ, ɡup, ɡup?, ɡupʳ, ɡus, ɡusk, ɡuskʳ, ɡusp, ɡusp?, ɡuspʳ, ɡust, ɡuvb, ɡuvd, ɡuzb, ɡuzd, ɡuzvb, ɡuzvbʳ, ɡuzvd, ɡuzvɡ, ɡuzvɡʳ, ɡuɡ, ɡuɡʳ, ɡæ, ɡæs, ɡʳa, ɡʳai̯, ɡʳai̯s, ɡʳas, ɡʳi, ɡʳis, ɡʳi̯a, ɡʳi̯as, ɡʳi̯o, ɡʳi̯ob, ɡʳi̯obʳ, ɡʳi̯ofk, ɡʳi̯ofkʳ, ɡʳi̯ofp, ɡʳi̯ofp?, ɡʳi̯ofpʳ, ɡʳi̯oft, ɡʳi̯ok, ɡʳi̯okʳ, ɡʳi̯op, ɡʳi̯op?, ɡʳi̯opʳ, ɡʳi̯os, ɡʳi̯osk, ɡʳi̯oskʳ, ɡʳi̯osp, ɡʳi̯osp?, ɡʳi̯ospʳ, ɡʳi̯ost, ɡʳi̯ovb, ɡʳi̯ovd, ɡʳi̯ozb, ɡʳi̯ozd, ɡʳi̯ozvb, ɡʳi̯ozvbʳ, ɡʳi̯ozvd, ɡʳi̯ozvɡ, ɡʳi̯ozvɡʳ, ɡʳi̯oɡ, ɡʳi̯oɡʳ, ɡʳi̯u, ɡʳi̯ub, ɡʳi̯ubʳ, ɡʳi̯ufk, ɡʳi̯ufkʳ, ɡʳi̯ufp, ɡʳi̯ufp?, ɡʳi̯ufpʳ, ɡʳi̯uft, ɡʳi̯uk, ɡʳi̯ukʳ, ɡʳi̯up, ɡʳi̯up?, ɡʳi̯upʳ, ɡʳi̯us, ɡʳi̯usk, ɡʳi̯uskʳ, ɡʳi̯usp, ɡʳi̯usp?, ɡʳi̯uspʳ, ɡʳi̯ust, ɡʳi̯uvb, ɡʳi̯uvd, ɡʳi̯uzb, ɡʳi̯uzd, ɡʳi̯uzvb, ɡʳi̯uzvbʳ, ɡʳi̯uzvd, ɡʳi̯uzvɡ, ɡʳi̯uzvɡʳ, ɡʳi̯uɡ, ɡʳi̯uɡʳ, ɡʳo, ɡʳob, ɡʳobʳ, ɡʳofk, ɡʳofkʳ, ɡʳofp, ɡʳofp?, ɡʳofpʳ, ɡʳoft, ɡʳoi̯, ɡʳoi̯b, ɡʳoi̯bʳ, ɡʳoi̯fk, ɡʳoi̯fkʳ, ɡʳoi̯fp, ɡʳoi̯fp?, ɡʳoi̯fpʳ, ɡʳoi̯ft, ɡʳoi̯k, ɡʳoi̯kʳ, ɡʳoi̯p, ɡʳoi̯p?, ɡʳoi̯pʳ, ɡʳoi̯s, ɡʳoi̯sk, ɡʳoi̯skʳ, ɡʳoi̯sp, ɡʳoi̯sp?, ɡʳoi̯spʳ, ɡʳoi̯st, ɡʳoi̯vb, ɡʳoi̯vd, ɡʳoi̯zb, ɡʳoi̯zd, ɡʳoi̯zvb, ɡʳoi̯zvbʳ, ɡʳoi̯zvd, ɡʳoi̯zvɡ, ɡʳoi̯zvɡʳ, ɡʳoi̯ɡ, ɡʳoi̯ɡʳ, ɡʳok, ɡʳokʳ, ɡʳop, ɡʳop?, ɡʳopʳ, ɡʳos, ɡʳosk, ɡʳoskʳ, ɡʳosp, ɡʳosp?, ɡʳospʳ, ɡʳost, ɡʳovb, ɡʳovd, ɡʳozb, ɡʳozd, ɡʳozvb, ɡʳozvbʳ, ɡʳozvd, ɡʳozvɡ, ɡʳozvɡʳ, ɡʳoɡ, ɡʳoɡʳ, ɡʳu, ɡʳub, ɡʳubʳ, ɡʳufk, ɡʳufkʳ, ɡʳufp, ɡʳufp?, ɡʳufpʳ, ɡʳuft, ɡʳui̯, ɡʳui̯b, ɡʳui̯bʳ, ɡʳui̯fk, ɡʳui̯fkʳ, ɡʳui̯fp, ɡʳui̯fp?, ɡʳui̯fpʳ, ɡʳui̯ft, ɡʳui̯k, ɡʳui̯kʳ, ɡʳui̯p, ɡʳui̯p?, ɡʳui̯pʳ, ɡʳui̯s, ɡʳui̯sk, ɡʳui̯skʳ, ɡʳui̯sp, ɡʳui̯sp?, ɡʳui̯spʳ, ɡʳui̯st, ɡʳui��vb, ɡʳui̯vd, ɡʳui̯zb, ɡʳui̯zd, ɡʳui̯zvb, ɡʳui̯zvbʳ, ɡʳui̯zvd, ɡʳui̯zvɡ, ɡʳui̯zvɡʳ, ɡʳui̯ɡ, ɡʳui̯ɡʳ, ɡʳuk, ɡʳukʳ, ɡʳup, ɡʳup?, ɡʳupʳ, ɡʳus, ɡʳusk, ɡʳuskʳ, ɡʳusp, ɡʳusp?, ɡʳuspʳ, ɡʳust, ɡʳuvb, ɡʳuvd, ɡʳuzb, ɡʳuzd, ɡʳuzvb, ɡʳuzvbʳ, ɡʳuzvd, ɡʳuzvɡ, ɡʳuzvɡʳ, ɡʳuɡ, ɡʳuɡʳ, ɡʳæ, ɡʳæs\r\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-dev-4982",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectDependencies": [
    "Planet.main"
   ],
   "projectLibraries": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
